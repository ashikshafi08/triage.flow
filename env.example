# AI Provider Configuration
OPENAI_API_KEY=your_openai_key_here
OPENROUTER_API_KEY=your_openrouter_key_here  # Recommended for cost savings
GITHUB_TOKEN=your_github_token_here

# Model Configuration
LLM_PROVIDER=openrouter  # or "openai"
DEFAULT_MODEL=anthropic/claude-3.5-sonnet  # or gpt-4o-mini

# Performance & Cost Optimization
ENABLE_PROMPT_CACHING=true  # 25-90% AI cost savings
ENABLE_SMART_SIZING=true    # Dynamic context sizing
MIN_RAG_SOURCES=10          # Minimum context sources
DEFAULT_RAG_SOURCES=15      # Default context sources
MAX_RAG_SOURCES=25          # Maximum context sources

# Feature Flags
ENABLE_RAG_CACHING=true
ENABLE_RESPONSE_CACHING=true
ENABLE_ASYNC_RAG=true

# Production Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8080  # Comma-separated list
VITE_API_URL=http://localhost:8000  # Frontend API URL 