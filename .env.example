# Example environment configuration for triage.flow
# Copy this to .env and customize as needed

# API Keys
OPENAI_API_KEY=your_openai_key_here
OPENROUTER_API_KEY=your_openrouter_key_here
GITHUB_TOKEN=your_github_token_here

# LLM Configuration
LLM_PROVIDER=openrouter
# Use models that support function calling for agent tools
DEFAULT_MODEL=openai/gpt-4o-mini
CHEAP_MODEL=openai/gpt-4o-mini

# Alternative function-calling compatible models:
# DEFAULT_MODEL=anthropic/claude-3.5-sonnet
# CHEAP_MODEL=anthropic/claude-3.5-haiku
# DEFAULT_MODEL=meta-llama/llama-3.1-70b-instruct
# CHEAP_MODEL=meta-llama/llama-3.1-8b-instruct

# Note: Gemini models don't support function calling:
# ‚ùå google/gemini-2.5-flash-preview-05-20 (doesn't work with agents)

# Redis Configuration (optional)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Performance Settings
AGENTIC_MAX_ITERATIONS=25
ENABLE_CONTEXT_AWARE_TOOLS=true
CACHE_ENABLED=true