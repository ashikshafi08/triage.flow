[{"id_": "9e65953b-9768-411a-9c20-9f0d4882f3cf", "embedding": null, "metadata": {"issue_id": 341, "title": "ZeroDivisionError", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "04fa9911-b662-4108-b896-64f668d4911a", "node_type": "4", "metadata": {"issue_id": 341, "title": "ZeroDivisionError", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "a0cb4c5a2081306b963cf16ce46d43af71f2d9247bc40788db3c5caec767bf34", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: ZeroDivisionError\n\nDescription: Traceback (most recent call last): File \"/app/src/main.py\", line 311, in <module> result = run_hedge_fund( ^^^^^^^^^^^^^^^ File \"/app/src/main.py\", line 66, in run_hedge_fund final_state = agent.invoke( ^^^^^^^^^^^^^ File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 1929, in invoke for chunk in self.stream( File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 1649, in stream for _ in runner.tick( File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py\", line 160, in tick _panic_or_proceed( File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py\", line 370, in _panic_or_proceed raise exc File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/executor.py\", line 70, in done task.result() File \"/usr/local/lib/python3.11/concurrent/futures/_base.py\", line 449, in result return self.__get_result() ^^^^^^^^^^^^^^^^^^^ File \"/usr/local/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result raise self._exception File \"/usr/local/lib/python3.11/concurrent/futures/thread.py\", line 58, in run result = self.fn(*self.args, **self.kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py\", line 44, in run_with_retry task.proc.invoke(task.input, config) File \"/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 410, in invoke input = context.run(step.invoke, input, config, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 184, in invoke ret = context.run(self.func, input, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/app/src/agents/charlie_munger.py\", line 87, in charlie_munger_agent predictability_analysis = analyze_predictability(financial_line_items) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/app/src/agents/charlie_munger.py\", line 446, in analyze_predictability growth_rates = [(revenues[i] / revenues[i+1] - 1) for i in range(len(revenues)-1)] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/app/src/agents/charlie_munger.py\", line 446, in <listcomp> growth_rates = [(revenues[i] / revenues[i+1] - 1) for i in range(len(revenues)-1)] ~~~~~~~~~~~~^~~~~~~~~~~~~~~ ZeroDivisionError: float division by zero During task with name 'charlie_munger_agent' and id 'a3b68279-c4f0-d14b-5d58-10a38b0b1117'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2567, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "0c610282-1a58-42dd-89d0-b0d4122058d7", "embedding": null, "metadata": {"issue_id": 340, "title": "Create support for AI/ML API - a model aggregate provider", "state": "open", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e610c3ea-fd84-4e01-91cd-f82408f1a068", "node_type": "4", "metadata": {"issue_id": 340, "title": "Create support for AI/ML API - a model aggregate provider", "state": "open", "labels": ["enhancement"], "type": "issue"}, "hash": "05eabec151e304dff2f4f0deb9cde6e016f593d3df95910020188d5f9d9c757c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Create support for AI/ML API - a model aggregate provider\n\nDescription: Hi! I'm Sergey from the Integrations team over at AI/ML API, a startup with 150K+ users, providing over 300 AI models in one place. We've had a couple of hackathons with you guys in SF too :) Your project looks dope, so we'd like to have a native integration with it.We already got integrations with Langflow, Agno, and AutoGPT - so our integrations team is pretty seasoned Say you're interested, and we'll test the compatibility, update the code/docs to include us, create a PR and add a tutorial on using AI-Hedge-Fund with AI/ML API to our docs\n\nState: open\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 732, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "726037ce-8269-413a-ba6f-1f5ab6b5f0a9", "embedding": null, "metadata": {"issue_id": 338, "title": "ModuleNotFoundError: No module named 'app.backend'; 'app' is not a package", "state": "open", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "00482dfa-3f82-4f1c-b88a-2c96f33a70c0", "node_type": "4", "metadata": {"issue_id": 338, "title": "ModuleNotFoundError: No module named 'app.backend'; 'app' is not a package", "state": "open", "labels": ["bug"], "type": "issue"}, "hash": "e2aa35eb875dffe77ff80c6ddc7e3a3254c35c5d0ceb3c8d62534ae29666d7f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: ModuleNotFoundError: No module named 'app.backend'; 'app' is not a package\n\nDescription: **Describe the bug** ModuleNotFoundError: No module named 'app.backend'; 'app' is not a package **Screenshot** Add a screenshot of the bug to help explain your problem. !Image **Additional context** (rag_test) [root@nc9007023 backend]pwd /root/old_stock/ai-hedge-fund/app/backend (rag_test) [root@nc9007023 backend]poetry run uvicorn main:app --reload\n\nState: open\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 526, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "360639b7-58f6-4a1c-953a-1e95ab22bc5f", "embedding": null, "metadata": {"issue_id": 337, "title": "can use other finance data source?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e96d98fe-3535-4264-8ecb-ac224f574c1e", "node_type": "4", "metadata": {"issue_id": 337, "title": "can use other finance data source?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "6d1b53a6928b4e6c2bda49730ac3558eb943437916a65225a5809d4ffd13c370", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: can use other finance data source?\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen. can I request an enhancement to support other finance data source like some other open data?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 352, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "898bd2ed-8e46-4a49-bae0-99ccc9123dc1", "embedding": null, "metadata": {"issue_id": 336, "title": "why use poetry?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ada62807-5128-4a81-99cb-30775d6de5a5", "node_type": "4", "metadata": {"issue_id": 336, "title": "why use poetry?", "state": "closed", "labels": [], "type": "issue"}, "hash": "10928af335c35f02c10dee3d2bf3d63d9c74ca6307523188f75f0a66b3988955", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: why use poetry?\n\nDescription: Why did the author choose to use Poetry? I've never managed project environments with Poetry before. Seeing that this project uses Poetry, I'm very interested\u2014what made you decide to adopt Poetry?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 248, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "403550a0-7f95-49e6-957a-4d1918cfbbb8", "embedding": null, "metadata": {"issue_id": 335, "title": "How to use the UI in this project?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8ad13412-7cc1-4052-9932-f7e246931288", "node_type": "4", "metadata": {"issue_id": 335, "title": "How to use the UI in this project?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "1bd8cdf9a140781de915f7b390cf4d766bd234e62016641a70799c586e6c3973", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How to use the UI in this project?\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen. I had saw Viratt useed UI of this project on X post. WO can share how to do it?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 339, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "518cfb04-2770-4572-bf19-384aed8e3d15", "embedding": null, "metadata": {"issue_id": 333, "title": "Exception: Error fetching data: MSFT - 429 - {\"detail\":\"Request was throttled. Expected available in 9 seconds.\"}", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2969aefc-e0d6-4557-b96f-cd663a404fc4", "node_type": "4", "metadata": {"issue_id": 333, "title": "Exception: Error fetching data: MSFT - 429 - {\"detail\":\"Request was throttled. Expected available in 9 seconds.\"}", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "07a02d3fce4f6590d59cb9b0c25d0d55323a325ebdbaf6cc341846a396301143", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Exception: Error fetching data: MSFT - 429 - {\"detail\":\"Request was throttled. Expected available in 9 seconds.\"}\n\nDescription: [CODE_BLOCK]\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 228, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "492369a4-f2cb-4840-9309-d17d1aee4316", "embedding": null, "metadata": {"issue_id": 332, "title": "How to output inference processing details instead of only \"No trading decisions available\"", "state": "open", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4a23cfb-997b-4a74-beb8-e8795a13e9c7", "node_type": "4", "metadata": {"issue_id": 332, "title": "How to output inference processing details instead of only \"No trading decisions available\"", "state": "open", "labels": ["enhancement"], "type": "issue"}, "hash": "b642f8a3369ba07df49f0e90ae81f371c130fda7d348f553b15cf2943aa29b8c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How to output inference processing details instead of only \"No trading decisions available\"\n\nDescription: After a long run only return this not very friendly\n\nState: open\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 270, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "3bb0df48-6f6f-4fdf-a705-1e500c353795", "embedding": null, "metadata": {"issue_id": 330, "title": "DeepWiki Enablement", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ec9bfae8-2d8f-41bd-8bdc-5551e92ff8f7", "node_type": "4", "metadata": {"issue_id": 330, "title": "DeepWiki Enablement", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "3458b396d2d6e1143e103ffaf0690d2304debbf1fb8ffad78b148185fcd71a9d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: DeepWiki Enablement\n\nDescription: Hey! You should add the DeepWiki badge to the README so the DeepWiki page for this repository is refreshed weekly. It would be super helpful for helping viewers digest new material and follow along with developments. Read more here. Badge Markdown: ![Ask DeepWiki](https://deepwiki.com/virattt/ai-hedge-fund)\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 457, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f4faf22c-17ab-4b6b-a521-ea3bb7cac8aa", "embedding": null, "metadata": {"issue_id": 326, "title": "No module named 'src'", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e2249fbc-8d94-4e2c-9931-a5815432f532", "node_type": "4", "metadata": {"issue_id": 326, "title": "No module named 'src'", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "eb1508cfeeece3c606fd43ded68eea3f91b571572765e5c997a81a41799b0743", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: No module named 'src'\n\nDescription: I only use PyCharm to run main.py,not use docker, also have a issue, can not find src module, and log as below, /Users/yizhang/program/anaconda/anaconda3/python.app/Contents/MacOS/python /Users/yizhang/Documents/GitHub/ai-hedge-fund/src/main.py Traceback (most recent call last): File \"/Users/yizhang/Documents/GitHub/ai-hedge-fund/src/main.py\", line 8, in from src.agents.portfolio_manager import portfolio_management_agent ModuleNotFoundError: No module named 'src' and how to fix it,Thanks And also I saw someone use docker to run main.py and also met this issue.Also we saw that issue is fixed\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 721, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "fcadf1a5-1582-43ba-a92b-4333dd83af96", "embedding": null, "metadata": {"issue_id": 325, "title": "Can you introduce MCP server", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4fbaba6d-3bef-4e4f-900f-e50ee0b61a8b", "node_type": "4", "metadata": {"issue_id": 325, "title": "Can you introduce MCP server", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "3290626e4d8d2588718b0e573da704b8115a5e286dfd6d0b5dd20005f5efbec8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Can you introduce MCP server\n\nDescription: Introduction of MCP server to this Agentic AI framework will help a lot like we can plug in lots of API for data and different LLM providers like badrock and all and also can automate the buying selling work flow.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 371, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "7dacf040-ce5b-4115-b359-ee0c09cad977", "embedding": null, "metadata": {"issue_id": 323, "title": "can not get data", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9a63d4a2-810b-474f-b5b1-556f05cf8a41", "node_type": "4", "metadata": {"issue_id": 323, "title": "can not get data", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "881e9b6c1a049d76b566949196920f29e0e1093c70121b8f807f76d99a7ab8fe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: can not get data\n\nDescription: **Describe the bug** i run poetry run python src/main.py --ticker BABA then i get the screenshot below, deepseek api and financialdatasets.ai api is available\u3002 **Screenshot** Add a screenshot of the bug to help explain your problem. <img width=\"906\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3986d081-d217-4b80-8f34-0b64fb1c2a21\" /> **Additional context** Add any other context about the problem here.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 538, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8cf5d132-5fbf-456f-86dc-8069fdfc193b", "embedding": null, "metadata": {"issue_id": 322, "title": "\u662f\u5426\u4e5f\u53ef\u4ee5\u628aBTC \u8fd9\u4e9b\u865a\u62df\u8d27\u5e73\u53f0\u7684\u4e5f\u52a0\u4e0a", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b3913d8f-1113-4009-b182-c4e3aad32e89", "node_type": "4", "metadata": {"issue_id": 322, "title": "\u662f\u5426\u4e5f\u53ef\u4ee5\u628aBTC \u8fd9\u4e9b\u865a\u62df\u8d27\u5e73\u53f0\u7684\u4e5f\u52a0\u4e0a", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "75986a4841c050dd36f7029fdf9b752d936e2376cac17281fc6d2681eb32e1aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: \u662f\u5426\u4e5f\u53ef\u4ee5\u628aBTC \u8fd9\u4e9b\u865a\u62df\u8d27\u5e73\u53f0\u7684\u4e5f\u52a0\u4e0a\n\nDescription: \u662f\u5426\u4e5f\u53ef\u4ee5\u628aBTC \u8fd9\u4e9b\u865a\u62df\u8d27\u5e73\u53f0\u7684\u4e5f\u52a0\u4e0a\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 172, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "27ad5620-7759-43ca-875c-52dd5f4452c6", "embedding": null, "metadata": {"issue_id": 321, "title": "500 server error on search/line-items endpoint of financialdatasets api", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8ba912a4-3fbc-4ce4-8d5c-8985fa1d611c", "node_type": "4", "metadata": {"issue_id": 321, "title": "500 server error on search/line-items endpoint of financialdatasets api", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "7c281ebcac0da9bc56dbb65d99579660d10b9067c3c8875f673e466d7b78e77c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: 500 server error on search/line-items endpoint of financialdatasets api\n\nDescription: **Describe the bug** Getting 500 server error for all financial analysts because of the search/line-items endpoint on financialdatasets api. Even doing a curl request doesn't work. Other endpoints work fine it seems. **Screenshot** <img width=\"927\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9eafb59e-6de3-4dd5-a25e-ca5def45b79e\" />\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 523, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "74500909-7431-415a-b262-a6c7a7808ed5", "embedding": null, "metadata": {"issue_id": 320, "title": "how to use other api key,such as moonshot ai, glm-4, deepseek\uff0cetc", "state": "open", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e337d098-0166-4c3d-be3c-b93fb03dd6ee", "node_type": "4", "metadata": {"issue_id": 320, "title": "how to use other api key,such as moonshot ai, glm-4, deepseek\uff0cetc", "state": "open", "labels": [], "type": "issue"}, "hash": "2ffce9b8985cc4a7ba65cfaa823e924bac211ac4a4ef98e32fd2e3fe1cf1d2c7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: how to use other api key,such as moonshot ai, glm-4, deepseek\uff0cetc\n\nDescription: \n\nState: open", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 100, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8215b214-dc4e-4cf0-a379-43294aa0ca34", "embedding": null, "metadata": {"issue_id": 319, "title": "about Financial Datasets API", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e52ea2ac-83e4-4de0-aba8-da6c0f24146e", "node_type": "4", "metadata": {"issue_id": 319, "title": "about Financial Datasets API", "state": "closed", "labels": [], "type": "issue"}, "hash": "577e6d838418838ababf17710c79cb073bc3e3bc9e39efdff88f7ae290075c60", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: about Financial Datasets API\n\nDescription: does this project work without Financial Datasets API premium? any free alternative?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 149, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "651a264d-c65e-474b-967c-b7c423408f5c", "embedding": null, "metadata": {"issue_id": 318, "title": "Cannot find some existing stocks", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6d8e2082-c799-416d-b276-49d086d6fd94", "node_type": "4", "metadata": {"issue_id": 318, "title": "Cannot find some existing stocks", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "99930650927c3aa9f5ad49e4597fbf2da71015f888766ab15c8c918c96280828", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Cannot find some existing stocks\n\nDescription: **Describe the bug** I am using docker by running \"./run.sh --ticker PONY main\". PONY is an existing stock but the API cannot find it. Error description: File \"/app/src/tools/api.py\", line 79, in get_financial_metrics raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\") Exception: Error fetching data: PONY - 400 - {\"error\":\"Invalid TICKER\",\"message\":\"Please provide a valid TICKER.\"} Is there any limitation for your api datasets?\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 607, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "1def61d7-ae58-4e03-be46-d2ccd2ae9e72", "embedding": null, "metadata": {"issue_id": 313, "title": "The application should print the output when one of the select agents failed.", "state": "open", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c7f3e5a1-e657-4ccd-8cc3-2e92e094cc3e", "node_type": "4", "metadata": {"issue_id": 313, "title": "The application should print the output when one of the select agents failed.", "state": "open", "labels": ["enhancement"], "type": "issue"}, "hash": "40f3553036ddd5b84e755d4a0d7ea1746e8feb28d817f0153e24759141d90157", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: The application should print the output when one of the select agents failed.\n\nDescription: When select multiple agents, when one of the agents run with failure, it shouldn't break the application. Instead, it should print the LLM output of other agents. Currently, the application just failed without valid output.\n\nState: open\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 428, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a105e532-0d8d-4fc2-9cb2-78809a3916d1", "embedding": null, "metadata": {"issue_id": 312, "title": "Rate limits", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3562e68d-e354-429b-84cd-833c4a5b81d3", "node_type": "4", "metadata": {"issue_id": 312, "title": "Rate limits", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "be69bfd86887520a9167a430c8c0e1ec9ea6987e1ea734cd0801561983060131", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Rate limits\n\nDescription: **I recommend adding a small sleep at line 252 in the api code for 45 seconds to avoid the process failing due to the rate limiter.** response = requests.get(url, headers=headers) if response.status_code == 429: print(f\"Rate limited for {ticker} waiting 45 seconds before fetching again\") time.sleep(45)\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 417, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "27418b5e-3248-414a-9887-38352f1d01aa", "embedding": null, "metadata": {"issue_id": 308, "title": "get price 404", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a08d0674-2a41-4142-af4f-f5f246f69ea7", "node_type": "4", "metadata": {"issue_id": 308, "title": "get price 404", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "642073ed4a7a8dff48e3ee8add57db851ac2931278d617575c5a4ad18f571e90", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: get price 404\n\nDescription: Traceback (most recent call last): File \"/app/src/main.py\", line 311, in <module> result = run_hedge_fund( ^^^^^^^^^^^^^^^ File \"/app/src/main.py\", line 66, in run_hedge_fund final_state = agent.invoke( ^^^^^^^^^^^^^ File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 1929, in invoke for chunk in self.stream( File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 1649, in stream for _ in runner.tick( File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py\", line 105, in tick run_with_retry(t, retry_policy, writer=writer) File \"/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py\", line 44, in run_with_retry task.proc.invoke(task.input, config) File \"/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 410, in invoke input = context.run(step.invoke, input, config, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 184, in invoke ret = context.run(self.func, input, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/app/src/agents/risk_manager.py\", line 25, in risk_management_agent prices = get_prices( ^^^^^^^^^^^ File \"/app/src/tools/api.py\", line 42, in get_prices raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\") Exception: Error fetching data: AAPL - 404 - {\"error\":\"No data found\",\"message\":\"No prices found for AAPL\"} During task with name 'risk_management_agent' and id '07e8c5dd-54b9-c792-fad1-ac6ba0c2c5bb'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1693, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ea29a8f4-3cb7-4756-9bc1-41e73fc91928", "embedding": null, "metadata": {"issue_id": 307, "title": "Failed to obtain \"price\" from financialdatasets.ai", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dfda7a77-61cb-4e7a-a8e1-74d9a27192d6", "node_type": "4", "metadata": {"issue_id": 307, "title": "Failed to obtain \"price\" from financialdatasets.ai", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "c4f42d4c7b8718dc794870cec32dc594607d2130466ccd1e03515d21447120d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Failed to obtain \"price\" from financialdatasets.ai\n\nDescription: <img width=\"820\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a91fcd97-6c8a-4912-97df-d8eb0f293419\" /> <img width=\"939\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/fa4c6132-2943-4f4c-a764-84b0d0263cab\" /> There is an error when trying to obtain the price of the MSFT.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 451, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "3678a70a-8159-416a-9680-fe98f7b43c02", "embedding": null, "metadata": {"issue_id": 305, "title": "US stockes BABA not supported", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f78a81ec-6617-4de7-a734-f30103bb3df7", "node_type": "4", "metadata": {"issue_id": 305, "title": "US stockes BABA not supported", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "20ed536038f9e802b7f1198fc8552c6d9b54ff8fd12310a87fb2908d9d8d12cd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: US stockes BABA not supported\n\nDescription: **Describe the bug** run poetry run python src/main.py --ticker BABA **Screenshot** <img width=\"940\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/843e9d52-f22d-4415-be42-8562f1310f0b\" />\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 333, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "288d6403-05cc-4a3d-8bc7-fdf38c78087a", "embedding": null, "metadata": {"issue_id": 302, "title": "run  failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "741c1019-8df2-401b-86d9-d261a9812876", "node_type": "4", "metadata": {"issue_id": 302, "title": "run  failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "07090c440fa762b8af7e7e22b02fb258ff32e611423e8d9b04a0a39ca29d3070", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "57df0c4b-e940-4240-b658-b67b671db9f9", "node_type": "1", "metadata": {}, "hash": "23421a50d33fd2a493491ef49530f55f9f806d42c5e726d61e31eefdf2bbf4e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: run  failed\n\nDescription: docker env ./run.sh build Detected Apple Silicon (M-series) - Metal GPU acceleration should be enabled [+] Building 118.9s (11/11) FINISHED docker:desktop-linux => [internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 534B 0.0s => [internal] load metadata for docker.io/library/python:3.11-slim 4.4s => [internal] load .dockerignore 0.0s => => transferring context: 304B 0.0s => [1/6] FROM docker.io/library/python:3.11-slim@sha256:705758cf20852ac194bd599084b5dbcecace1ca08ef88e0437c2d29b547247de 30.0s => => resolve docker.io/library/python:3.11-slim@sha256:705758cf20852ac194bd599084b5dbcecace1ca08ef88e0437c2d29b547247de 0.0s => => sha256:ea2bf1a9fc56bd9904263534a315b2493a81724fe20fe81a695012d45bc3ab43 1.75kB / 1.75kB 0.0s => => sha256:277bcd31f17f0de7684e81ae149309e939bc6169931ee771a716b839325a393c 5.39kB / 5.39kB 0.0s => => sha256:b16f1b16678093d11ecfece1004207a40f9bc1b7d9d1d16a070c1db552038818 28.07MB / 28.07MB 28.2s => => sha256:8a45c7e905d6f25747fdf1b9286ccaf78e53af421e86800be363fac2c5e17386 3.33MB / 3.33MB 4.9s => => sha256:b7c08fd34265f32576e55c9dddd9f235b8b7f60fd6444cf617d7b15d08b2273a 16.13MB / 16.13MB 26.5s => => sha256:705758cf20852ac194bd599084b5dbcecace1ca08ef88e0437c2d29b547247de 9.13kB / 9.13kB 0.0s => => sha256:92fbff4eeba45536c25e921782477b78ed2f0017f075066d2da8420ca9df42a3 248B / 248B 5.4s => => extracting sha256:b16f1b16678093d11ecfece1004207a40f9bc1b7d9d1d16a070c1db552038818 1.0s => => extracting sha256:8a45c7e905d6f25747fdf1b9286ccaf78e53af421e86800be363fac2c5e17386 0.1s => => extracting sha256:b7c08fd34265f32576e55c9dddd9f235b8b7f60fd6444cf617d7b15d08b2273a 0.6s => => extracting sha256:92fbff4eeba45536c25e921782477b78ed2f0017f075066d2da8420ca9df42a3 0.0s => [internal] load build context 0.0s => => transferring context: 1.29MB 0.0s => [2/6] WORKDIR /app 0.2s => [3/6] RUN pip install poetry==1.7.1 27.0s => [4/6] COPY pyproject.toml poetry.lock* /app/ 0.0s => [5/6] RUN poetry config virtualenvs.create false && poetry install --no-interaction --no-ansi 56.3s => [6/6] COPY .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2085, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "57df0c4b-e940-4240-b658-b67b671db9f9", "embedding": null, "metadata": {"issue_id": 302, "title": "run  failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "741c1019-8df2-401b-86d9-d261a9812876", "node_type": "4", "metadata": {"issue_id": 302, "title": "run  failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "07090c440fa762b8af7e7e22b02fb258ff32e611423e8d9b04a0a39ca29d3070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "288d6403-05cc-4a3d-8bc7-fdf38c78087a", "node_type": "1", "metadata": {"issue_id": 302, "title": "run  failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "58f9950e7928ee2045190d2367208b97f7bbbdd3ad4bff255d13586b96055e92", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/app/ 0.0s => exporting to image 1.0s => => exporting layers 1.0s => => writing image sha256:e0766ccd67c86f25e7af7d743fbfcbce89bbd12cead11cc9cda56080fbf7c0b9 0.0s => => naming to docker.io/library/ai-hedge-fund 0.0s View build details: docker-desktop://dashboard/build/desktop-linux/desktop-linux/eqbqjovkn3reic08os6yvi784 What's next: View a summary of image vulnerabilities and recommendations \u2192 docker scout quickview \u279c ai-hedge-fund git:(main) ./run.sh --ticker AAPL,MSFT,NVDA main Detected Apple Silicon (M-series) - Metal GPU acceleration should be enabled Running: docker run -it --rm -v /Users/chenxy/python/ai-hedge-fund/.env:/app/.env ai-hedge-fund python src/main.py --ticker AAPL,MSFT,NVDA --initial-cash 100000.0 --margin-requirement 0.0 Traceback (most recent call last): File \"/app/src/main.py\", line 8, in <module> from src.agents.portfolio_manager import portfolio_management_agent ModuleNotFoundError: No module named 'src'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 2086, "end_char_idx": 3108, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "db015ce1-c146-4b73-9ea6-4d7627f5c9ae", "embedding": null, "metadata": {"issue_id": 300, "title": "mac docker: invalid reference format", "state": "open", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7d2c5ff5-fe40-46c3-ba46-1aa6faaf4e3c", "node_type": "4", "metadata": {"issue_id": 300, "title": "mac docker: invalid reference format", "state": "open", "labels": ["bug"], "type": "issue"}, "hash": "9bf424ab0d050f2e0585485a64c9f6831e655f431238d05b9eea425491f72df1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: mac docker: invalid reference format\n\nDescription: **Describe the bug** run docker on mac (base) huayuqin@Huayus-MacBook-Pro ai-hedge-fund % ./run.sh --ticker AAPL,MSFT,NVDA main Detected Apple Silicon (M-series) - Metal GPU acceleration should be enabled Running: docker run -it --rm -v /Users/huayuqin/github repos/ai-hedge-fund/.env:/app/.env ai-hedge-fund python src/main.py --ticker AAPL,MSFT,NVDA --initial-cash 100000.0 --margin-requirement 0.0 docker: invalid reference format. See 'docker run --help'. **Screenshot** <img width=\"1050\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/827588a1-f80a-4f2f-8410-aa874326e995\" /> **Additional context** follow instruction ./run.sh build and ./run.sh --ticker AAPL,MSFT,NVDA main has add [CODE_BLOCK] in Dockerfile\n\nState: open\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 864, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b4ee0787-50b5-47f1-9dca-048707d2ee6c", "embedding": null, "metadata": {"issue_id": 299, "title": "Error in analysis, using default", "state": "open", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "83ec5fa2-4be5-4783-8005-d58c13a1bdc0", "node_type": "4", "metadata": {"issue_id": 299, "title": "Error in analysis, using default", "state": "open", "labels": ["bug"], "type": "issue"}, "hash": "0563b0e75acfb03e70b3907831287dbf584aa7ea0d9fc0d3cfe9150f7fa04852", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Error in analysis, using default\n\nDescription: **Describe the bug** i try to analysis TSLA, but get this \"Error in analysis\"\uff0cwhat exactly happend\uff1fno more error info has been released **Screenshot** <img width=\"603\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cdd1746c-e897-409f-a57b-2cee877fba7e\" /> **Additional context** I use Warren Buffett and deepseek-r1\n\nState: open\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 461, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9a940ae7-33ba-4b7c-83a3-4e0eabfca0bf", "embedding": null, "metadata": {"issue_id": 298, "title": "How does the portfolio manager know your current positions", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6dfc2d2c-f2ba-4629-8ef2-d99364f3647b", "node_type": "4", "metadata": {"issue_id": 298, "title": "How does the portfolio manager know your current positions", "state": "closed", "labels": [], "type": "issue"}, "hash": "99aff0af4f86ffa07f53b843e59c4d741c4048f47e89de63e45b60344d0ed66d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How does the portfolio manager know your current positions\n\nDescription: Not sure if I missed something but I was digging through code/docs to try to see how to let the agent know an existing portfolio (i.e xxxxx shares of YYYY bought at ZZZ) rather than just passing starting cash and a margin, but can't seem to find these info. Is this something that isn't implemented?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 394, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "17f7769f-accc-4061-9385-0080b6388c9b", "embedding": null, "metadata": {"issue_id": 297, "title": "Error Handling in run_graph", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d4a5b6aa-4056-496d-bb2d-385e0d9ddd85", "node_type": "4", "metadata": {"issue_id": 297, "title": "Error Handling in run_graph", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "7ee9d3f4fee36681c4ac15c2eb3a38fd818788bdacb9b0511ad455e3e46b7cf1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Error Handling in run_graph\n\nDescription: The code appears well-structured and implements a LangGraph workflow for managing a portfolio with risk assessment. However, there are a few areas that could be improved: 1.**: The run_graph function doesn't handle potential exceptions during the graph.invoke call. It's recommended to add a try-except block to catch and log any errors during the graph execution. 2. **Parameter validation**: Consider adding parameter validation within run_graph and create_graph to ensure correct types are being passed and that parameters such as tickers and selected_agents are not empty when they should not be. 3. **Clarity of Analyst Node Creation**: The creation of analyst_nodes is a bit dense. Consider breaking this down into smaller steps for readability, especially if the configuration is complex. 4. **start function**: The code uses a start function imported from src.main, but there is no context on what the function does. Without this context, it's difficult to review. It is being used as a node in the graph, so it probably has a defined input and output. This information might be relevant for a more in-depth review. 5. **Type Hints**: While type hints are used, they can be more comprehensive, especially within run_graph function. Adding return type hint will improve code clarity. 6. **Asyncio Best Practices**: The use of asyncio.get_running_loop() is generally fine, but consider using asyncio.to_thread in Python 3.9+ as it's slightly more concise and recommended for running synchronous functions in a separate thread within an async context. code is here... ``python import asyncio import json from typing import List, Dict, Any from langchain_core.messages import HumanMessage from langgraph.graph import END, StateGraph from src.agents.portfolio_manager import portfolio_management_agent from src.agents.risk_manager import risk_management_agent from src.main import start from src.utils.analysts import ANALYST_CONFIG from src.graph.state import AgentState Helper function to create the agent graph def create_graph(selected_agents: List[str]) -> StateGraph: \"\"\"Create the workflow with selected agents.\"\"\" graph = StateGraph(AgentState) graph.add_node(\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2301, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c84ea675-896c-4be0-a653-eb7a16bdedf3", "embedding": null, "metadata": {"issue_id": 296, "title": "Error handling in get_start_date", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5965a80c-19a3-49cb-88b8-487682360611", "node_type": "4", "metadata": {"issue_id": 296, "title": "Error handling in get_start_date", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "3fb02a5f6ddfd8e5ab642748ab6b51422f7d1e01d0d0033059e042414d3d107f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Error handling in get_start_date\n\nDescription: The code appears to be well-structured and follows good practices. However, there are a couple of minor points to consider: 1. **Error Handling in get_start_date:** The get_start_date method assumes that self.end_date is always in the correct format (%Y-%m-%d). If self.end_date is invalid, it will raise a ValueError. Adding a try-except block to handle potential ValueError would improve robustness. 2. **Default Value for start_date:** Currently, if start_date is not provided, the code calculates it by subtracting 90 days from the end_date. Consider making this calculation directly within the Field definition for start_date using default_factory. This can simplify the logic and improve readability. code is here.... from datetime import datetime, timedelta from pydantic import BaseModel, Field from typing import List, Optional from src.llm.models import ModelProvider class HedgeFundResponse(BaseModel): decisions: dict analyst_signals: dict class ErrorResponse(BaseModel): message: str error: str | None = None class HedgeFundRequest(BaseModel): tickers: List[str] selected_agents: List[str] end_date: Optional[str] = Field(default_factory=lambda: datetime.now().strftime(\"%Y-%m-%d\")) start_date: Optional[str] = Field(default_factory=lambda: (datetime.now() - timedelta(days=90)).strftime(\"%Y-%m-%d\")) model_name: str = \"gpt-4o\" model_provider: ModelProvider = ModelProvider.OPENAI initial_cash: float = 100000.0 margin_requirement: float = 0.0\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1591, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "04072561-a816-4daa-a699-32d21cbd4176", "embedding": null, "metadata": {"issue_id": 295, "title": "API Throttling (429) Error when Fetching Data for Multiple Tickers", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4e08212-d1b3-498d-abc3-8f6df91b7ec9", "node_type": "4", "metadata": {"issue_id": 295, "title": "API Throttling (429) Error when Fetching Data for Multiple Tickers", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "1709cc0b2f4fb94919837be683d4fd88a25fd7fde564d2f49b2525b6b07aaa10", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: API Throttling (429) Error when Fetching Data for Multiple Tickers\n\nDescription: **Describe the bug** When running the hedge fund with multiple tickers, the application hits the API rate limit of financialdatasets.ai, resulting in repeated 429 Too Many Requests errors. This prevents agents (e.g., aswath_damodaran_agent, michael_burry_agent) from completing their tasks. The system does not have sufficient throttling, queueing, or retry backoff to gracefully handle this. **Screenshot** [CODE_BLOCK] **Additional context** Occurs when running 5 or more tickers at once\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 658, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b9a1be8b-4237-4323-9780-9c263502e0d5", "embedding": null, "metadata": {"issue_id": 294, "title": "support china ticker", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "381d3318-f3a0-438d-8d03-c5f6dcbd88a6", "node_type": "4", "metadata": {"issue_id": 294, "title": "support china ticker", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "88142917cd11087caa1ce867e29990928e95ef25267358b38428a27f852e6ad9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: support china ticker\n\nDescription: Could you please extend the currently supported stock markets to include not only the U.S. Nasdaq market, but also China's Shanghai and Shenzhen stock exchanges?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 311, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "99363bea-f1c9-43df-b66b-d0789f7dc016", "embedding": null, "metadata": {"issue_id": 292, "title": "Test AI", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "008e9c71-983f-4752-b351-231b99e4bc56", "node_type": "4", "metadata": {"issue_id": 292, "title": "Test AI", "state": "closed", "labels": [], "type": "issue"}, "hash": "a470f3b11737ac9ebc4e40a39c265efe4585d2bd1d32101aa44dd3d2cd1ab57c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Test AI\n\nDescription: Test AI agents\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 58, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a7be8d17-dd31-42d9-bdb9-b1e31ff70078", "embedding": null, "metadata": {"issue_id": 291, "title": "ModuleNotFoundError: No module named 'src'", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1e34f418-f997-4671-b1e3-5542116b7696", "node_type": "4", "metadata": {"issue_id": 291, "title": "ModuleNotFoundError: No module named 'src'", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "87d207345bd5c70951a95d74bfb73536b141b250a1a730efde57ffc848a718b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: ModuleNotFoundError: No module named 'src'\n\nDescription: **Describe the bug** Just cloned the project and created the env file only with the OpenAI key, followed the steps to create the docker image and run it using the commands, and got the error that it could not find the src folder. **Screenshot** <img width=\"883\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7ffffdbe-f1fb-4538-b5d7-68512493473c\" /> **Additional context** Did not insert the financial datasets into the .env file and left the default placeholders for everything except the OpenAI key.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 659, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ac94e20f-dc19-412d-9f7b-da079f34301d", "embedding": null, "metadata": {"issue_id": 288, "title": "add openrouter api support.", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9403f561-7299-4df4-b268-e2998a66fdda", "node_type": "4", "metadata": {"issue_id": 288, "title": "add openrouter api support.", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "5e3f7ffe450fb9c02f47665955c391629656733aa495100d4ec29df23fce5a96", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: add openrouter api support.\n\nDescription: add openrouter api support for free api keys.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 202, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ee728f30-f016-4a7d-b08e-3d248e47a0d5", "embedding": null, "metadata": {"issue_id": 287, "title": "Anyone making money", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1ed761ee-02d5-4c9b-981a-58f12cfa34c0", "node_type": "4", "metadata": {"issue_id": 287, "title": "Anyone making money", "state": "closed", "labels": [], "type": "issue"}, "hash": "d61b147f43581b44b3a324dd92dd6ede8cf4c50e9fefe6d2808f026431c0c9bd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Anyone making money\n\nDescription: Bois I am wondering, is there anyone making money from this? Thanks a lot! A virtual hug <3\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 147, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "0151e754-fa2d-4cb3-9d79-406957ff6fd5", "embedding": null, "metadata": {"issue_id": 286, "title": "stat /root/docker/ai-hedge-fund/docker-compose.nvidia.yml: no such file or directory", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5f07e2a7-1e61-4cd1-9558-696674f8ff78", "node_type": "4", "metadata": {"issue_id": 286, "title": "stat /root/docker/ai-hedge-fund/docker-compose.nvidia.yml: no such file or directory", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "0e45513d9e0292bcb0c70b10f2ad78edb82ccadb2fc0090de10f7e9b697394cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: stat /root/docker/ai-hedge-fund/docker-compose.nvidia.yml: no such file or directory\n\nDescription: **Describe the bug** Running AI Hedge Fund with Ollama using Docker Compose... stat /root/docker/ai-hedge-fund/docker-compose.nvidia.yml: no such file or directory **Screenshot** !Image **Additional context** Running in a debian lxc in proxmox. Just trying to do a basic run for testing purposes following the readme. I have ollama installed and verified, nvidia-smi installed and verified. Seems like there's a docker compose file missing. I searched open/closed issues and didn't see this. Thanks.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 686, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "987b17b4-55bd-4e00-8a15-c6370467ee45", "embedding": null, "metadata": {"issue_id": 285, "title": "Enable discussions tabs for this repo on github", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d4e4a52f-d890-418f-9fbf-42f1690fa2ca", "node_type": "4", "metadata": {"issue_id": 285, "title": "Enable discussions tabs for this repo on github", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "ed9d98d16369d5aeaa201f2d2774eed98422236ba6d736cbe95691392e0e271d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Enable discussions tabs for this repo on github\n\nDescription: **Describe the feature you'd like** Opening discussions tabs will declutter most of the open issues as general issues such as those related to installations can be discussed there\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 356, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "df88bc7e-1fab-4a03-bdb2-3ced5c7c8b29", "embedding": null, "metadata": {"issue_id": 283, "title": "Ticker for Indian companies", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b7dcebfa-db3f-47c9-9fa4-f1baa5f8f9fb", "node_type": "4", "metadata": {"issue_id": 283, "title": "Ticker for Indian companies", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "30e79ba2856a8a5f54e42144c753bd553c63c86420e6c065d723f0ac4880ff3e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Ticker for Indian companies\n\nDescription: Please could you provide support for Indian companies ?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 212, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6bf816bc-4a97-449e-8f83-848a43ed39e0", "embedding": null, "metadata": {"issue_id": 280, "title": "Bug Report: Floating Point Precision Issue in Sentiment Agent Confidence Score", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9063b190-0d47-4ff9-91d4-ed1d162f4a11", "node_type": "4", "metadata": {"issue_id": 280, "title": "Bug Report: Floating Point Precision Issue in Sentiment Agent Confidence Score", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "d175aafd605f27240890920d1353bc9844d5834a37724620ee59c5b3c955bf2a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Bug Report: Floating Point Precision Issue in Sentiment Agent Confidence Score\n\nDescription: **Describe the bug** The confidence score for the \"Sentiment\" agent is displaying a floating-point precision issue, showing an excessive number of decimal places. In the provided screenshot, the confidence is 56.00000000000001 % instead of a more rounded value like 56.0%. **Screenshot** <img width=\"931\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8a2eb134-43b7-4a35-bead-5efa2caba117\" /> **Additional context** N/A\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 613, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "80135c7d-637c-4a14-934b-5ce628b1f694", "embedding": null, "metadata": {"issue_id": 279, "title": "ollama qwen3 needs more rules of def extract_json_from_response()", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5516edfc-c3ab-46e1-9f77-2876d75f2891", "node_type": "4", "metadata": {"issue_id": 279, "title": "ollama qwen3 needs more rules of def extract_json_from_response()", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "92d9210664bd85e64a9908eae4c3d83c74f1634c2db96fd776e129285a7c5a21", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: ollama qwen3 needs more rules of def extract_json_from_response()\n\nDescription: **Describe the bug** ollama qwen3 seems not to response json in \"[CODE_BLOCK]\" pairs.(Could be {} raw json) A more compatible def: [CODE_BLOCK]json ... [CODE_BLOCK]json ... CODE_BLOCK?\\s*([\\s\\S]*?)\\s*[CODE_BLOCK]\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 380, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4fdd5d5e-8c4f-409a-b960-50ed7f9ace8d", "embedding": null, "metadata": {"issue_id": 278, "title": "how about add Trump's twitter analysis", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8336c051-f3bd-481f-956e-2104158cd05e", "node_type": "4", "metadata": {"issue_id": 278, "title": "how about add Trump's twitter analysis", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "26255c208dec2975fb12b4ee959608b1f4983eb9e5a3da98ce9296e75721beb6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: how about add Trump's twitter analysis\n\nDescription: Add the function of Trump\u2018s twitter analysis to predict the trend of the stock index\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 252, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "18950f23-b471-428b-afc9-bf65a094aecf", "embedding": null, "metadata": {"issue_id": 277, "title": "bug report", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b6056a1c-7ca1-458c-93cc-adf4d1070976", "node_type": "4", "metadata": {"issue_id": 277, "title": "bug report", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "566b7b516cb2462550666d8f6718fc73c34613dbb7d802469ba63f31f1633945", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: bug report\n\nDescription: **Describe the bug** A clear and concise description of what the bug is. **Screenshot** Add a screenshot of the bug to help explain your problem. **Additional context** Add any other context about the problem here. https://vivalaskin.in/ https://sirmor.com/\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 370, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e65eb16c-3cf6-4425-8f14-a9c6b6ab1054", "embedding": null, "metadata": {"issue_id": 276, "title": "backtester command failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dabd7560-802c-4c85-a5c4-4b9a3961a661", "node_type": "4", "metadata": {"issue_id": 276, "title": "backtester command failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "1acbdcf46456339fe8798982126390c507ef3550a9bea3fca91af854ba870acc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: backtester command failed\n\nDescription: Run command > poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA Error message as below: Traceback (most recent call last): File \"/Users/warren/ai-hedge-fund/src/backtester.py\", line 759, in <module> performance_metrics = backtester.run_backtest() File \"/Users/warren/ai-hedge-fund/src/backtester.py\", line 345, in run_backtest output = self.agent( tickers=self.tickers, ...<5 lines>... selected_analysts=self.selected_analysts, ) File \"/Users/warren/ai-hedge-fund/src/main.py\", line 66, in run_hedge_fund final_state = agent.invoke( { ...<17 lines>... }, ) File \"/Users/warren/Library/Caches/pypoetry/virtualenvs/ai-hedge-fund-8HXL_EBN-py3.13/lib/python3.13/site-packages/langgraph/pregel/__init__.py\", line 1929, in invoke for chunk in self.stream( ~~~~~~~~~~~^ input, ^^^^^^ ...<6 lines>... **kwargs, ^^^^^^^^^ ): ^ File \"/Users/warren/Library/Caches/pypoetry/virtualenvs/ai-hedge-fund-8HXL_EBN-py3.13/lib/python3.13/site-packages/langgraph/pregel/__init__.py\", line 1649, in stream for _ in runner.tick( ~~~~~~~~~~~^ loop.tasks.values(), ^^^^^^^^^^^^^^^^^^^^ ...<2 lines>... get_waiter=get_waiter, ^^^^^^^^^^^^^^^^^^^^^^ ): ^ File \"/Users/warren/Library/Caches/pypoetry/virtualenvs/ai-hedge-fund-8HXL_EBN-py3.13/lib/python3.13/site-packages/langgraph/pregel/runner.py\", line 105, in tick run_with_retry(t, retry_policy, writer=writer) ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/Users/warren/Library/Caches/pypoetry/virtualenvs/ai-hedge-fund-8HXL_EBN-py3.13/lib/python3.13/site-packages/langgraph/pregel/retry.py\", line 44, in run_with_retry task.proc.invoke(task.input, config) ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^ File \"/Users/warren/Library/Caches/pypoetry/virtualenvs/ai-hedge-fund-8HXL_EBN-py3.13/lib/python3.13/site-packages/langgraph/utils/runnable.py\", line 410, in invoke input = context.run(step.invoke, input, config, **kwargs) File \"/Users/warren/Library/Caches/pypoetry/virtualenvs/ai-hedge-fund-8HXL_EBN-py3.13/lib/python3.13/site-packages/langgraph/utils/runnable.py\", line 184, in invoke ret = context.run(self.func, input, **kwargs) File \"/Users/warren/ai-hedge-fund/src/agents/valuation.py\", line 47, in valuation_agent line_items = search_line_items( ticker=ticker, ...<9 lines>... limit=2, ) File \"/Users/warren/ai-hedge-fund/src/tools/api.py\", line 118, in search_line_items raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\") Exception: Error fetching data: AAPL - 429 - {\"detail\":\"Request was throttled. Expected available in 14 seconds.\"} During task with name 'valuation_analyst_agent' and id 'd97c1525-38a6-687b-35df-67a7ff644944'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2748, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "3ca5aa41-4d60-4ef5-9f85-bb2ae6e4db3d", "embedding": null, "metadata": {"issue_id": 272, "title": "mac docker issue", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8d110b1d-c62b-444f-b997-b19a639a55d8", "node_type": "4", "metadata": {"issue_id": 272, "title": "mac docker issue", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "09e6211e63d2946f25ef71c1506b306bae038e7b1212d75fafaf80e169c4ac27", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: mac docker issue\n\nDescription: **Describe the bug** in mac run docker ./run.sh --ticker AAPL,MSFT,NVDA main Running: docker run -it --rm -v /Users/machunyu/Desktop/2025/ai-hedge-fund/.env:/app/.env ai-hedge-fund python src/main.py --ticker AAPL,MSFT,NVDA --initial-cash 100000.0 --margin-requirement 0.0 Traceback (most recent call last): File \"/app/src/main.py\", line 8, in <module> from src.agents.portfolio_manager import portfolio_management_agent ModuleNotFoundError: No module named 'src' **Screenshot** !Image\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 604, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "489d9638-83d1-4580-82c3-860430391bcf", "embedding": null, "metadata": {"issue_id": 268, "title": "GOLD and index support", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "711276b8-cbfb-4b57-a9ab-bc9834d91f65", "node_type": "4", "metadata": {"issue_id": 268, "title": "GOLD and index support", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "ab6fd7a229f187531ac4d0074eb5125a4d38c56876efc2295ed9b9838c1e9114", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: GOLD and index support\n\nDescription: Since the Financial Assets support GOLD and index like US100, would like to see, and I'm sure I'm not alone..\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 261, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "15db55ae-26f2-4a50-961f-9fdf965e6fb7", "embedding": null, "metadata": {"issue_id": 266, "title": "Analysis based on analysts not working", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8d284c0e-aa34-403c-bede-cc34e6faba41", "node_type": "4", "metadata": {"issue_id": 266, "title": "Analysis based on analysts not working", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "cae8c8df47ec9b3767cf535b5554536afd87347c733df6f3a7b952a7cbb5ffae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Analysis based on analysts not working\n\nDescription: Solved. Just needed to change the LLM Model\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 184, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b5b4f916-811e-4d8d-94f4-126524057576", "embedding": null, "metadata": {"issue_id": 264, "title": "How to run ai-hedge-fund on win11?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1ba8ecaa-2972-4c91-a136-3f36d3a78ac2", "node_type": "4", "metadata": {"issue_id": 264, "title": "How to run ai-hedge-fund on win11?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "d93de321f8233a0015c879bae3f75b0e6ace1563c612543fca46d7d9ab864e80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How to run ai-hedge-fund on win11?\n\nDescription: Anyone can create a manual to guide us how to run ai-hedge-fund on win11? Thanks\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 244, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "dc7899c0-67df-4c24-b692-f74c47880f07", "embedding": null, "metadata": {"issue_id": 261, "title": "Prompt Reasoning Order Concern", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "88e75c00-413d-4b91-9026-7e8effd94470", "node_type": "4", "metadata": {"issue_id": 261, "title": "Prompt Reasoning Order Concern", "state": "closed", "labels": [], "type": "issue"}, "hash": "a5f566cfb6c8f54c521a3aa60bd391671c4d54768e9527cd82cbea5a6674ceb8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Prompt Reasoning Order Concern\n\nDescription: In the Warren Buffet Prompt: Return the trading signal in the following JSON format exactly: {{ \"signal\": \"bullish\" | \"bearish\" | \"neutral\", \"confidence\": float between 0 and 100, \"reasoning\": \"string\" }} It looks like the reasoning is last. My understanding is that since LLMs generate tokens sequentially, this won't actually do any reasoning that affects the decision-it will just give a signal and confidence, and then reason after the fact to justify what it said. Unless if Langchain is doing something under the hood, I think reasoning should go first for chain of thought, since then it will use the content it generates in the reasoning section when generating output for the signal and confidence. To verify it, I ran the program locally and saw this as the printed output (I injected prints in the src/utils/llm.py: for attempt in range(max_retries): try: Call the LLM result = llm.invoke(prompt) For non-JSON support models, we need to extract and parse the JSON manually if model_info and not model_info.has_json_mode(): print(\"RESULT CONTENT: \", result.content) parsed_result = extract_json_from_response(result.content) if parsed_result: return pydantic_model(**parsed_result) else: print(\"\\n\\nRESULT: \", result) return result ) signal='neutral' confidence=65.0 reasoning=\"Micr... Although I'm not looking at the raw content, so the ordering may likely be more dependent on the Pydantic model than the actual output of the LLM. Am I missing something or should this be re-ordered?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1562, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "bfa1dc47-9ecd-48a4-95da-83b19065fced", "embedding": null, "metadata": {"issue_id": 259, "title": "backend request failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ac8e8746-b0d8-4a52-8125-1b7e29c5d47f", "node_type": "4", "metadata": {"issue_id": 259, "title": "backend request failed", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "d58c0628521ce1a49ea474af2e9279ddf0051aaa28706d06b851bbc7c65dc173", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: backend request failed\n\nDescription: **Describe the bug** A clear and concise description of what the bug is. graph.add_node \u51fa\u9519 error info \uff1a { \"detail\": \"An error occurred while processing the request: Channel 'data' already exists with a different type\" } My Request\uff1a curl -X 'POST' \\ 'http://127.0.0.1:8000/run-hedge-fund' \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"tickers\": [ \"TSLA\" ], \"selected_agents\": [ \"ben_graham\" ], \"end_date\": \"string\", \"start_date\": \"string\", \"model_name\": \"gpt-4o\", \"model_provider\": \"OpenAI\", \"initial_cash\": 100000, \"margin_requirement\": 0 }' **Screenshot** Add a screenshot of the bug to help explain your problem. !Image !Image **Additional context** Add any other context about the problem here.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 855, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "48ee146e-9872-4857-833f-ce11a1587839", "embedding": null, "metadata": {"issue_id": 258, "title": "Use ollama", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "89b19d57-47ea-4468-b3d8-0ff0e9ff6e02", "node_type": "4", "metadata": {"issue_id": 258, "title": "Use ollama", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "2c74d973cef641ca8e166719c6ea42c1a7654bd39e297cb9cb61369bbfbdc31f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Use ollama\n\nDescription: How do I use ollama on Mac instead cloud api\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 184, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d69fa0c7-6e5e-4447-9d47-c1988731eec7", "embedding": null, "metadata": {"issue_id": 256, "title": "How long does it take to make final decisions usually?", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cd5767c2-7e8f-4741-88e7-6925c5fd461b", "node_type": "4", "metadata": {"issue_id": 256, "title": "How long does it take to make final decisions usually?", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "4317479117148499be39523c8ee34e009cefa3787c67746e377224ef4addf491", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How long does it take to make final decisions usually?\n\nDescription: I have waited for an hour and the portfolio management is still thinking. By the way, I'm using Qwen3-30b-a3b model.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 273, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d859c620-9626-43f3-8256-421284243f28", "embedding": null, "metadata": {"issue_id": 255, "title": "Add xAI models", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9f66b3e4-d9ce-4223-a9f8-ca76944f2924", "node_type": "4", "metadata": {"issue_id": 255, "title": "Add xAI models", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "79085568b53f2f25ed2b3b0c8085107db0786598175173ed18dc3ebcccdb664f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Add xAI models\n\nDescription: Do you have a plan to add xAI models in the near future?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 200, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "08322b66-af9b-4798-876e-5c23f478ceea", "embedding": null, "metadata": {"issue_id": 254, "title": "Cache design flaw in get_financial_metrics prevents fetching newer data", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6c2c8c2e-4f20-413f-bba6-9103c8940254", "node_type": "4", "metadata": {"issue_id": 254, "title": "Cache design flaw in get_financial_metrics prevents fetching newer data", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "9794e95628c1963592fe0a97f8bc8ca90a8c0251ffb3852485cf20d7286d0747", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Cache design flaw in get_financial_metrics prevents fetching newer data\n\nDescription: Description There's a critical caching issue in the get_financial_metrics function that prevents users from getting the most recent financial data when they've previously queried older data for the same ticker. Steps to Reproduce 1. Query financial metrics for ticker \"AAPL\" with end_date=\"2023-12-31\" 2. Later query the same ticker with a more recent date (e.g., end_date=\"2024-12-31\") Current Behavior When step 2 is executed, the function finds cached data from the earlier query and filters by the new end_date. Since the older data's report_period is before the new end_date, the function returns only the old cached data without making an API call to fetch newer reports. Expected Behavior When querying with a newer end_date, the function should check if the cached data contains recent enough entries, and if not, make an API call to fetch the most recent data. Root Cause The caching mechanism only checks for the existence of data for a ticker without validating whether that data covers the requested time period adequately. The filter only excludes data that is too recent, but doesn't identify when data is too old or incomplete. Proposed Solution Modify the cache lookup to also check the most recent report_period in the cached data: [CODE_BLOCK] This ensures we only use cached data if it contains sufficiently recent information.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1520, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e4067457-9170-4706-96ba-b35da10856a9", "embedding": null, "metadata": {"issue_id": 251, "title": "The key I am using is for DeepSeek R1. Why does it report an error when running backtesting?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "906c2e9f-1053-4cbe-9922-ad21a92100d0", "node_type": "4", "metadata": {"issue_id": 251, "title": "The key I am using is for DeepSeek R1. Why does it report an error when running backtesting?", "state": "closed", "labels": [], "type": "issue"}, "hash": "fc277aeb38f7a32d0d92e33bcf850dcbecab9b10bf1c985e1d1eb39ce6a8cc43", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: The key I am using is for DeepSeek R1. Why does it report an error when running backtesting?\n\nDescription: Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}} Error in LLM call after 3 attempts: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****-key is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3584, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "80e7da8c-cc5f-4b4a-a153-fb50ce0a3947", "embedding": null, "metadata": {"issue_id": 250, "title": "The calculation of the portfolio value when shorting seems off", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c8f63439-5144-4476-a69f-eed5f8fd2827", "node_type": "4", "metadata": {"issue_id": 250, "title": "The calculation of the portfolio value when shorting seems off", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "4adf2bb4c1ae38f2e0332e4d09f5422f9bc342bd0aca999d7c2a718f41bc71b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: The calculation of the portfolio value when shorting seems off\n\nDescription: Since you already adds proceeds back to cash balance self.portfolio[\"cash\"] += proceeds when calculating the portfolio value, you should only reduce the amount of the current stock price, not the difference between short_cost_basis and price. Otherwise this will cause incorrect unrealized portfolio value before you cover all the short positions. change total_value += position[\"short\"] * (position[\"short_cost_basis\"] - price) to total_value -= position[\"short\"] * price\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 637, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d7285939-b672-46d2-989b-d83fc1d3e33f", "embedding": null, "metadata": {"issue_id": 248, "title": "Fail to return results when ticker is BTC-USD", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7683341d-8119-4769-9eff-e62bd55383c1", "node_type": "4", "metadata": {"issue_id": 248, "title": "Fail to return results when ticker is BTC-USD", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "5f16e314534c3ce86dc37aa17514273c3ab5488dae3344b57d0bc194196b5e36", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Fail to return results when ticker is BTC-USD\n\nDescription: When using ticker as BTC-USD(financialdatasets.ai using this correctly), there is no feedback while the error message is \"message\":\"Please provide a valid ticker from https://www.sec.gov/files/company_tickers.json\". I guess bitcon is used as different name at different sites. **Screenshot** !Image\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 446, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f0445c4d-7151-497f-8e57-f381bda57bb1", "embedding": null, "metadata": {"issue_id": 241, "title": "Add error handling for missing or invalid .env variables", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f8acd5e9-b2b5-4f67-8750-0272eaf27e56", "node_type": "4", "metadata": {"issue_id": 241, "title": "Add error handling for missing or invalid .env variables", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "995c463e9f2c0cca4bd340940cd7c99192f556e7843d77f39b513b0ddfb205bf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Add error handling for missing or invalid .env variables\n\nDescription: Hi \ud83d\udc4b Currently, the application depends on environment variables from .env (like GROQ_API_KEY), but there's no validation if any of these are missing or incorrect. It would be great to add a validation check (either in main.py or at app startup) to: - Log a warning if any required key is missing - Exit gracefully with a message, instead of crashing Let me know if this sounds useful \u2014 happy to raise a PR. Thanks!\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 574, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "56c47f22-4f99-4ab7-80a8-f7b8e0f05534", "embedding": null, "metadata": {"issue_id": 240, "title": "Any tests on current or past market trends", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1358fe12-8edf-429f-be76-0f484498f576", "node_type": "4", "metadata": {"issue_id": 240, "title": "Any tests on current or past market trends", "state": "closed", "labels": [], "type": "issue"}, "hash": "0b835ee341c9b752d66b0f91ca1344cc5854897499ab6252de52fc6127b2281a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Any tests on current or past market trends\n\nDescription: Is there metrics to the performace of the current or previous market trends for this Hedge Fund?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 175, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c0eda94d-9a66-4d28-8607-afa590f41f9e", "embedding": null, "metadata": {"issue_id": 239, "title": "Jim Simons AI agent", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9c66102e-f2e6-409a-bfd6-2cfd811efd09", "node_type": "4", "metadata": {"issue_id": 239, "title": "Jim Simons AI agent", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "8fabf9000ee8c0055573f953a7bd48e36460b5ed005a02849bf48f14ac66b002", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Jim Simons AI agent\n\nDescription: Jim Simons, the greatest algorithmic trader should be added as an agent to the make the model more enhanced.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 257, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ee12a1e5-0502-4d78-b976-bf9758b0d05f", "embedding": null, "metadata": {"issue_id": 235, "title": "Error downloading model qwen2.5: 'charmap' codec can't decode byte 0x8f in position 37: character maps to Cannot proceed without Ollama and the selected model.", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "536600e8-bd3b-4257-bc79-ff7e8c068da6", "node_type": "4", "metadata": {"issue_id": 235, "title": "Error downloading model qwen2.5: 'charmap' codec can't decode byte 0x8f in position 37: character maps to Cannot proceed without Ollama and the selected model.", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "4d7e96078bbb2784f91a35cec9bce3b543e316f2484f0a0188a5427fdce4b7aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Error downloading model qwen2.5: 'charmap' codec can't decode byte 0x8f in position 37: character maps to Cannot proceed without Ollama and the selected model.\n\nDescription: **Describe the bug** So **ollama** is already running in my system, and I have already downloaded the **qwen2.5 7b** model, seems like it's detecting the running server but can't access the model. **Screenshot** !Image **Additional context** (.venv) E:\\Python Projects\\Stock Trading\\ai-hedge-fund>poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 --ollama ? Select your AI analysts. done (3 selections) Selected analysts: Ben Graham, Charlie Munger, Phil Fisher Using Ollama for local LLM inference. ? Select your Ollama model: [ollama] qwen2.5 (7B) Model qwen2.5 is not available locally. ? Do you want to download the qwen2.5 model? The download will happen in the background. Yes Downloading model qwen2.5... This may take a while depending on your internet speed and the model size. The download is happening in the background. Please be patient... Download progress: Error downloading model qwen2.5: 'charmap' codec can't decode byte 0x8f in position 37: character maps to <undefined> Cannot proceed without Ollama and the selected model.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1355, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "dc4aa713-f6cc-43a2-992a-ef37c83103a2", "embedding": null, "metadata": {"issue_id": 234, "title": "module of dotenv is not found", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5bae5ff3-b821-4703-9879-3481087dcf2c", "node_type": "4", "metadata": {"issue_id": 234, "title": "module of dotenv is not found", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "bd1a4d8034f04f78816671a99f1660e2c11e88f3d6db9943f9fd93f6ef052884", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: module of dotenv is not found\n\nDescription: my python is in my C drive, but my ai hedge fund is in my D drive. I pip installed dotenv but when i run p\"oetry run python src/main.py --ticker AAPL,MSFT,NVDA\", from line 3 main.py \"from donenv import ....\" the dotenv module is not found.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 371, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9ab6e082-b72e-4bf5-80cb-422a4ddb88d4", "embedding": null, "metadata": {"issue_id": 223, "title": "index", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5750a562-7800-4568-bef6-e18a0be34cc5", "node_type": "4", "metadata": {"issue_id": 223, "title": "index", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "939295ab735670a8bbf0effe947bf9f55090101e1820218ac885c8e08d9af3f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: index\n\nDescription: **Describe the bug** A clear and concise description of what the bug is. **Screenshot** Add a screenshot of the bug to help explain your problem. **Additional context** Add any other context about the problem here.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 322, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "80717a06-6369-4fc6-89e2-412565868235", "embedding": null, "metadata": {"issue_id": 221, "title": "Can't download using 'poetry install'", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5c7adefd-58b7-4a20-bc94-a456edfdc972", "node_type": "4", "metadata": {"issue_id": 221, "title": "Can't download using 'poetry install'", "state": "closed", "labels": [], "type": "issue"}, "hash": "7a6454419213171831384d850aabe5efd72f9c157ca59f60a39c9028893bb991", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Can't download using 'poetry install'\n\nDescription: Installing dependencies from lock file Package operations: 51 installs, 0 updates, 0 removals - Installing numpy (1.26.4): Failed PEP517 build of a dependency failed Backend subprocess exited when trying to invoke build_wheel | Command '['C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\tmpwhozoais\\\\.venv\\\\Scripts\\\\python.exe', 'C:\\\\Users\\\\User\\\\pipx\\\\venvs\\\\poetry\\\\Lib\\\\site-packages\\\\pyproject_hooks\\\\_in_process\\\\_in_process.py', 'build_wheel', 'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\tmpynq7r37r']' returned non-zero exit status 1. | | + C:\\Users\\User\\AppData\\Local\\Temp\\tmpwhozoais\\.venv\\Scripts\\python.exe C:\\Users\\User\\AppData\\Local\\Temp\\tmp4dwfxb_d\\numpy-1.26.4\\vendored-meson\\meson\\meson.py setup C:\\Users\\User\\AppData\\Local\\Temp\\tmp4dwfxb_d\\numpy-1.26.4 C:\\Users\\User\\AppData\\Local\\Temp\\tmp4dwfxb_d\\numpy-1.26.4\\.mesonpy-58hz322k -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\User\\AppData\\Local\\Temp\\tmp4dwfxb_d\\numpy-1.26.4\\.mesonpy-58hz322k\\meson-python-native-file.ini | The Meson build system | Version: 1.2.99 | Source dir: C:\\Users\\User\\AppData\\Local\\Temp\\tmp4dwfxb_d\\numpy-1.26.4 | Build dir: C:\\Users\\User\\AppData\\Local\\Temp\\tmp4dwfxb_d\\numpy-1.26.4\\.mesonpy-58hz322k | Build type: native build | Project name: NumPy | Project version: 1.26.4 | WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe | | ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']] | The following exception(s) were encountered: | Running icl \"\" gave \"[WinError 2] The system cannot find the file specified\" | Running cl /? gave \"[WinError 2] The system cannot find the file specified\" | Running cc --version gave \"[WinError 2] The system cannot find the file specified\" | Running gcc --version gave \"[WinError 2] The system cannot find the file specified\" | Running clang --version gave \"[WinError 2] The system cannot find the file specified\" | Running clang-cl /? gave \"[WinError 2] The system cannot find the file specified\" | Running pgcc --version gave \"[WinError 2] The system cannot find the file specified\" | | A full log can be found at C:\\Users\\User\\AppData\\Local\\Temp\\tmp4dwfxb_d\\numpy-1.26.4\\.mesonpy-58hz322k\\meson-logs\\meson-log.txt Note: This error originates from the build backend, and is likely not a problem with poetry but one of the following issues with numpy (1.26.4) - not supporting PEP 517 builds - not specifying PEP 517 build requirements correctly - the build requirements are incompatible with your operating system or Python version - the build requirements are missing system dependencies (eg: compilers, libraries, headers). You can verify this by running pip wheel --no-cache-dir --use-pep517 \"numpy (==1.26.4)\".\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2877, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "fcf1e76d-bf80-46ca-9633-0a149e643b73", "embedding": null, "metadata": {"issue_id": 220, "title": "ModuleNotFoundError: No module named 'langchain_ollama' after git pull updated", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "301300c7-a0ae-412c-aae0-406e0b8db2ff", "node_type": "4", "metadata": {"issue_id": 220, "title": "ModuleNotFoundError: No module named 'langchain_ollama' after git pull updated", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "4daf5de759861bdeb5c9060c313dc7de3de6295bc0145fcddf9e6d32a15af59c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: ModuleNotFoundError: No module named 'langchain_ollama' after git pull updated\n\nDescription: **Describe the bug** after the update, the git was pulled on 15 Apr 2025. I have an error when using the poetry run python src/main.py --ticker command. **Screenshot** !Image\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 355, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c47ec169-f2a2-4f39-bce3-fade0c88168d", "embedding": null, "metadata": {"issue_id": 214, "title": "Two errors exist in bill_ackman.py where the start and end positions are swapped due to the financial_line_items returning data in reverse order. This inversion leads to incorrect data slicing in the affected code sections.", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c8a62ca9-4c67-4a5e-acda-93c2568f17b3", "node_type": "4", "metadata": {"issue_id": 214, "title": "Two errors exist in bill_ackman.py where the start and end positions are swapped due to the financial_line_items returning data in reverse order. This inversion leads to incorrect data slicing in the affected code sections.", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "847fed41c30b277bf7bda65468bcb71f18b18cccdd3c48602c9eed05022cbf2e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Two errors exist in bill_ackman.py where the start and end positions are swapped due to the financial_line_items returning data in reverse order. This inversion leads to incorrect data slicing in the affected code sections.\n\nDescription: \u200b\u200bDescribe the Bug\u200b\u200b Two errors exist in bill_ackman.py where the start and end positions are swapped due to the financial_line_items returning data in reverse order. This inversion leads to incorrect data slicing in the affected code sections. \u200b\u200bScreenshot\u200b\u200b Not applicable for code logic errors. A code comparison screenshot of the patch is recommended to visualize the changes. \u200b\u200bAdditional Context\u200b\u200b \u200b\u200bRoot Cause\u200b\u200b: The financial_line_items API returns data in reverse chronological order, b bill_ackman.py.patch ut the code mistakenly treats it as forward-sorted. \u200b\u200bFix Submitted\u200b\u200b: A patch correcting the position swapping has been provided. \u200b\u200bImpact\u200b\u200b: Incorrect financial metric calculations (e.g., quarterly revenue or expense aggregations). \u200b\u200bTesting Recommendation\u200b\u200b: Validate with historical datasets where ground-truth forward-sorted results are available.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1195, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "92307769-ef8b-4f8f-a4c9-13eac61d5a19", "embedding": null, "metadata": {"issue_id": 212, "title": "Normal distribution model ", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fc70fb12-d1cd-41e2-b83c-fbb1422cd969", "node_type": "4", "metadata": {"issue_id": 212, "title": "Normal distribution model ", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "664073f1981c89fa9d1c31386d3461e9c74b773b03c7eb1819cb85746afaf69a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Normal distribution model \n\nDescription: adding a normal distribution model with Z-score is a great enhancement for AI- hedge fund simulation. It can help agents (especially Risk Manager, Valuation Agent, or Sentiment Agent) make more data-driven decisions based on statistical thresholds.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 404, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e218c212-4862-4bd0-818b-c7fc14aa6c36", "embedding": null, "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6e5d0754-2123-4e6e-9a27-483028afd4df", "node_type": "4", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b037c435729e6829cc9a72e0db344368b1e319d3de042bd8112bf204b0bb06d0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48c51b82-faef-4960-8d26-2f24c039d864", "node_type": "1", "metadata": {}, "hash": "e5f464e09b85d090bd8d58c889f3b4087df90c597ba93032b6c7808770efee4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Use own stock data instead of paying 200 USD for it...    .csv\n\nDescription: Make it possible to extract own stock data thru cTrader -> .CSV. For example EUR_JPY 10 tick data structure; Timestamp,Open,High,Low,Close,SMA_20,RSI,ATR,MACD,Bollinger_Upper,Bollinger_Lower,CCI,KeltnerChannel_Top,KeltnerChannel_Bottom,EMA50,EMA200,StochK,StochD,WilliamsR,AO,Acceleration,Fractal_Up,Fractal_Down,ParabolicSAR,ADX,DI_Plus,DI_Minus,RegressionForecast,RegressionIntercept,VolumeROC 2024-11-24 22:00:59,161.53000,161.53000,161.53000,161.53000,161.28070,83.14774,0.03457,-0.03864,161.44980,161.11160,564.17683,161.39092,161.22172,161.27840,161.26070,74.98186,54.42662,-2.33333,0.06776,0.04408,NaN,NaN,161.23700,22.90325,67.00177,13.20958,161.39167,161.21047,-90.00000 2024-11-24 22:01:30,161.56000,161.56000,161.56000,161.56000,161.29935,84.37574,0.03536,-0.05556,161.51155,161.08715,313.63278,161.42358,161.24238,161.29054,161.26397,97.57177,73.27013,-1.82371,0.11942,0.07326,NaN,NaN,161.23700,26.38797,67.83777,12.22480,161.46414,161.18343,-90.00000 2024-11-24 22:02:19,161.57300,161.57300,161.57300,161.57300,161.31770,84.89123,0.03579,-0.06815,161.55981,161.07559,219.64375,161.44687,161.26687,161.30207,161.26716,99.29078,90.84029,-0.00000,0.17519,0.09607,NaN,NaN,161.27050,29.53799,66.20527,11.66706,161.52610,161.16647,-90.00000 2024-11-24 22:02:54,161.54400,161.54400,161.54400,161.54400,161.33150,78.69487,0.03750,-0.07232,161.58437,161.07863,152.51755,161.46211,161.28211,161.31043,161.26962,94.14683,96.21369,-8.63095,0.22425,0.10189,NaN,NaN,161.30680,31.95837,61.84311,12.39524,161.55991,161.16794,-90.00000 - ctrader example code: - using cAlgo.API; using cAlgo.API.Indicators; using System; using System.IO; using System.Text; using System.Globalization; using System.Collections.Generic; namespace cAlgo.Robots { [Robot(TimeZone = TimeZones.UTC, AccessRights = AccessRights.FullAccess)] public class ExportOHLCWithIndicators : Robot { // Indicator declarations private MovingAverage _sma20; private RelativeStrengthIndex _rsi; private AverageTrueRange _atr; private MacdHistogram _macd; private BollingerBands _bollingerBands; private CommodityChannelIndex _cci; private KeltnerChannels _keltnerChannels; private ExponentialMovingAverage _ema50; private ExponentialMovingAverage _ema200; private StochasticOscillator _stochastic; private WilliamsPctR _williamsR; private AwesomeOscillator _ao;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2404, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "48c51b82-faef-4960-8d26-2f24c039d864", "embedding": null, "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6e5d0754-2123-4e6e-9a27-483028afd4df", "node_type": "4", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b037c435729e6829cc9a72e0db344368b1e319d3de042bd8112bf204b0bb06d0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e218c212-4862-4bd0-818b-c7fc14aa6c36", "node_type": "1", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "6714996f9c5ac7536ea8c9eeee2f23c8ad1fa1f5dc8026bd2239b475a0c30d76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b08993b-7bf9-46a3-8771-c3024e7326e4", "node_type": "1", "metadata": {}, "hash": "883c1c6948335d0bc44ae1cfade37d5d40ae13cbe41812694a4c87c6604e0468", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "API; using cAlgo.API.Indicators; using System; using System.IO; using System.Text; using System.Globalization; using System.Collections.Generic; namespace cAlgo.Robots { [Robot(TimeZone = TimeZones.UTC, AccessRights = AccessRights.FullAccess)] public class ExportOHLCWithIndicators : Robot { // Indicator declarations private MovingAverage _sma20; private RelativeStrengthIndex _rsi; private AverageTrueRange _atr; private MacdHistogram _macd; private BollingerBands _bollingerBands; private CommodityChannelIndex _cci; private KeltnerChannels _keltnerChannels; private ExponentialMovingAverage _ema50; private ExponentialMovingAverage _ema200; private StochasticOscillator _stochastic; private WilliamsPctR _williamsR; private AwesomeOscillator _ao; private AcceleratorOscillator _accelerationOscillator; private Fractals _fractals; private ParabolicSAR _parabolicSar; private DirectionalMovementSystem _adx; private LinearRegressionForecast _regressionForecast; private LinearRegressionIntercept _regressionIntercept; // Custom volume ROC implementation private double[] _volumeROC; private int _volumeROCPeriod = 14; private string _filePath; private bool _headerWritten = false; // User parameters for saving options [Parameter(\"Save OHLC\", DefaultValue = true)] public bool SaveOHLC { get; set; } [Parameter(\"Save SMA 20\", DefaultValue = true)] public bool SaveSMA20 { get; set; } [Parameter(\"Save RSI\", DefaultValue = true)] public bool SaveRSI { get; set; } [Parameter(\"Save ATR\", DefaultValue = true)] public bool SaveATR { get; set; } [Parameter(\"Save MACD\", DefaultValue = true)] public bool SaveMACD { get; set; } [Parameter(\"Save Bollinger Bands\", DefaultValue = true)] public bool SaveBollingerBands { get; set; } [Parameter(\"Save CCI\", DefaultValue = true)] public bool SaveCCI { get; set; } [Parameter(\"Save Keltner Channels\", DefaultValue = true)] public bool SaveKeltnerChannels { get; set; } [Parameter(\"Save EMA50\", DefaultValue = true)] public bool SaveEMA50 { get; set; } [Parameter(\"Save EMA200\", DefaultValue = true)] public bool SaveEMA200 { get; set; } [Parameter(\"Save Stochastic\", DefaultValue = true)] public bool SaveStochastic { get; set; } [Parameter(\"Save Williams %R\", DefaultValue = true)] public bool SaveWilliamsR { get; set; } [Parameter(\"Save Awesome Oscillator\", DefaultValue = true)] public bool SaveAO { get; set; } [Parameter(\"Save Acceleration Oscillator\", DefaultValue = true)] public bool SaveAcceleration { get; set; } [Parameter(\"Save Fractals\", DefaultValue = true)] public bool SaveFractals { get; set; } [Parameter(\"Save Parabolic SAR\", DefaultValue = true)] public bool SaveParabolicSAR { get; set; } [Parameter(\"Save ADX\", DefaultValue = true)] public bool SaveADX { get; set; } [Parameter(\"Save Regression\", DefaultValue = true)] public bool SaveRegression { get; set; } [Parameter(\"Save Volume ROC\", DefaultValue = true)] public bool SaveVolumeROC { get; set; } [Parameter(\"Volume ROC Period\", DefaultValue = 14)] public int VolumeROCPeriod { get; set; } protected override void OnStart() { try { // Initialize indicators _sma20 = Indicators.MovingAverage(Bars.ClosePrices, 20, MovingAverageType.Simple); _rsi = Indicators.RelativeStrengthIndex(Bars.ClosePrices, 14); _atr = Indicators.AverageTrueRange(14, MovingAverageType.Simple); _macd = Indicators.MacdHistogram(Bars.ClosePrices, 12, 26, 9); _bollingerBands = Indicators.BollingerBands(Bars.ClosePrices, 20, 2, MovingAverageType.Simple); _cci = Indicators.CommodityChannelIndex(20); _keltnerChannels = Indicators.KeltnerChannels(20, MovingAverageType.Exponential, 10, MovingAverageType.Simple, 2); _ema50 = Indicators.ExponentialMovingAverage(Bars.ClosePrices, 50); _ema200 = Indicators.ExponentialMovingAverage(Bars.ClosePrices, 200); _stochastic = Indicators.StochasticOscillator(14, 3,", "mimetype": "text/plain", "start_char_idx": 1654, "end_char_idx": 5451, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4b08993b-7bf9-46a3-8771-c3024e7326e4", "embedding": null, "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6e5d0754-2123-4e6e-9a27-483028afd4df", "node_type": "4", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b037c435729e6829cc9a72e0db344368b1e319d3de042bd8112bf204b0bb06d0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48c51b82-faef-4960-8d26-2f24c039d864", "node_type": "1", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "fbf7f03a3ca9062204b887094f23d7d7075101628e5dca9603e7ebca6ef75aee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e01a6a04-df74-4a57-b627-8364fbdf7813", "node_type": "1", "metadata": {}, "hash": "2700b66009ff05c3682d7996779cbd871af1927c433266026d94de5f639ab266", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "RelativeStrengthIndex(Bars.ClosePrices, 14); _atr = Indicators.AverageTrueRange(14, MovingAverageType.Simple); _macd = Indicators.MacdHistogram(Bars.ClosePrices, 12, 26, 9); _bollingerBands = Indicators.BollingerBands(Bars.ClosePrices, 20, 2, MovingAverageType.Simple); _cci = Indicators.CommodityChannelIndex(20); _keltnerChannels = Indicators.KeltnerChannels(20, MovingAverageType.Exponential, 10, MovingAverageType.Simple, 2); _ema50 = Indicators.ExponentialMovingAverage(Bars.ClosePrices, 50); _ema200 = Indicators.ExponentialMovingAverage(Bars.ClosePrices, 200); _stochastic = Indicators.StochasticOscillator(14, 3, 3, MovingAverageType.Simple); _williamsR = Indicators.WilliamsPctR(14); _ao = Indicators.AwesomeOscillator(); _accelerationOscillator = Indicators.AcceleratorOscillator(); _fractals = Indicators.Fractals(5); _parabolicSar = Indicators.ParabolicSAR(0.02, 0.2); _adx = Indicators.DirectionalMovementSystem(14); _regressionForecast = Indicators.LinearRegressionForecast(Bars.ClosePrices, 14); _regressionIntercept = Indicators.LinearRegressionIntercept(Bars.ClosePrices, 14); // Set Volume ROC period from parameter _volumeROCPeriod = VolumeROCPeriod; // Initialize Volume ROC array with the current bars count _volumeROC = new double[Bars.Count]; // Calculate initial Volume ROC values CalculateVolumeROC(); // Set the file path - ensure directory exists string documentsFolder = Environment.GetFolderPath(Environment.SpecialFolder.MyDocuments); _filePath = Path.Combine(documentsFolder, \"OHLC_with_Indicators.csv\"); // Create the directory if it doesn't exist Directory.CreateDirectory(Path.GetDirectoryName(_filePath)); // Write the header (we'll write it first time in OnBar) _headerWritten = false; Print(\"Export will be saved to: \" + _filePath); } catch (Exception ex) { Print($\"Error in OnStart: {ex.Message}\"); Print($\"Stack trace: {ex.StackTrace}\"); } } private void CalculateVolumeROC() { try { // Calculate Volume Rate of Change for all bars for (int i = 0; i < Bars.Count; i++) { if (i >= _volumeROCPeriod) { double currentVolume = Bars.TickVolumes[i]; double pastVolume = Bars.TickVolumes[i - _volumeROCPeriod]; if (pastVolume != 0) { _volumeROC[i] = ((currentVolume - pastVolume) / pastVolume) * 100; } else { // Handle division by zero _volumeROC[i] = 0; } } else { _volumeROC[i] = 0; } } } catch (Exception ex) { Print($\"Error in CalculateVolumeROC: {ex.Message}\"); } } private void WriteHeader() { try { // Build header columns var headerColumns = new List<string>(); headerColumns.Add(\"Timestamp\"); if (SaveOHLC) { headerColumns.Add(\"Open\"); headerColumns.Add(\"High\"); headerColumns.Add(\"Low\"); headerColumns.Add(\"Close\"); } if (SaveSMA20) headerColumns.Add(\"SMA_20\"); if (SaveRSI) headerColumns.Add(\"RSI\"); if (SaveATR) headerColumns.Add(\"ATR\"); if (SaveMACD) headerColumns.Add(\"MACD\"); if (SaveBollingerBands) { headerColumns.Add(\"Bollinger_Upper\"); headerColumns.Add(\"Bollinger_Lower\"); } if (SaveCCI) headerColumns.Add(\"CCI\"); if (SaveKeltnerChannels) { headerColumns.Add(\"KeltnerChannel_Top\"); headerColumns.Add(\"KeltnerChannel_Bottom\"); } if (SaveEMA50) headerColumns.Add(\"EMA50\"); if (SaveEMA200) headerColumns.Add(\"EMA200\"); if (SaveStochastic) { headerColumns.Add(\"StochK\"); headerColumns.Add(\"StochD\"); } if (SaveWilliamsR) headerColumns.Add(\"WilliamsR\"); if (SaveAO) headerColumns.Add(\"AO\"); if (SaveAcceleration) headerColumns.Add(\"Acceleration\"); if (SaveFractals) { headerColumns.Add(\"Fractal_Up\"); headerColumns.", "mimetype": "text/plain", "start_char_idx": 4831, "end_char_idx": 8294, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e01a6a04-df74-4a57-b627-8364fbdf7813", "embedding": null, "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6e5d0754-2123-4e6e-9a27-483028afd4df", "node_type": "4", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b037c435729e6829cc9a72e0db344368b1e319d3de042bd8112bf204b0bb06d0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b08993b-7bf9-46a3-8771-c3024e7326e4", "node_type": "1", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "0951deebb6bdf902f6fb81b26cb39fbd07e263a998bad227842e521959c1cc43", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b30ffe89-13f2-4d2e-8fc7-10383afa92e3", "node_type": "1", "metadata": {}, "hash": "f526e3bcc7d82c40388939423fa09d45213fa8ba3838580383fcd54547733f56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Add(\"MACD\"); if (SaveBollingerBands) { headerColumns.Add(\"Bollinger_Upper\"); headerColumns.Add(\"Bollinger_Lower\"); } if (SaveCCI) headerColumns.Add(\"CCI\"); if (SaveKeltnerChannels) { headerColumns.Add(\"KeltnerChannel_Top\"); headerColumns.Add(\"KeltnerChannel_Bottom\"); } if (SaveEMA50) headerColumns.Add(\"EMA50\"); if (SaveEMA200) headerColumns.Add(\"EMA200\"); if (SaveStochastic) { headerColumns.Add(\"StochK\"); headerColumns.Add(\"StochD\"); } if (SaveWilliamsR) headerColumns.Add(\"WilliamsR\"); if (SaveAO) headerColumns.Add(\"AO\"); if (SaveAcceleration) headerColumns.Add(\"Acceleration\"); if (SaveFractals) { headerColumns.Add(\"Fractal_Up\"); headerColumns.Add(\"Fractal_Down\"); } if (SaveParabolicSAR) headerColumns.Add(\"ParabolicSAR\"); if (SaveADX) { headerColumns.Add(\"ADX\"); headerColumns.Add(\"DI_Plus\"); headerColumns.Add(\"DI_Minus\"); } if (SaveRegression) { headerColumns.Add(\"RegressionForecast\"); headerColumns.Add(\"RegressionIntercept\"); } if (SaveVolumeROC) headerColumns.Add(\"VolumeROC\"); // Create a new file or overwrite existing using (var writer = new StreamWriter(_filePath, false, Encoding.UTF8)) { writer.WriteLine(string.Join(\",\", headerColumns)); } _headerWritten = true; Print(\"Header written successfully\"); } catch (Exception ex) { Print($\"Error writing header: {ex.Message}\"); Print($\"Stack trace: {ex.StackTrace}\"); } } protected override void OnBar() { try { // Write header if not written yet if (!_headerWritten) { WriteHeader(); } var index = Bars.Count - 1; // Ensure array size matches current bar count if (_volumeROC.Length <= index) { Array.Resize(ref _volumeROC, index + 100); // Resize with some extra capacity } // Update Volume ROC for current bar if (index >= _volumeROCPeriod) { double currentVolume = Bars.TickVolumes[index]; double pastVolume = Bars.TickVolumes[index - _volumeROCPeriod]; if (pastVolume != 0) { _volumeROC[index] = ((currentVolume - pastVolume) / pastVolume) * 100; } else { _volumeROC[index] = 0; } } // Format all values var timestamp = Bars.OpenTimes[index].ToString(\"yyyy-MM-dd HH:mm:ss\", CultureInfo.InvariantCulture); var open = Bars.OpenPrices[index].ToString(\"F5\", CultureInfo.InvariantCulture); var high = Bars.HighPrices[index].ToString(\"F5\", CultureInfo.InvariantCulture); var low = Bars.LowPrices[index].ToString(\"F5\", CultureInfo.InvariantCulture); var close = Bars.ClosePrices[index].ToString(\"F5\", CultureInfo.InvariantCulture); var sma20 = _sma20.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var rsi = _rsi.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var atr = _atr.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var macd = _macd.Histogram[index].ToString(\"F5\", CultureInfo.InvariantCulture); var bollingerUpper = _bollingerBands.Top[index].ToString(\"F5\", CultureInfo.InvariantCulture); var bollingerLower = _bollingerBands.Bottom[index].ToString(\"F5\", CultureInfo.InvariantCulture); var cci = _cci.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var keltnerTop = _keltnerChannels.Top[index].ToString(\"F5\", CultureInfo.InvariantCulture); var keltnerBottom = _keltnerChannels.Bottom[index].ToString(\"F5\", CultureInfo.InvariantCulture); var ema50 = _ema50.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var ema200 = _ema200.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var stochK = _stochastic.PercentK[index].ToString(\"F5\", CultureInfo.InvariantCulture); var stochD = _stochastic.PercentD[index].ToString(\"F5\", CultureInfo.InvariantCulture); var williamsR = _williamsR.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var ao = _ao.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var acceleration = _accelerationOscillator.", "mimetype": "text/plain", "start_char_idx": 7642, "end_char_idx": 11339, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b30ffe89-13f2-4d2e-8fc7-10383afa92e3", "embedding": null, "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6e5d0754-2123-4e6e-9a27-483028afd4df", "node_type": "4", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b037c435729e6829cc9a72e0db344368b1e319d3de042bd8112bf204b0bb06d0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e01a6a04-df74-4a57-b627-8364fbdf7813", "node_type": "1", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "aa1a324b7940d1a17ae65973962937033ae4a011b06c243a281dd96bd4b5c751", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb0e2dbb-5d17-44c5-9b7f-dd939a7a5445", "node_type": "1", "metadata": {}, "hash": "a01df96fa9441111aaf0953d72ad590ad288229a5e02c0e25b5fa5f931e8f788", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "CultureInfo.InvariantCulture); var keltnerTop = _keltnerChannels.Top[index].ToString(\"F5\", CultureInfo.InvariantCulture); var keltnerBottom = _keltnerChannels.Bottom[index].ToString(\"F5\", CultureInfo.InvariantCulture); var ema50 = _ema50.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var ema200 = _ema200.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var stochK = _stochastic.PercentK[index].ToString(\"F5\", CultureInfo.InvariantCulture); var stochD = _stochastic.PercentD[index].ToString(\"F5\", CultureInfo.InvariantCulture); var williamsR = _williamsR.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var ao = _ao.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var acceleration = _accelerationOscillator.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); // For Fractals, use NaN format if needed string fractalUp, fractalDown; if (_fractals.UpFractal[index] != 0) fractalUp = _fractals.UpFractal[index].ToString(\"F5\", CultureInfo.InvariantCulture); else fractalUp = \"NaN\"; if (_fractals.DownFractal[index] != 0) fractalDown = _fractals.DownFractal[index].ToString(\"F5\", CultureInfo.InvariantCulture); else fractalDown = \"NaN\"; var parabolicSar = _parabolicSar.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var adx = _adx.ADX[index].ToString(\"F5\", CultureInfo.InvariantCulture); var diPlus = _adx.DIPlus[index].ToString(\"F5\", CultureInfo.InvariantCulture); var diMinus = _adx.DIMinus[index].ToString(\"F5\", CultureInfo.InvariantCulture); var regressionForecast = _regressionForecast.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var regressionIntercept = _regressionIntercept.Result[index].ToString(\"F5\", CultureInfo.InvariantCulture); var volumeROC = _volumeROC[index].ToString(\"F5\", CultureInfo.InvariantCulture); // Build row values var rowValues = new List<string>(); rowValues.Add(timestamp); if (SaveOHLC) { rowValues.Add(open); rowValues.Add(high); rowValues.Add(low); rowValues.Add(close); } if (SaveSMA20) rowValues.Add(sma20); if (SaveRSI) rowValues.Add(rsi); if (SaveATR) rowValues.Add(atr); if (SaveMACD) rowValues.Add(macd); if (SaveBollingerBands) { rowValues.Add(bollingerUpper); rowValues.Add(bollingerLower); } if (SaveCCI) rowValues.Add(cci); if (SaveKeltnerChannels) { rowValues.Add(keltnerTop); rowValues.Add(keltnerBottom); } if (SaveEMA50) rowValues.Add(ema50); if (SaveEMA200) rowValues.Add(ema200); if (SaveStochastic) { rowValues.Add(stochK); rowValues.Add(stochD); } if (SaveWilliamsR) rowValues.Add(williamsR); if (SaveAO) rowValues.Add(ao); if (SaveAcceleration) rowValues.Add(acceleration); if (SaveFractals) { rowValues.Add(fractalUp); rowValues.Add(fractalDown); } if (SaveParabolicSAR) rowValues.Add(parabolicSar); if (SaveADX) { rowValues.Add(adx); rowValues.Add(diPlus); rowValues.Add(diMinus); } if (SaveRegression) { rowValues.Add(regressionForecast); rowValues.Add(regressionIntercept); } if (SaveVolumeROC) rowValues.Add(volumeROC); // Append to the file using (var writer = new StreamWriter(_filePath, true, Encoding.UTF8)) { writer.WriteLine(string.Join(\",\", rowValues)); } // Debug info if (index % 10 == 0) // Only print occasionally to avoid flooding { Print($\"Data written for bar {index}, timestamp: {timestamp}\"); } } catch (Exception ex) { Print($\"Error in OnBar: {ex.Message}\"); Print($\"Stack trace: {ex.StackTrace}\"); } } protected override void OnStop() { Print($\"Export complete.", "mimetype": "text/plain", "start_char_idx": 10583, "end_char_idx": 14001, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "bb0e2dbb-5d17-44c5-9b7f-dd939a7a5445", "embedding": null, "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6e5d0754-2123-4e6e-9a27-483028afd4df", "node_type": "4", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b037c435729e6829cc9a72e0db344368b1e319d3de042bd8112bf204b0bb06d0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b30ffe89-13f2-4d2e-8fc7-10383afa92e3", "node_type": "1", "metadata": {"issue_id": 211, "title": "Use own stock data instead of paying 200 USD for it...    .csv", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "c4c947f67139e51cc37c73897fa0cd78c53d29daf8bad3816dde6b4e892dd07d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Add(parabolicSar); if (SaveADX) { rowValues.Add(adx); rowValues.Add(diPlus); rowValues.Add(diMinus); } if (SaveRegression) { rowValues.Add(regressionForecast); rowValues.Add(regressionIntercept); } if (SaveVolumeROC) rowValues.Add(volumeROC); // Append to the file using (var writer = new StreamWriter(_filePath, true, Encoding.UTF8)) { writer.WriteLine(string.Join(\",\", rowValues)); } // Debug info if (index % 10 == 0) // Only print occasionally to avoid flooding { Print($\"Data written for bar {index}, timestamp: {timestamp}\"); } } catch (Exception ex) { Print($\"Error in OnBar: {ex.Message}\"); Print($\"Stack trace: {ex.StackTrace}\"); } } protected override void OnStop() { Print($\"Export complete. File saved at: {_filePath}\"); } } }\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 13299, "end_char_idx": 14145, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "dae50215-0969-42a0-a019-2289126c5291", "embedding": null, "metadata": {"issue_id": 210, "title": "Broker-integrations", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "27b48d63-68fe-4946-8939-cada80794ada", "node_type": "4", "metadata": {"issue_id": 210, "title": "Broker-integrations", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "406da8613741df876c1266ca217250a7481ffac862731c6b582f210db7d29ea4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Broker-integrations\n\nDescription: A simple way to make it take positions on specific account on places like; https://www.avanza.se/ AND Skilling (ctrader api) Thanks for a great and fun collection\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 311, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "60e5f154-05b5-444a-a07b-d0486c2d6895", "embedding": null, "metadata": {"issue_id": 209, "title": "Yahoo finance", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1866d662-a3e7-4c33-9640-ab81971b84c1", "node_type": "4", "metadata": {"issue_id": 209, "title": "Yahoo finance", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "18f26360d2e8acc5f8bc08c6ba6aac46119851c2a6df51e5755adad4357172b3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Yahoo finance\n\nDescription: **Describe the feature you'd like** Instead the financial data sets,we might need input parameters to be changed to change data sources to yahoo finance or alpha vantage or screener.in or tijori\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 337, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "5d6cd565-bf8f-40f0-8672-05e98e1cbf17", "embedding": null, "metadata": {"issue_id": 207, "title": "cache behaves incorrectly, ignores period parameter", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "535f222c-8f2e-4899-bbdc-712948196d7e", "node_type": "4", "metadata": {"issue_id": 207, "title": "cache behaves incorrectly, ignores period parameter", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "438adc0440c4127677ea97e5bebf13aebd92e0108351c0a0624e0dceeae5b1aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: cache behaves incorrectly, ignores period parameter\n\nDescription: I think I found 2 problems with the cache 1. cache will return any data thats less than the end_date even if its period parameter asked for something else. [CODE_BLOCK] Since the first call asked for the period to be annual, thats the data stored in the cache. If I execute the call again asking for quarterly results, it will just get the annual results from the cache and return those instead. 2. cache only merges on report_period, ignoring differences between ttm and quarterly results If the first issue was fixed by knowing that different keys (report_period) will be returned by using period annual and quarterly/ttm, it will expose this second issue. For some api calls such as tools.api.get_financial_metrics, the call supports annual, ttm, and quarterly values for the period param. If you choose ttm or quarterly, the report_period will be the same, but the values will be different, so they need to be cached separately. [CODE_BLOCK] [CODE_BLOCK] I think the solution is to take the period param into account when caching results.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1196, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f4bef509-6a25-4c9d-a33c-0f95afaaba25", "embedding": null, "metadata": {"issue_id": 205, "title": "Error in LLM call after 3 attempts: Error code: 404 - {'error': {'message': 'Not Found'}}", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e632b5ab-67b7-4b0a-a5ac-5acc6d2c6f49", "node_type": "4", "metadata": {"issue_id": 205, "title": "Error in LLM call after 3 attempts: Error code: 404 - {'error': {'message': 'Not Found'}}", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "0253ffb5c8ba0861b320ebbb682b5cc16667cb3b0d3a9d416896bf4091b107be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Error in LLM call after 3 attempts: Error code: 404 - {'error': {'message': 'Not Found'}}\n\nDescription: !Image\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 198, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "03957748-397c-413f-97d6-792cd7e87e9e", "embedding": null, "metadata": {"issue_id": 204, "title": "Use for other markets", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "83158024-30ec-4152-8edd-3de68560bbab", "node_type": "4", "metadata": {"issue_id": 204, "title": "Use for other markets", "state": "closed", "labels": [], "type": "issue"}, "hash": "da937ff6f6ba1f992ceb0d0b98da4e5ed3635584e2ef907b39493730660968e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Use for other markets\n\nDescription: @virattt is there any way which this can be used for international stocks (Like indian stocks)? Thanks\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 160, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c1c6ea23-345e-47c5-a356-6f9dd7b1802b", "embedding": null, "metadata": {"issue_id": 203, "title": "Backtesting result calculation is weird", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9cf51c80-e427-439c-8584-7bf0f2161c3f", "node_type": "4", "metadata": {"issue_id": 203, "title": "Backtesting result calculation is weird", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "475ab8fc3725ca4d4922aa1996f1040454dfe7055e187f6a1e51f27ec4d9995c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Backtesting result calculation is weird\n\nDescription: **Describe the bug** poetry run python src/backtester.py --ticker TSLA --start-date 2024-12-01 --end-date 2024-12-20 This was my command and below is the result. [CODE_BLOCK] As you can see, the price of Tesla just goes up and the ai made all the decisions of SHORT. Therefore it can not make profits at all but the result says total value goes up.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 490, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4dee2079-4515-4bc1-8f2b-2fe1f6a7298a", "embedding": null, "metadata": {"issue_id": 202, "title": "Open or Close Price of Share", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c2076f1a-1a9a-469e-87f7-7ef161b4c94d", "node_type": "4", "metadata": {"issue_id": 202, "title": "Open or Close Price of Share", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "fe29d074628483f455b3c58f52a329a16d893399b9afc15da5a25d12ade8198c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Open or Close Price of Share\n\nDescription: \n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 158, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "49893e9d-450a-404e-a3ac-4a8859a03655", "embedding": null, "metadata": {"issue_id": 198, "title": "dotenv", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ae7c7be3-c9f2-436e-bcdf-e7ba09d1dd71", "node_type": "4", "metadata": {"issue_id": 198, "title": "dotenv", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "6b5f131338fbbce62c36e5c7009da20fc7d37bc0efbaa2b8dd7beac7dc2c6ef4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: dotenv\n\nDescription: Traceback (most recent call last): File \"C:\\Users\\ronny\\OneDrive\\Documents\\GitHub\\ai-hedge-fund\\src\\main.py\", line 3, in <module> from dotenv import load_dotenv ModuleNotFoundError: No module named 'dotenv'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 315, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "25490172-761f-44bf-83e8-145914a26ec3", "embedding": null, "metadata": {"issue_id": 192, "title": "api.financialdatasets.ai SSL  issue", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2a0baa71-47a6-4346-824d-f69623b62ae4", "node_type": "4", "metadata": {"issue_id": 192, "title": "api.financialdatasets.ai SSL  issue", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "fa26ce99c592de0770e3bf556eac9d3051fc35e965a3b753d4b6c5142782c3f2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: api.financialdatasets.ai SSL  issue\n\nDescription: **Describe the bug** A clear and concise description of what the bug is. urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'api.financialdatasets.ai'. **Screenshot** Add a screenshot of the bug to help explain your problem. !Image **Additional context** Add any other context about the problem here.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 524, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d2bbc483-29ae-4478-b732-347cd4be5a7f", "embedding": null, "metadata": {"issue_id": 190, "title": "Perplexity API support", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ed190479-2901-4d59-a363-6e6908983e14", "node_type": "4", "metadata": {"issue_id": 190, "title": "Perplexity API support", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "46741c2cc68cf6b8dbc0e79846351781da1120392e66f7d4c28e7976ff4dbdcb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Perplexity API support\n\nDescription: I'd like to use the perplexity API instead of the existing options like openai. Would love to see that implementet. Already tried to research a bit on my own, but i'm not able to find enough information yet. Thanks already for this nice Project!\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 397, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e8710e35-6ce5-467d-8c8e-44bd4a606ec9", "embedding": null, "metadata": {"issue_id": 189, "title": "\u600e\u4e48\u6837\u624d\u80fd\u8c03\u7528\u7845\u57fa\u6d41\u52a8\u7684API\uff1f", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dbf12e90-d2da-4e25-8ee4-0b6da149e4e1", "node_type": "4", "metadata": {"issue_id": 189, "title": "\u600e\u4e48\u6837\u624d\u80fd\u8c03\u7528\u7845\u57fa\u6d41\u52a8\u7684API\uff1f", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "cde177540cdefc3aadf320125ca5837ba2802f55f9479b987e2daaf9ba310c92", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: \u600e\u4e48\u6837\u624d\u80fd\u8c03\u7528\u7845\u57fa\u6d41\u52a8\u7684API\uff1f\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen. \u600e\u4e48\u6837\u624d\u80fd\u8c03\u7528\u7845\u57fa\u6d41\u52a8\u7684API\uff1f \u7845\u57fa\u6d41\u52a8\uff0c\u6a21\u578b\u5e7f\u573a\u6a21\u578b\u591a\uff0c\u65b9\u4fbf\u8c03\u7528\u4e00\u4e2a API\uff0c\u5c31\u53ef\u4ee5\u7528\u5f88\u591a\u6a21\u578b\u3002\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 292, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4b480b1b-0ff4-419d-9460-dabc32973cf7", "embedding": null, "metadata": {"issue_id": 188, "title": "Running on Local LLM with Ollama", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bde870ba-f705-4cb9-a7aa-608f44ea9da5", "node_type": "4", "metadata": {"issue_id": 188, "title": "Running on Local LLM with Ollama", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "053dc3b04c56eba6f7886775877a192e9e2709e54a112bfb4b85b44ed1035a43", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Running on Local LLM with Ollama\n\nDescription: Implement ChatOllama for local LLM with baseurl parameter.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 220, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "bb0e2a5a-6015-4aec-a505-f3d49f125996", "embedding": null, "metadata": {"issue_id": 186, "title": "Crypto Support And API Server", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ebf2c4b4-20ea-4c56-beb4-3e53acf2e789", "node_type": "4", "metadata": {"issue_id": 186, "title": "Crypto Support And API Server", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "ee5d7a4f7eca8c593600e84b9dc40a9b76376f1852a0a08a086a84f816ffb0e1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Crypto Support And API Server\n\nDescription: Since the Financial Assets support crypto, would like to see, and I'm sure I'm not alone. Getting real trained trading hints from a system like this would hold more water for me possibly than a YouTube Influencer. Also, would like to see this as its own API server so that a PHP, or Javascript could make API calls and generated results onto a webpage. is this possible now....?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 537, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "484d2e81-0304-4e75-8096-6e5797911a4a", "embedding": null, "metadata": {"issue_id": 182, "title": "When will China A-share market data be supported?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5abf4bc2-2f43-42b2-b544-62ec799fad46", "node_type": "4", "metadata": {"issue_id": 182, "title": "When will China A-share market data be supported?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "0f4d4e315295ddf21fa3d2e2513164be4e94663244bdd8d05b62202df2ea69d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: When will China A-share market data be supported?\n\nDescription: China's stock market data is more complex and more conditional. We look forward to supporting China's capital market data as soon as possible.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 321, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e61f8ecb-ec61-49d5-8d64-a1ab0df10df2", "embedding": null, "metadata": {"issue_id": 181, "title": "Which data determine the confidence level?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "126626ef-7fa7-476c-b2e9-2242fad076bc", "node_type": "4", "metadata": {"issue_id": 181, "title": "Which data determine the confidence level?", "state": "closed", "labels": [], "type": "issue"}, "hash": "cca3ce790d5b7b62a04d19958cb0b0bda57c12d6704b1ae4428f256ad3a9193c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Which data determine the confidence level?\n\nDescription: Which data determine the confidence level?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 121, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ed9f8f1a-6dab-4a0c-a673-0843f4b76db1", "embedding": null, "metadata": {"issue_id": 180, "title": "\u5728\u4ec0\u4e48\u5730\u65b9\u7528\uff1f\u600e\u4e48\u7528", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "50238aea-46d5-414e-852e-7bd1b0c0fb78", "node_type": "4", "metadata": {"issue_id": 180, "title": "\u5728\u4ec0\u4e48\u5730\u65b9\u7528\uff1f\u600e\u4e48\u7528", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "53ff85d17f5f9d11a10f9aa764447ecc24e93b69087b4ef1084b71a86ca3c0d2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: \u5728\u4ec0\u4e48\u5730\u65b9\u7528\uff1f\u600e\u4e48\u7528\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen. \u8fd9\u4e2aAI\u7a0b\u5e8f\u600e\u4e48\u7528\uff1f\u5728\u54ea\u91cc\u7528\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 250, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6e2d7c8c-823b-49c2-8ea6-412b8075e179", "embedding": null, "metadata": {"issue_id": 178, "title": "Action     | HOLD - Reasoning: Error in portfolio management, defaulting to hold", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "20a866bb-8809-4f71-b9a1-d27e4c738625", "node_type": "4", "metadata": {"issue_id": 178, "title": "Action     | HOLD - Reasoning: Error in portfolio management, defaulting to hold", "state": "closed", "labels": [], "type": "issue"}, "hash": "93b83e47ddcfdf7c2124ccd5ad2d327883d412596ef069f7ea570406e8ad0ba2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Action     | HOLD - Reasoning: Error in portfolio management, defaulting to hold\n\nDescription: Why do I get this message for all the stocks, when running the poetry run python src/main.py --ticker AAPL,MSFT,NVDA,TSLA --show-reasoning?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 256, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "77b8208a-3df4-497c-b3e3-7a64c54a180a", "embedding": null, "metadata": {"issue_id": 176, "title": "TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType'", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "805c50af-6d84-4d98-b914-ca7f8e1f513c", "node_type": "4", "metadata": {"issue_id": 176, "title": "TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType'", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "99cd91ccd1813c6ff30c0a41e7b9105785e543a664ecbc3d86e9094c2a9d6012", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType'\n\nDescription: **Describe the bug** A clear and concise description of what the bug is. when I running \"poetry run python src/main.py --ticker AAPL,MSFT,NVDA\" there is a bug: ai-hedge-fund\\src\\data\\cache.py\", line 11, in Cache def _merge_data(self, existing: list[dict] | None, new_data: list[dict], key_field: str) -> list[dict]: TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType'ai-hedge-fund\\src\\data\\cache.py\", line 11, in Cache def _merge_data(self, existing: list[dict] | None, new_data: list[dict], key_field: str) -> list[dict]: TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType' **Screenshot** Add a screenshot of the bug to help explain your problem. **Additional context** Add any other context about the problem here.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 960, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "804d45c0-7b3c-48e7-abbd-d26ee43def17", "embedding": null, "metadata": {"issue_id": 175, "title": "Has it performed well?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bcac52e4-26ff-4c57-b489-b398ddd5c75e", "node_type": "4", "metadata": {"issue_id": 175, "title": "Has it performed well?", "state": "closed", "labels": [], "type": "issue"}, "hash": "1797f3e708a85a276920b5c06b300afa167fc4f54bf1f8e70ced77f46f15330f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Has it performed well?\n\nDescription: Hey guys, has anyone used it for real trading? Has it performed well?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 128, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "1f30e219-659e-4a2f-9efe-a1ab0b7c3cf7", "embedding": null, "metadata": {"issue_id": 173, "title": "Financial API Server Error (500) When Fetching AAPL Data", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f8741cb5-d978-4341-945a-f0877d709105", "node_type": "4", "metadata": {"issue_id": 173, "title": "Financial API Server Error (500) When Fetching AAPL Data", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "19b26405a05124e294dce75c4cdcccc292976df43ac0f49875b654fe723a6b92", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Financial API Server Error (500) When Fetching AAPL Data\n\nDescription: **Describe the bug** When running the hedge fund simulation with AAPL, MSFT, and NVDA tickers, the program crashes with a 500 server error while trying to fetch financial metrics for AAPL. The error specifically occurs in the Charlie Munger analyst module. **Importantly, the API key is valid and works correctly when tested via curl.** **Screenshot** <img width=\"1435\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9466abd6-8c0e-4f40-a448-f647945f33b0\" /> **Additional context** Error occurs during the execution of get_financial_metrics() function in the API tools module The server returns a 500 internal server error when requesting AAPL financial data The error happens specifically during Charlie Munger analyst's analysis process Command used: poetry run python src/main.py --ticker AAPL,MSFT,NVDA Error traceback shows the failure in /src/tools/api.py at line 77 **Steps to reproduce** 1. Run the command poetry run python src/main.py --ticker AAPL,MSFT,NVDA 2. Select Charlie Munger as one of the analysts 3. Execute the hedge fund simulation 4. Observe the 500 error when attempting to fetch AAPL financial metrics\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1297, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4f268a57-2b54-4639-9637-e278f65d86a5", "embedding": null, "metadata": {"issue_id": 170, "title": "Backtest results are inconsistent across runs", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ca9f079a-6211-4fb4-a67e-3128544abf81", "node_type": "4", "metadata": {"issue_id": 170, "title": "Backtest results are inconsistent across runs", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b45785e039a22abb03205e23f5b503142cfd5aef3e2c459749661f9143d98cb3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Backtest results are inconsistent across runs\n\nDescription: **Describe the feature you'd like** The backtest results vary each time the test is executed, even when using the same input parameters and dataset. This inconsistency makes it difficult to validate strategies and compare performance across runs.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 421, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f850b023-46fb-4a1a-8c49-fc6eaff6c668", "embedding": null, "metadata": {"issue_id": 168, "title": "Feature Request: Interactive Streamlit Web Interface for AI Hedge Fund", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fb8e31d-a987-4075-9a65-1f914698e81a", "node_type": "4", "metadata": {"issue_id": 168, "title": "Feature Request: Interactive Streamlit Web Interface for AI Hedge Fund", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "2a19b61b9ced08dbdec94a016c09661e7321ae9f1ff4caf4d62a8e3560eece79", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Feature Request: Interactive Streamlit Web Interface for AI Hedge Fund\n\nDescription: We propose adding an interactive web interface using Streamlit to the AI Hedge Fund project. This would make the project more accessible to users without technical knowledge and provide visualization capabilities to better understand the trading decisions and performance of the AI agents.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 489, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "5b31e343-349c-4c6d-a0fa-f397765bf847", "embedding": null, "metadata": {"issue_id": 166, "title": "Github Action Enhancement: Adding a workflow for linting code using ruff", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0cba52a-1354-415c-8ef5-a9dbfe344645", "node_type": "4", "metadata": {"issue_id": 166, "title": "Github Action Enhancement: Adding a workflow for linting code using ruff", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "711f921bd7d9d1f4979ff0453189e3e99d060e97a86e7ab656ed1ae8a3458d44", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Github Action Enhancement: Adding a workflow for linting code using ruff\n\nDescription: Feature I'm suggesting a GitHub workflow that uses Ruff for linting the code. Such that, the workflow will: \u2705 Automatically run Ruff linting whenever we push code or create a pull request. \u2705 Show linting errors, if any, in GitHub Actions. \u2705 Optionally allow to manually trigger the workflow using workflow_dispatch. If permitted, I can work on this feature....by first creating a simple workflow and then developing it interactively over time. Requirements A yaml file with cloud hosted runners. > Multiple workflows we can work upon, but this is a simple one yet.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 766, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8e1464ed-0cd5-4ac4-a6cd-040d1b4ff599", "embedding": null, "metadata": {"issue_id": 165, "title": "Can this program operate in the A-share market?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e76eb0d2-3eaa-4c5c-aaa7-9127e36db733", "node_type": "4", "metadata": {"issue_id": 165, "title": "Can this program operate in the A-share market?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "babbe7c9d4d62048433f86ae74ab31b9be57cfcf7ad781591269e504ffddedb2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Can this program operate in the A-share market?\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 272, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f8d3e1d8-245e-4971-8b09-b48b6542b0ce", "embedding": null, "metadata": {"issue_id": 164, "title": "No data found backtesting", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62b0f886-3eb2-4d44-be17-3741ec7ee20e", "node_type": "4", "metadata": {"issue_id": 164, "title": "No data found backtesting", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "a2cf98e175b006bfb19b935d9302f1e86968c5d00201718b1c1d48d5f48c257d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: No data found backtesting\n\nDescription: **Describe the bug** When running backtesting on ticker [CODE_BLOCK], we get an exception indicating that there was no data found - news data. The issue was found when running the command: [CODE_BLOCK] **Screenshot** !Image **Additional context** I guess there needs to be implemented a better error handling\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 436, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "7975970b-5933-414b-b9c9-33c1a2d40335", "embedding": null, "metadata": {"issue_id": 161, "title": "TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "57f96afd-f4eb-4901-a5aa-cdc5bbfe1d3d", "node_type": "4", "metadata": {"issue_id": 161, "title": "TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "c1be916225a322df5efdff531d88aed570c5daf06b0b4acdeb8d8de6db3d964b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'\n\nDescription: !Image\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 180, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e7dcce7d-7524-43a9-9389-6fda5fbc3e86", "embedding": null, "metadata": {"issue_id": 157, "title": "KeyError: 'intrinsic_value'", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eb2de4b8-611d-490f-8c66-3b9ad7a234f1", "node_type": "4", "metadata": {"issue_id": 157, "title": "KeyError: 'intrinsic_value'", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "1a1bed8189cd08db0cfe2d8a832e84b542ff1eef032beac9e4de1d80719a6b19", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: KeyError: 'intrinsic_value'\n\nDescription: **Describe the bug** Running the command: poetry run python src/main.py --ticker JD **Screenshot** \u22ef Warren Buffett [JD] Calculating intrinsic value Traceback (most recent call last): File \"/home/myusername/projects/aihedge0309/src/main.py\", line 278, in <module> result = run_hedge_fund( File \"/home/myusername/projects/aihedge0309/src/main.py\", line 74, in run_hedge_fund final_state = agent.invoke( File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 1929, in invoke for chunk in self.stream( File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 1649, in stream for _ in runner.tick( File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/pregel/runner.py\", line 160, in tick _panic_or_proceed( File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/pregel/runner.py\", line 370, in _panic_or_proceed raise exc File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/pregel/executor.py\", line 70, in done task.result() File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result return self.__get_result() File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result raise self._exception File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run result = self.fn(*self.args, **self.kwargs) File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/pregel/retry.py\", line 44, in run_with_retry task.proc.invoke(task.input, config) File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/utils/runnable.py\", line 410, in invoke input = context.run(step.invoke, input, config, **kwargs) File \"/root/.cache/pypoetry/virtualenvs/ai-hedge-fund-uuTkxgfd-py3.10/lib/python3.10/site-packages/langgraph/utils/runnable.py\", line 184, in invoke ret = context.run(self.func, input, **kwargs) File \"/home/myusername/projects/aihedge0309/src/agents/warren_buffett.py\", line 69, in warren_buffett_agent intrinsic_value = intrinsic_value_analysis[\"intrinsic_value\"] KeyError: 'intrinsic_value' **Additional context** The program crash\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2532, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ea4960ee-021a-49d9-a7ec-840671bb0a54", "embedding": null, "metadata": {"issue_id": 155, "title": "Incorrect Portfolio Initialization (Margin Requirement is Misused)", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d4c3813a-23c4-4664-9e7a-5af6724fa9fe", "node_type": "4", "metadata": {"issue_id": 155, "title": "Incorrect Portfolio Initialization (Margin Requirement is Misused)", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "e6d9126cfa9c91c78132c6b8b1b106f6c7b770fe99022c7e8287fb2f53dd8578", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Incorrect Portfolio Initialization (Margin Requirement is Misused)\n\nDescription: _The margin requirement (args.margin_requirement) is stored in the wrong place inside the portfolio dictionary , this can cause incorrect risk calculations and potential invalid trading decisions._ What This Code Does Wrong: 1. **Incorrect placement of margin_requirement:** Margin should be tracked per position, not globally at the portfolio level. Keeping it at the top level makes it unclear how margin is allocated across trades. 2. **Potential calculation errors in risk management:** If risk management agents rely on margin_requirement, they may assume it applies to all trades uniformly, leading to incorrect margin calls. 3. **Incompatibility with leveraged positions:** If leverage is applied, there is no mechanism to track which positions require margin. **old part** !Image **fixed part** !Image****\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 982, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "648e5b3a-f6a3-4c93-975d-599790fa100e", "embedding": null, "metadata": {"issue_id": 153, "title": "Running the model using Ollama", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1513e615-623c-481e-a00e-55acc0364d1f", "node_type": "4", "metadata": {"issue_id": 153, "title": "Running the model using Ollama", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "72a03f263ed9a424260d36fa22a6910dcb6cde0a84574a24b0058d421af90a10", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Running the model using Ollama\n\nDescription: Can we run this code using LLM provided by Ollama\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 209, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "5d5f4b76-7318-43b1-8b16-7bad07f1de67", "embedding": null, "metadata": {"issue_id": 148, "title": "Missing Exception Handling in run_hedge_fund() will failed", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "634d69be-2660-4c0e-b367-8c028382c4e2", "node_type": "4", "metadata": {"issue_id": 148, "title": "Missing Exception Handling in run_hedge_fund() will failed", "state": "closed", "labels": [], "type": "issue"}, "hash": "2c0de19371eb1adc4425c10d0328313fce4bcd9e2b0c344f75f10a94064a83a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Missing Exception Handling in run_hedge_fund() will failed\n\nDescription: if not final_state[\"messages\"]: raise ValueError(\"No messages returned from the hedge fund agent\")\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 193, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9f8f1ee8-4761-4598-85f0-6a85c7a47d76", "embedding": null, "metadata": {"issue_id": 147, "title": "Better error handling", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3935dc4d-f76f-4310-b622-b45a42cfdad8", "node_type": "4", "metadata": {"issue_id": 147, "title": "Better error handling", "state": "closed", "labels": [], "type": "issue"}, "hash": "ac2fefc83470d6e0a41fc426c51ba8da8c8dbd7372e8b7c6611bd4f6fc547fd1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Better error handling\n\nDescription: This is a test issue. pls ignore.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 91, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "cd6f7f9d-2b90-451d-9993-04094548d6d5", "embedding": null, "metadata": {"issue_id": 146, "title": "Replacing poetry with UV", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bd210cde-2848-4259-886d-f7f3a12f7d8e", "node_type": "4", "metadata": {"issue_id": 146, "title": "Replacing poetry with UV", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "3c3d8ed0641e1b1c8b93ab404c6ce34b40133675d04dd49bcbb56fd948acf30d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Replacing poetry with UV\n\nDescription: Uv is an extremely fast drop-in replacement for tools like poetry. It would be very cool to see this implemented here. https://docs.astral.sh/uv/\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 299, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d44a45f8-dc32-4a00-b041-3db6a5596b0b", "embedding": null, "metadata": {"issue_id": 145, "title": "dockerized version", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4fe12343-5795-447a-9f6a-188a53dcdd6c", "node_type": "4", "metadata": {"issue_id": 145, "title": "dockerized version", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "37dc4fb005c5f4b0a2846d491b39bd0909d345d4293194994d0c1db9baaa8fc7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: dockerized version\n\nDescription: **Describe the feature you'd like** A clear and concise dockerized version\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 222, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "72bf1bed-c36f-491f-9e5d-c1793bdb21f6", "embedding": null, "metadata": {"issue_id": 144, "title": "Test Complete", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2265bec1-5ea1-499d-9862-d21678e03daf", "node_type": "4", "metadata": {"issue_id": 144, "title": "Test Complete", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "11513a5497831780f3b5374cae5f036a8c21a6e7560c2f6cfd1611eb57c714b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Test Complete\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 238, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6bf68973-5f73-45f6-9e97-00f65dc01390", "embedding": null, "metadata": {"issue_id": 143, "title": "Test", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "98ae1cd3-2c2b-4357-81ba-1ed61b686952", "node_type": "4", "metadata": {"issue_id": 143, "title": "Test", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "2d714119800e85d225d6633cc706156aab1d5b38abcc8e821350bd99636fd77b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Test\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 229, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b4a4cfb9-39f5-4ffa-945f-d92b7e4f8550", "embedding": null, "metadata": {"issue_id": 141, "title": "Improve JSON Parsing Error Handling in parse_hedge_fund_response() in main.py", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3a894ad4-112e-47db-b50c-4910edb878b6", "node_type": "4", "metadata": {"issue_id": 141, "title": "Improve JSON Parsing Error Handling in parse_hedge_fund_response() in main.py", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "ad029243a6a991c571c5c80b104bdfdec49927d1b24dabe907949c206f3c9fb9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Improve JSON Parsing Error Handling in parse_hedge_fund_response() in main.py\n\nDescription: The function parse_hedge_fund_response(response) currently has a broad except: clause that catches all exceptions, including those unrelated to JSON parsing. This can lead to: - Hiding real errors (e.g., None being passed instead of valid JSON). - Making debugging harder by suppressing detailed error messages. - Unexpected behavior when the function silently fails and returns None without logging the root cause. **Current Implementation of the function:** !Image **Proposed Fix**: !Image **Expected Improvement**: Narrows down on classifying variety of errors providing more information into the issue.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 786, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "2719a82a-83c1-4731-a6a5-2c8e7d02ca26", "embedding": null, "metadata": {"issue_id": 139, "title": "Fail gracefully when data is not available to save credits.", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4368ec33-29d0-46d8-93fc-dad944e4fbf7", "node_type": "4", "metadata": {"issue_id": 139, "title": "Fail gracefully when data is not available to save credits.", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "517fc89fe4e563a6e9b33f3391d87ec4b94a3db6be9e93e0ace5911fd276d75a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Fail gracefully when data is not available to save credits.\n\nDescription: There seem to be many exceptions raised which halt the script, when it may be possible for the error to be communicated, and the report just not have the details which could not be found. This is somewhat of a bug report, but I see it as an enhancement, because it would save me lots of credits with financialdatasets.ai. It gets several reports finished, but then it is unable to get responses for some requests. Rather than just bail on all reports, it would be better to just tell that some reports were unable to be completed, and to display the reports it could generate. Multiple times I've run the script, watched my credits get spent on requests, it finishes several of the reports, and then dumps the whole process when it receives one 200 HTTP response.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 952, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "27e09217-a1dc-4bfd-b90f-2805d2c65718", "embedding": null, "metadata": {"issue_id": 136, "title": "Website / App", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e2d23ced-50f5-4ae8-b0eb-e54271544deb", "node_type": "4", "metadata": {"issue_id": 136, "title": "Website / App", "state": "closed", "labels": [], "type": "issue"}, "hash": "14da24d89feaaa2d4eb7e04b3703a87f8b0e3ed3d67782633a5af02c5a487f16", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Website / App\n\nDescription: Is there a website or app already set up we can just login too ?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 114, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "0c489efc-8f5d-4f5b-a66e-b7906ae819aa", "embedding": null, "metadata": {"issue_id": 135, "title": "Cloned version of repo, switching out Poetry for UV, LangChain for PydanticAI, Logfire and OpenRouter.", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b1b94a9c-8078-4e77-98fc-3fb67a0522ed", "node_type": "4", "metadata": {"issue_id": 135, "title": "Cloned version of repo, switching out Poetry for UV, LangChain for PydanticAI, Logfire and OpenRouter.", "state": "closed", "labels": [], "type": "issue"}, "hash": "0ba69f0e3901f5e351925693f1040bf564e388e2a137cbde5b4f62961f2afe06", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Cloned version of repo, switching out Poetry for UV, LangChain for PydanticAI, Logfire and OpenRouter.\n\nDescription: Hi there, I am loving this app, super cool way to show off Financial Datasets. I am wanting to work with UV, PydanticAI, Logfire and OpenRouter, so I vibe coded a very rudimentary working version of this code base to here. Will be working on getting what Viratt has built here working. Any pull requests most welcome. Cheers.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 464, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "fc7b28e1-09e3-43dc-8e9a-628127620907", "embedding": null, "metadata": {"issue_id": 134, "title": "ERROR", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c6f75be4-5c8f-4123-b7bb-ecf0e2398aaf", "node_type": "4", "metadata": {"issue_id": 134, "title": "ERROR", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "c5883e2acb81a3b1d3bd4a78ecb23feaf8e355fcfeb5764246b3e3eeb051d411", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: ERROR\n\nDescription: Seems that the code is not working, I have put everysingle API key for not having errors, but its not working. Also im sure i Have installed poetry well, but is there any way to debug it? thank you! !Image\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 313, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9b593c1a-78a7-4ed2-9de9-f7001c42760b", "embedding": null, "metadata": {"issue_id": 132, "title": "The error \"ZeroDivisionError: float division by zero\" in cathie_wood.py indicates that the R&D expenses for a company (likely KO - Coca-Cola) were zero at the start, causing the division operation to fail.", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fc9fd36b-097e-44de-ac51-2f19c55e7dbf", "node_type": "4", "metadata": {"issue_id": 132, "title": "The error \"ZeroDivisionError: float division by zero\" in cathie_wood.py indicates that the R&D expenses for a company (likely KO - Coca-Cola) were zero at the start, causing the division operation to fail.", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "faf5a5061d63b7fc9fa8e90efb5a9545c2684a37efe73f5c441ba85dd5eb8790", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: The error \"ZeroDivisionError: float division by zero\" in cathie_wood.py indicates that the R&D expenses for a company (likely KO - Coca-Cola) were zero at the start, causing the division operation to fail.\n\nDescription: Edit cathie_wood.py in line 258 to avoid division by zero: Replace: rd_growth = (rd_expenses[-1] - rd_expenses[0]) / abs(rd_expenses[0]) if rd_expenses[0] == 0: rd_growth = 0 Avoid division by zero else: rd_growth = (rd_expenses[-1] - rd_expenses[0]) / abs(rd_expenses[0])\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 580, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b0d7f878-1191-4727-877b-377762858db7", "embedding": null, "metadata": {"issue_id": 131, "title": "The error indicates that the Warren Buffett agent is attempting to access a key 'intrinsic_value', but it doesn't exist in the intrinsic_value_analysis dictionary", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "35432107-078b-4cf7-96e6-d3ee52657699", "node_type": "4", "metadata": {"issue_id": 131, "title": "The error indicates that the Warren Buffett agent is attempting to access a key 'intrinsic_value', but it doesn't exist in the intrinsic_value_analysis dictionary", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "62c28a4f42d6caa143542ee4cbd71389968073972c571862664221b9afec5f46", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: The error indicates that the Warren Buffett agent is attempting to access a key 'intrinsic_value', but it doesn't exist in the intrinsic_value_analysis dictionary\n\nDescription: Modify src/agents/warren_buffett.py (Line 69) intrinsic_value = intrinsic_value_analysis[\"intrinsic_value\"] Modify it to: intrinsic_value = intrinsic_value_analysis.get(\"intrinsic_value\", None) Use .get() instead\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 477, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a6b1a339-788b-4292-86f0-6445694e4692", "embedding": null, "metadata": {"issue_id": 130, "title": "Support For Gemini Models and OpenRouter", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f5f35c1f-9e7a-411b-bfa9-bbcb4d2083fd", "node_type": "4", "metadata": {"issue_id": 130, "title": "Support For Gemini Models and OpenRouter", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "ced2569039175510a68d15bc92dbda198efced48ec13524d78bfa68a6f01c875", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Support For Gemini Models and OpenRouter\n\nDescription: **Describe the feature you'd like** Allow Gemini Models to be used through the OpenAI api and add the use of OpenRouter with model selection\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 310, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "659557ca-6818-4688-aa9d-683226cb73b5", "embedding": null, "metadata": {"issue_id": 127, "title": "Wallet hedge", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d6e8e52f-8005-4706-ac23-5718e32c15bb", "node_type": "4", "metadata": {"issue_id": 127, "title": "Wallet hedge", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "5fe426a4483886ef361ef0ce254888fc7decc267de67ce35ff6350562c8134d0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Wallet hedge\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 237, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "fcfad2d2-a48f-4f94-87e0-09b4df01829a", "embedding": null, "metadata": {"issue_id": 125, "title": "Server Error (500)", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c5d31e8a-32a7-4b19-ac40-892ffbb08b6a", "node_type": "4", "metadata": {"issue_id": 125, "title": "Server Error (500)", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "feff9d720c0e582f2f582e81efa46d347ffae95ed3b6f3d12fedcb4eec40cb7c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Server Error (500)\n\nDescription: The server is creating a 500 error. Is there any server issues for the moment? File \"/home/*****/projects/ai-hedge-fund/src/agents/sentiment.py\", line 25, in sentiment_agent insider_trades = get_insider_trades( File \"/home/*****/projects/ai-hedge-fund/src/tools/api.py\", line 162, in get_insider_trades raise Exception(f\"Error fetching data: {ticker} {limit} {start_date} {current_end_date} {response.status_code} - {response.text}\") Exception: Error fetching data: MKSI 1000 None 2025-03-05 500 - <!doctype html> <html lang=\"en\"> <head> <title>Server Error (500)</title> </head> <body> <h1>Server Error (500)</h1><p></p> </body> </html>\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 758, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a7c810b8-9ccf-4627-8329-98ba70c60c9a", "embedding": null, "metadata": {"issue_id": 124, "title": "Can the model support calling a specified address?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b8e89b2d-c7d8-490f-8410-685dc2fa0180", "node_type": "4", "metadata": {"issue_id": 124, "title": "Can the model support calling a specified address?", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "ec11000eb314c687b2698d3809a8f9fe6b947562682fb1de331de8af8126c465", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Can the model support calling a specified address?\n\nDescription: Can the model support calling a specified address? current .env.example How to set the API call address for the corresponding model when the file only contains the model's Key settings?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 365, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "83d6bd48-fa8a-4615-ae4b-ab9e0ee0048a", "embedding": null, "metadata": {"issue_id": 123, "title": "Standard data source integration", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6f38fe64-0510-4e9c-9cc5-18d61d23b363", "node_type": "4", "metadata": {"issue_id": 123, "title": "Standard data source integration", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "6391e069a61c3b88805e84ebcbd28494cbbb5431e38ec04d6aab144a84af3cfe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Standard data source integration\n\nDescription: Standard Data Source Integration Integrations with various data sources should follow a standard protocol. Anthropic recently released an open-source protocol called MCP for integrating LLM applications with external sources. This repository could enhance agent capabilities by leveraging such a protocol. Issue 42 focuses on a base abstract interface for data integration. Adopting either the abstraction in 42 or Anthropic's MCP protocol would maximize the repository's capabilities.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 647, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "cef6d550-e1b7-4d5e-a7aa-5e57dc0d20cd", "embedding": null, "metadata": {"issue_id": 121, "title": "For further information visit https://errors.pydantic.dev/2.10/v/missing", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0ba694f2-a0cc-4ded-8e8e-0c0e61f1e5bc", "node_type": "4", "metadata": {"issue_id": 121, "title": "For further information visit https://errors.pydantic.dev/2.10/v/missing", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "646d8d7b64171ae59d24b2f987d077e50ebff88db3d2b916c1c1434d2c5d771a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: For further information visit https://errors.pydantic.dev/2.10/v/missing\n\nDescription: For further information visit https://errors.pydantic.dev/2.10/v/missing\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 247, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b12d3651-48a6-4b32-92f1-3d3b84404115", "embedding": null, "metadata": {"issue_id": 120, "title": "Warning: Missing 'calendar_date' for ticker AAPL Warning: Missing 'calendar_date' for ticker AAPL", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "efe227e9-dd42-44d3-9651-d11f64d5c1ed", "node_type": "4", "metadata": {"issue_id": 120, "title": "Warning: Missing 'calendar_date' for ticker AAPL Warning: Missing 'calendar_date' for ticker AAPL", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "56c73c430a704607fb92020de85530cc9dde04d0a8c69ad036833b7e19e8a944", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Warning: Missing 'calendar_date' for ticker AAPL Warning: Missing 'calendar_date' for ticker AAPL\n\nDescription: Warning: Missing 'calendar_date' for ticker AAPL Warning: Missing 'calendar_date' for ticker AAPL\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 297, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "21283e17-e4f2-4900-9983-a1c8f149bc6b", "embedding": null, "metadata": {"issue_id": 119, "title": "Integrate the free data service like yfinance", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "418fda75-58e8-42dc-8483-2ee284ef8225", "node_type": "4", "metadata": {"issue_id": 119, "title": "Integrate the free data service like yfinance", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "c3830e03da9ef1650faf8465a326a9884e70ff8a245ef44f849ace9910e70ff3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Integrate the free data service like yfinance\n\nDescription: Data from financialdatasets.ai is too expensive. It is not friendly when performing testing and debug. Could it possible to integrate with a free financial data service like using yfinance?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 364, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "078437f4-951c-4d2c-abdd-f7daf1bd934b", "embedding": null, "metadata": {"issue_id": 117, "title": "Add RL to improve performance using ratios as outcome rewards", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b7a19dee-5fce-4f3e-9a29-7e0731d0cda0", "node_type": "4", "metadata": {"issue_id": 117, "title": "Add RL to improve performance using ratios as outcome rewards", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "f8dcc21395f8cc5a3dad5d9fe6dd937cf35887498e1ca11449f09eadc8eb64c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Add RL to improve performance using ratios as outcome rewards\n\nDescription: Can we use the method discussed in this repo to implement a similar model improvement technique using Reinforcement Learning? The outcome rewards here can be replaced with various financial ratios.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 388, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8060aa34-7bde-4975-8a6e-bd4bfc87f5df", "embedding": null, "metadata": {"issue_id": 116, "title": "errors during task", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b5413915-4b48-4b16-b2d9-0c0b779a9188", "node_type": "4", "metadata": {"issue_id": 116, "title": "errors during task", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "aeff33ddef37faa5b03c1e7d70eed2b91d986cee05d2e97c4e9ffbf9cca619e4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: errors during task\n\nDescription: Tickers: OKLO,NNE,SMR File \"/mnt/d/Data/AIHedge/ai-hedge-fund/src/agents/cathie_wood.py\", line 196, in analyze_disruptive_potential rev_growth = (revenues[-1] - revenues[0]) / abs(revenues[0]) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~ ZeroDivisionError: float division by zero During task with name 'cathie_wood_agent' and id 'ca42911f-62ae-d7dd-f258-9129618d39b9' Ticker: PDD File \"/mnt/d/Data/AIHedge/ai-hedge-fund/src/agents/warren_buffett.py\", line 69, in warren_buffett_agent intrinsic_value = intrinsic_value_analysis[\"intrinsic_value\"] ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^ KeyError: 'intrinsic_value' During task with name 'warren_buffett_agent' and id '4adb2c97-bfcc-8a11-aabc-d6bea21a8f17'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 832, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c0aabed0-7f89-442e-bd20-573c015489c5", "embedding": null, "metadata": {"issue_id": 115, "title": "connect with a real wallet", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6835c7f7-af76-47bd-90d9-9b161d4f6b57", "node_type": "4", "metadata": {"issue_id": 115, "title": "connect with a real wallet", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "c59a7a93538ba789fd4d3d5c5379564f65d6a0dbb98f6d0548e9bd259cecc1bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: connect with a real wallet\n\nDescription: Hey, i know this project is not for real trading but, as we can see the performance and the reliability of all agents i think it will be interesting to test on a demo wallet and let it many days and see the return after few weeks What do y\u2019all think about it ?\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 416, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b58b5650-0b99-4aba-9892-c15eceb9b12b", "embedding": null, "metadata": {"issue_id": 114, "title": "AzureOpenAI", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eb1c2dec-a3c4-49bb-b8d3-4647ac3ec374", "node_type": "4", "metadata": {"issue_id": 114, "title": "AzureOpenAI", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "676712ed233667fed3d592fa4e918d93e6738781889126d3be3dd31f9e64328b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: AzureOpenAI\n\nDescription: Hello Team, Can we get Azure OpenAI added to LLM? All the API use by OpenAI is the same with Azure OpenAI. Azure is just cheaper to use and would be a good option to help the community with cost. Example: AZURE_OPENAI_KEY=Your Key AZURE_OPENAI_ENDPOINT=https://yourinstancename-northcentralus.openai.azure.com/ northcentralus = Location (Location can be different depending on where the instance is deployed) AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo gpt-35-turbo = Model can be different depending on user choices.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 651, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6fb045e0-d9cd-4884-a6cd-0fb1a7230162", "embedding": null, "metadata": {"issue_id": 113, "title": "Collaboration Opportunity", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "75aa432d-b404-4ccb-8dd5-5c1b9dbc7b79", "node_type": "4", "metadata": {"issue_id": 113, "title": "Collaboration Opportunity", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "8a3310f2c409445ab963a772596e5bd520d5e4442262dffcb1be41e9cb76c44d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Collaboration Opportunity\n\nDescription: I am reaching out on behalf of the FigDAO team. We are a group of public health experts with extensive experience in global health, united by the belief that blockchain and AI technologies can drive transformative change in global health and social impact. The global health landscape is facing unprecedented challenges that demand urgent, innovative, and sustainable solutions. Traditional funding models\u2014dominated by government aid, multilateral institutions, and philanthropic foundations\u2014are proving to be insufficient, bureaucratically rigid, and slow to respond to evolving crises. To address these gaps, we are developing the Global Health Fund, that leverages decentralization, AI, and blockchain to create a faster, more transparent, and inclusive funding system for global health challanges. A key part of this initiative is the creation of an AI-powered global health fund, automating essential functions of global health infrastructure through AI agents. As experts in healthcare, we are seeking partnerships with technology leaders to drive innovation in our field. After exploring your project, we see strong synergies and potential collaboration opportunities. Representing and understanding the health sector we can ensure practical implementation of AI hedge fund in real life projects. We would love to explore partnership prospects. We are open to conversation on potential collaboration opportunities.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1576, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "7455603f-63bb-4f33-8f47-c547dd95d68d", "embedding": null, "metadata": {"issue_id": 112, "title": "enhance insider trading sentiment analysis", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9886e264-96aa-4b4c-834e-c1d7a707b8ea", "node_type": "4", "metadata": {"issue_id": 112, "title": "enhance insider trading sentiment analysis", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "652882a869de6625a81c4e288338b94edc653cbcf429c3b55b64df5bd5470640", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: enhance insider trading sentiment analysis\n\nDescription: **Description** Enhance insider trading sentiment analysis with the following factors: - seller/buyer role (CEO, CFO, etc.) - transaction amount - recency factor - etc. The current analysis is very straightforward with fixed weights. **Benefits** - Better insider trading sentiment identification\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 468, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "40d5d462-48c8-4bb7-902c-d0a9bbb881e9", "embedding": null, "metadata": {"issue_id": 111, "title": "fails for $GOOG", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "80c3bd64-3f7c-439f-92ff-9b240b476162", "node_type": "4", "metadata": {"issue_id": 111, "title": "fails for $GOOG", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "63759f88b6e03551710075edb3a8f3d6dbc60ffd11e5274a0fb8bd7fb67b8569", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: fails for $GOOG\n\nDescription: **Describe the bug** running [CODE_BLOCK] results in a ticker not found error **Screenshot** <img width=\"1824\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ff76e181-b88e-4d77-b1d7-f7d5927b03cd\" /> **Additional context** Looks like it's because financial datasets is unable to resolve the ticker symbol. It works with \"GOOGL\" though.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 465, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6a97e8a0-997d-486c-a057-714e45362fdd", "embedding": null, "metadata": {"issue_id": 107, "title": "problem in final resultat backtest", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bd504eaa-ca22-4107-b6ee-52f665f997af", "node_type": "4", "metadata": {"issue_id": 107, "title": "problem in final resultat backtest", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "47fe5af7bb93ec0da1b9ef062e7f17b3724d2f47e8f76cc9bf13b73a6d9b2965", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: problem in final resultat backtest\n\nDescription: just below\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 147, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "038fdb51-b754-46c5-8c09-9c6a0ce91bd9", "embedding": null, "metadata": {"issue_id": 106, "title": "final result of backtest", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "abbe4f7a-f4d6-49de-bf23-d1ea8aa7f4ea", "node_type": "4", "metadata": {"issue_id": 106, "title": "final result of backtest", "state": "closed", "labels": [], "type": "issue"}, "hash": "3fa63e6e2ca93979898a434df3980d0725dec2e19eae9a046476c3073981a9ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: final result of backtest\n\nDescription: hey everyone, as you can see in my final report of the backtest i don't have the same results : !Image how can i have the total value (start 100K) and the cash position ? like this : <img width=\"941\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/aa6ddbec-1cba-4a7d-8bed-98a1a583e03f\" /> <img width=\"941\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9e3b282a-a651-4986-b2d9-dc8b7fbe348b\" />\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 479, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f065e1e1-1c60-415e-a5ee-372c5e15da7f", "embedding": null, "metadata": {"issue_id": 102, "title": "Basic Install - First run - Bug", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c0f7f792-2e50-4ac4-ba0c-3e931ed1c37f", "node_type": "4", "metadata": {"issue_id": 102, "title": "Basic Install - First run - Bug", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "ef4d446f328208ca267a22b37c70d92a05669f316a70f995354a4514bda0f58c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Basic Install - First run - Bug\n\nDescription: Tried running it : poetry run python src/main.py --ticker AAPL --show-reasoning and get this error. from agents.fundamentals import fundamentals_agent def get_prices(self, ticker: str) -> list[dict[str, any]] | None: TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 432, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "507c8ee4-c7bc-41c4-844d-6496ce790943", "embedding": null, "metadata": {"issue_id": 99, "title": "Add langgraph.json to allow running the app with langgraph CLI", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fae496a2-5747-4a5e-aaa0-159a744ba074", "node_type": "4", "metadata": {"issue_id": 99, "title": "Add langgraph.json to allow running the app with langgraph CLI", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b603de49bc3b36dc235f51b29c501ac48a69662bea081c0841fe0aa6655f86c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Add langgraph.json to allow running the app with langgraph CLI\n\nDescription: **Description** Add a langgraph.json configuration file to the repository to enable running the application with the langgraph CLI. This will simplify the setup process and improve usability for developers using the langgraph tool. The LangGraph command line interface includes commands to build and run a LangGraph Cloud API server locally in Docker. For development and testing, you can use the CLI to deploy a local API server as an alternative. **Benefits** - Simplifies the setup process for new developers. - Ensures consistency in configuration. - Enhances the developer experience when using the langgraph CLI.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 810, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f0a83623-588c-466c-9065-422bdc95918a", "embedding": null, "metadata": {"issue_id": 98, "title": "tkinter errors", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a742e38c-da17-4eb7-9875-d994a3a568e2", "node_type": "4", "metadata": {"issue_id": 98, "title": "tkinter errors", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "320cdd65cff2d2e5c47c8f7b421d349b59f83c69d51b7ea1c69c11f81863dea9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: tkinter errors\n\nDescription: **Describe the bug** When I run the example code, I'm getting: [CODE_BLOCK] **Additional context** Ran the installation instructions with a small modification: curl -sSL https://install.python-poetry.org | python3.11 -\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 335, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c2a28bf2-f491-4664-9f25-8cc32218d6a4", "embedding": null, "metadata": {"issue_id": 97, "title": "o3-mini", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0f8f2398-fa41-4084-94ce-9ab1a2041c4e", "node_type": "4", "metadata": {"issue_id": 97, "title": "o3-mini", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "569ce9ee0cc62d923e1f8dabaa788051050b369466ea1fdf8e9decb4a706d884", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: o3-mini\n\nDescription: **Describe the bug** When selecting o3-mini as the LLM, I'm presented with an issue and unable to proceed. **Error Message:** Error in portfolio management: Error code: 404 - {'error': {'message': 'The model o3-mini does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}} **Additional context** https://platform.openai.com/docs/modelso3-mini https://platform.openai.com/docs/guides/reasoning - I've tried adding reasoning_effort=\"medium\" to models.py and I've tried it without reasoning_effort and it still doesn't work.\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 700, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ef478f4e-f0a5-42a9-8d52-b85fcd0bd51a", "embedding": null, "metadata": {"issue_id": 95, "title": "Unhandled Exceptions for Different Tickers", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "130f24e8-b193-42ca-a9bc-9a8f3c57dbdb", "node_type": "4", "metadata": {"issue_id": 95, "title": "Unhandled Exceptions for Different Tickers", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "f9a95e4519edff0b1d093b8462492ec234d466999004ae84e5c86eb5c388dd22", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Unhandled Exceptions for Different Tickers\n\nDescription: **Describe the Bug** **Hi everyone,** First off, thank you all for the effort you\u2019ve put into this project! I really appreciate the work being done. I\u2019ve come across a few cases where exceptions aren\u2019t properly handled, leading to crashes (or consuming financialdatasets.ai api). One example is when running the AI Hedge Fund script with the following setup: [CODE_BLOCK] After selecting analysts and the LLM model, everything runs fine until the Valuation Analyst step, where the script crashes with this error: [CODE_BLOCK] Note: I've also encountered other exceptions when choosing different tickers. Let me know if I can provide more details. Thanks again for the great work! \ud83d\ude80 Thanks,\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 834, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a278c721-dfff-4d52-927b-3756b07b9a78", "embedding": null, "metadata": {"issue_id": 91, "title": "Can not run the repo", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1abc0f19-51a8-4c0e-9ceb-40a7227b5557", "node_type": "4", "metadata": {"issue_id": 91, "title": "Can not run the repo", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "9fd93062079d59b88d568f40c541cd447286e3b7fbf6ceb75a8ac69118cdc308", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Can not run the repo\n\nDescription: ai-hedge-fund/src/data/cache.py\", line 11, in Cache def _merge_data(self, existing: list[dict] | None, new_data: list[dict], key_field: str) -> list[dict]: TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType'\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 360, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "5e054459-9682-4537-bb63-89af8622cb30", "embedding": null, "metadata": {"issue_id": 90, "title": "Payman AI Agent for Automated Trade Execution and Compliance", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3d707444-5291-4e19-a71e-038f77663578", "node_type": "4", "metadata": {"issue_id": 90, "title": "Payman AI Agent for Automated Trade Execution and Compliance", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b41dac64c94328cf9df1a3b65646aef3e080613d07a9aad9bc6e99fefac0eb76", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Payman AI Agent for Automated Trade Execution and Compliance\n\nDescription: I\u2019ve been working on integrating Payman AI into an AI hedge fund framework, specifically to automate trade execution while enforcing risk and compliance rules. The goal is to: 1. **Automatically execute trades** based on signals from the **Portfolio Management Agent** without manual intervention. 2. **Enforce compliance policies** (e.g., verifying risk limits, margin requirements, and regulatory constraints) before executing trades. 3. **Track and audit financial transactions** in real time, logging all trade activities for transparency. 4. **Provide real-time alerts and approval workflows**, so flagged transactions can be manually reviewed before execution. **What I\u2019ve Built So Far** I put together a **local implementation** that connects **AI Hedge Fund\u2019s trading signals** to **Payman AI\u2019s financial infrastructure**. Here\u2019s how I did it: - Integrated Payman\u2019s API to send payments and settle trades. - Hooked it up to the **Portfolio Management Agent**, so trades execute only if they meet predefined risk rules. - Added logging to track all transactions, making sure they\u2019re traceable and compliant. - Created an approval system that sends alerts to for high-risk transactions. It\u2019s running well locally, and I\u2019d love to contribute this back to the repo. Can I submit a PR for this? I\u2019d also be happy to refine it based on feedback and make sure it aligns with the overall project goals. Let me know what you think!\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1620, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b45ba7a0-8ae6-496a-a6aa-8e9a2897812f", "embedding": null, "metadata": {"issue_id": 87, "title": "real time trading + custom agents", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4ee68070-b04d-4e1e-a0de-389df6a2ca60", "node_type": "4", "metadata": {"issue_id": 87, "title": "real time trading + custom agents", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "806afc37e4e3da8b25b0652596b078e9cc5593d69d2659d64ea0fbfd0a7b3c4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: real time trading + custom agents\n\nDescription: **real time trading testing + custom agents** - A web app dashboard to aggregate the data of the hedge fund's trades, showing metrics like max drawdown, profit, sharpe, sortino, positions, and profit. - Charts to display growth & trades made in real time. - An LLM agent that assists the user in creating their own custom agent that can do certain things and work cohesively to reach a consensus with other agents. You could then create a community space for sharing and hosting these custom agents, with leaderboards on the ones with the best performing metrics and strategies, or the most upvoted, etc.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 767, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "cebf83a4-17b5-489a-a791-4a808d4d1311", "embedding": null, "metadata": {"issue_id": 83, "title": "Simple streamlit UI and deployment on streamlit", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "27fde311-b4c4-4f5a-93fe-ad77d98e4306", "node_type": "4", "metadata": {"issue_id": 83, "title": "Simple streamlit UI and deployment on streamlit", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "d33b6fe63f69bce7ce9064094de4652e2339d6fbccbb1e28acc9ecebffdc6a55", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Simple streamlit UI and deployment on streamlit\n\nDescription: **Describe the feature you'd like** UI and deployment of the project where person just need to enter the API keys and stock symbol to retrieve the details\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 331, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "27d9dc45-adaf-41f1-bb06-6f980e58de92", "embedding": null, "metadata": {"issue_id": 82, "title": "Why is risk management null?", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "57df0645-9f1f-4509-97aa-c48135895cde", "node_type": "4", "metadata": {"issue_id": 82, "title": "Why is risk management null?", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "39d3a94b359d9c8dd240f0986165faa4595b555640a37bf30f773ad7281d2074", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Why is risk management null?\n\nDescription: Why is the risk management percentage always none?\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 181, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "21d3b56b-46d0-42f1-bd1d-97b2dcd3fa8f", "embedding": null, "metadata": {"issue_id": 79, "title": "Request: choosing different models", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4992db91-dd72-4936-8f2c-ee940c2159b8", "node_type": "4", "metadata": {"issue_id": 79, "title": "Request: choosing different models", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "b010808066521684026ffc0e6b67c55a7ef7bc0557a9979080eb9b4701b96314", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Request: choosing different models\n\nDescription: It would be awesome to be able to pick which model is used. As far as I've seen, it is currently only possible to use OpenAI models. I have also seen a Pull Request to include Grok. How difficult would it be to add the possibility to choose a model instead of using just one? I'm thinking of including the option to choose from a variety of models.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 512, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6806ea56-9b73-4f33-b62b-42a0cc86eddb", "embedding": null, "metadata": {"issue_id": 78, "title": "When running default documented command as test - fail to consider signal \"hold\" as valid", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5e0267f1-9b2e-4511-8aaf-19330d3b9ed4", "node_type": "4", "metadata": {"issue_id": 78, "title": "When running default documented command as test - fail to consider signal \"hold\" as valid", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "be1abdce138581e2b13e63fb6fd8c52979c2d254dc9e45319744799a20381777", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: When running default documented command as test - fail to consider signal \"hold\" as valid\n\nDescription: Hello After completing the process of setting myself up, I did a first run. It ended with the following conclusion, where only \"bullish\", \"bearish\" and \"neutral\" are seen as valid. \"hold\" was not. [CODE_BLOCK] Kind Regards Flo\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 418, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f40519ce-3056-4498-9955-a372b5a38326", "embedding": null, "metadata": {"issue_id": 72, "title": "Error", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2a95a21f-9f07-4e2a-a60d-622776b09dc2", "node_type": "4", "metadata": {"issue_id": 72, "title": "Error", "state": "closed", "labels": [], "type": "issue"}, "hash": "d94c6a46da0657c1e52e767b1986126cb01182229c4c5dc23b3ccca92ba8acd9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Error\n\nDescription: Every time I try to run, I get this error. Though all the module are installed. !Image\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 128, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4bc65cd1-4338-481f-ac1c-0db59038bfe0", "embedding": null, "metadata": {"issue_id": 71, "title": "push the result to discord webhook", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "01433512-d182-416b-875e-8bf3787d19ca", "node_type": "4", "metadata": {"issue_id": 71, "title": "push the result to discord webhook", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "bd1d548435f08469289dc333289db5dfd1d77175ee2bf006db8507b7074fc7b8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: push the result to discord webhook\n\nDescription: **Describe the feature you'd like** A clear and concise description of what you want to happen. great bot detecting stock signals. I am thinking of adding Discord webhook function that every time it output result it will automatically send to Discord Webhook\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 422, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "54086da0-0c0e-48c9-a6f2-2bdfa4012dad", "embedding": null, "metadata": {"issue_id": 68, "title": "ValueError: No insider trades returned (when selecting Sentiment Agent)", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a22a3750-6d54-4a3a-bab0-0e79b059ddc0", "node_type": "4", "metadata": {"issue_id": 68, "title": "ValueError: No insider trades returned (when selecting Sentiment Agent)", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "7a4b8bfd32fcd6850847b219aea2c4e0f35aef6e3978e25e69bf55d381cce6d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: ValueError: No insider trades returned (when selecting Sentiment Agent)\n\nDescription: **Describe the bug** A ValueError is raised when sentiment agent is selected (my chosen ticker was 'ONON') **Copy of Output - my PII redacted** [CODE_BLOCK] **Additional context** I would love to see the output of the sentiment agent for 'ONON' :)\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 421, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "64b3a83e-2236-46be-8a5a-efc8a1cd075f", "embedding": null, "metadata": {"issue_id": 67, "title": "Add arguments to allow for agent selection instead of interactive.", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "876f28a9-a297-4b10-8b3d-c3dc0549fd31", "node_type": "4", "metadata": {"issue_id": 67, "title": "Add arguments to allow for agent selection instead of interactive.", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "8f34871cad14ab556811f307fb7bff451d2e9327a838ff58f808c6329fa6c0c6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Add arguments to allow for agent selection instead of interactive.\n\nDescription: **Describe the feature you'd like** Right now, selecting the agents is an interactive process going through a menu. Please add the option to select agents via arguments or preferences file.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 385, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d41eeec0-9cb9-4d0a-9412-a16bf0881f61", "embedding": null, "metadata": {"issue_id": 64, "title": "discussion: Roadmap for this project", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1848e74c-109d-4881-9bb4-342e403d2a03", "node_type": "4", "metadata": {"issue_id": 64, "title": "discussion: Roadmap for this project", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "4c9ab909c2b39086e960f83191a5dfbd13ff45b65049837bc97b77d1979857d0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: discussion: Roadmap for this project\n\nDescription: I would like to see how I can contribute on this repo. It seems like the repo has good fundamentals. However, it would be helpful to understand your vision (@virattt), so the dev community can focus their efforts. From this issue, I gather other people want to be involved but not sure where to start. In my mind, here's some things that could be improved. Note some items are more speculative, open to pushback. chores \ud83d\udd04 - [ ] Add pydantic models as interfaces between functions (or dataclasses where validation is not needed) - [ ] Type the whole repo using 3.9+ standards (no List/Dict/Union/Optional) - [ ] Add linting (ruff?) - [ ] cicd - linting, black, mypy - [ ] python semantic release in cicd - automatic versioning and changelog - [ ] Testing - I realize this is a tricky one. Due to the nature of LLM's, there is a cost element. Initially, we could have a series of tests that contributors can run locally to make sure there are no regressions or bugs added. Long term, we support open source models that can run in cicd features \ud83d\ude80 - [ ] Add yfinance app for free tier - This has been a popular user request. After we add pydantic models for the API, it should be easy to plug and play other APIs - [ ] Support crypto - Longer term item and not sure of scope, but I certainly think it would be cool - [ ] Take input for risk tolerance - Informs the model how aggressive its recommendations should be - [ ] ...what else? I started with this PR, which adds pydantic models for the outputs.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1665, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "0e81b540-c6c4-49e0-82f6-a50281f409fa", "embedding": null, "metadata": {"issue_id": 62, "title": "Can't run the Backtester", "state": "closed", "labels": ["bug"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "27c5435a-08c7-4fe3-8f70-908064309a55", "node_type": "4", "metadata": {"issue_id": 62, "title": "Can't run the Backtester", "state": "closed", "labels": ["bug"], "type": "issue"}, "hash": "0f9a86f3e8f21287e4cb159b54dcaf92f53cf6cfefc77b1cc49974804ce643e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Can't run the Backtester\n\nDescription: [CODE_BLOCK]\n\nState: closed\n\nLabels: bug\n\nCategories: category-bug\n\nType: Bug report or error", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 139, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "7c94bdb3-046d-4005-98ec-3f68c894aa4a", "embedding": null, "metadata": {"issue_id": 61, "title": "Include Finviz", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "67cff04c-ff8a-4203-ac11-bd4072fb36ad", "node_type": "4", "metadata": {"issue_id": 61, "title": "Include Finviz", "state": "closed", "labels": ["enhancement"], "type": "issue"}, "hash": "0ebb10ef6335ef335fa1c5729c1afa9ed2651100e72e9f2f805222a9862e9b47", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Include Finviz\n\nDescription: Finviz provides a wealth of free information. To include Finviz data, we can use this library.\n\nState: closed\n\nLabels: enhancement\n\nCategories: category-enhancement\n\nType: Feature request or enhancement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 238, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a0a3efac-5388-4b36-b458-3e1b46575f83", "embedding": null, "metadata": {"issue_id": 59, "title": "Error handling still needs to be improved - keep getting different errors", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d6de839b-ea98-4096-b5ff-15f7a9ba1abd", "node_type": "4", "metadata": {"issue_id": 59, "title": "Error handling still needs to be improved - keep getting different errors", "state": "closed", "labels": [], "type": "issue"}, "hash": "21e2380c2b39305a98d53934e7db8f2954af56344da96f99208ceee088155ac4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Error handling still needs to be improved - keep getting different errors\n\nDescription: Tried several combinations, but most failed with errors. Here are a few errors that I encountered: [CODE_BLOCK] [CODE_BLOCK]\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 234, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "2c3ce053-a5b5-4ced-b266-a18c338f77bb", "embedding": null, "metadata": {"issue_id": 54, "title": "How can I get involved?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "feeefd1e-e237-47ca-a46f-07fcd6cbbeff", "node_type": "4", "metadata": {"issue_id": 54, "title": "How can I get involved?", "state": "closed", "labels": [], "type": "issue"}, "hash": "a134545853bf9ffdc2058d980d2e5aa4bc056a0f69f92fadc6817e25947e8067", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How can I get involved?\n\nDescription: Hello, Just wanted to check if you are looking for any help?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 120, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4a4d3070-7fcd-4bea-b99b-5da27411fad6", "embedding": null, "metadata": {"issue_id": 50, "title": "How to test 'sell' decision ", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ff778b93-30b9-4d2f-9678-c6fa4376a24b", "node_type": "4", "metadata": {"issue_id": 50, "title": "How to test 'sell' decision ", "state": "closed", "labels": [], "type": "issue"}, "hash": "f4e2f50f6a6986f4dd38305d7b2ef5dc0600e8a44ab445fb3d7cafd47acdeb7b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How to test 'sell' decision \n\nDescription: Since this project is for educational purpose ,How can we test and see the 'sell' signal? Is there a way we can stub the test data for a dummy portfolio? Currently i dont know how the portfolio is managed in this code.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 283, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "18800994-250b-4e0e-97e5-c68d58417a67", "embedding": null, "metadata": {"issue_id": 49, "title": "Financialdataset.ai key required?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "515250eb-90b6-4ea2-bae4-c6a7880fb715", "node_type": "4", "metadata": {"issue_id": 49, "title": "Financialdataset.ai key required?", "state": "closed", "labels": [], "type": "issue"}, "hash": "67c81e3e0335cfeb034aedd86056a0cb06df0ee184900f9382612509e4189150", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Financialdataset.ai key required?\n\nDescription: Install seems complete, got a free OPenAI API, trying to test run the hedge fund with AAPL and TSLA tickers to test, have hashed out the dataset line in the .env file but get command to obtain financialdataset API. Should it work with those free tickers or am I missing something? File \"/home/user/ai-hedge-fund/src/tools/api.py\", line 52, in search_line_items raise Exception( Exception: Error fetching data: 401 - {\"error\": \"Missing API key\", \"message\": \"Please include an X-API-KEY from https://financialdatasets.ai in your request header.\"} During task with name 'valuation_agent' and id '6c4a8d82-e57f-110d-2c15-ef9a40d341b8'\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 700, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e2108f76-d687-4921-8397-21288a548307", "embedding": null, "metadata": {"issue_id": 48, "title": "division by zero error", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d23e589f-dddd-4afd-83b5-1b22fdae0ce5", "node_type": "4", "metadata": {"issue_id": 48, "title": "division by zero error", "state": "closed", "labels": [], "type": "issue"}, "hash": "7145187ce55bca22f24d3c5f341db8d18423ff76c18dba021aaa6192ff7227aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: division by zero error\n\nDescription: <img width=\"2056\" alt=\"Screenshot 2025-01-07 at 08 04 09\" src=\"https://github.com/user-attachments/assets/38b5934e-2975-42af-8ed4-1e87ca1a1698\" />\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 205, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c7e4365b-1449-49a8-9699-dd902a274ff4", "embedding": null, "metadata": {"issue_id": 47, "title": "Installation stalls during poetry install", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0b30e0df-fcbb-43d2-9045-b98f12002fd9", "node_type": "4", "metadata": {"issue_id": 47, "title": "Installation stalls during poetry install", "state": "closed", "labels": [], "type": "issue"}, "hash": "825479f95f6c8279442badff04ee81a994f3b65d43a2067b93b1df027dc4d472", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Installation stalls during poetry install\n\nDescription: Last two lines are - Installing typing extensions (4.12.2): Pending - Installung urllibs3 (2.2.3) and then it hangs itself up. Tried on Fedora 40 and Debian 12. Any thoughts?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 252, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "be904583-524a-42d7-9e55-65809567db46", "embedding": null, "metadata": {"issue_id": 46, "title": "API key not found", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c82ad8dc-5856-461f-82c7-55cbeaf1d0ac", "node_type": "4", "metadata": {"issue_id": 46, "title": "API key not found", "state": "closed", "labels": [], "type": "issue"}, "hash": "aaa49a4d4adb8577fa8816c274a922b9f4d698c68993bc830806f85e9e11e22d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: API key not found\n\nDescription: i had this error : Exception: Error fetching data: 401 - {\"error\": \"Missing API key\", \"message\": \"Please include an X-API-KEY from https://financialdatasets.ai in your request header.\"} while I already created the .env doc , with the two keys\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 296, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "02ebe4a6-490b-406e-a702-145cd9954aab", "embedding": null, "metadata": {"issue_id": 45, "title": "Is it mandatory to use financial datasets API?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "26fb10fc-def6-43f5-8730-8773bbcfa361", "node_type": "4", "metadata": {"issue_id": 45, "title": "Is it mandatory to use financial datasets API?", "state": "closed", "labels": [], "type": "issue"}, "hash": "bf4ab103253354256423128782200dbd80637183d3a300b4282e3446e6f1fcb9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Is it mandatory to use financial datasets API?\n\nDescription: Hello team, Is it possible to switch to a free alternative of financial data API. such as using finance? Many thanks\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 199, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "0b6442db-320f-4090-94cd-bda6c4099f05", "embedding": null, "metadata": {"issue_id": 44, "title": "Handling no insider trades etc", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "24b27052-08be-4646-9794-26e531a99d78", "node_type": "4", "metadata": {"issue_id": 44, "title": "Handling no insider trades etc", "state": "closed", "labels": [], "type": "issue"}, "hash": "932152707081696b1b5a1f1c4ea59c6c2be29375a2b8ba5e4dd5a3c0ef0c23d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Handling no insider trades etc\n\nDescription: Need to be able to gracefully handle situation where no insider trades are found in get_insider_trades. At present flow errors out; it should handle this situation more gracefully. Are there other similar situations where data is assumed will always be there from the feed?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 340, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8a7614b4-4b0e-4555-8fde-fecbd7ddca99", "embedding": null, "metadata": {"issue_id": 43, "title": "For Forex Market", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2ce9306-0b8b-4cca-8e12-a9a0710832e8", "node_type": "4", "metadata": {"issue_id": 43, "title": "For Forex Market", "state": "closed", "labels": [], "type": "issue"}, "hash": "32b987424a8a812e49fbb8ca13e75a209bfc389761171192b0d4b437f47fca22", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: For Forex Market\n\nDescription: Forex market has daily volume of more then 7 trillion usd. I think we need to also train it on different forex pairs. We can use OANDA API to access data from the market.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 223, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4c158539-cabe-42d2-a6d2-f2721d45221b", "embedding": null, "metadata": {"issue_id": 40, "title": "Exception for Specific Dates", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a73858b6-8158-4d6b-bd5e-ce90b492d294", "node_type": "4", "metadata": {"issue_id": 40, "title": "Exception for Specific Dates", "state": "closed", "labels": [], "type": "issue"}, "hash": "ec782d9a8197890788253a7aad5043b86ef2fda79d1a1c7cd67cc524cac0db94", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Exception for Specific Dates\n\nDescription: This condition fails for specific dates. For example, running for 31-December without providing start_date raises an exception [CODE_BLOCK] https://github.com/virattt/ai-hedge-fund/blame/6c888162a6a9085bfd5a7061a4bc6ae21c210c51/src/agents/market_data.pyL21\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 321, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "cd4ab86f-c31d-4050-8469-ef7344cd0d3d", "embedding": null, "metadata": {"issue_id": 38, "title": "Discussion: Why Shouldn't We Use yfinance for Backtesting and Researching?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "46fc7659-0437-4f02-bd82-0bd19e3a0916", "node_type": "4", "metadata": {"issue_id": 38, "title": "Discussion: Why Shouldn't We Use yfinance for Backtesting and Researching?", "state": "closed", "labels": [], "type": "issue"}, "hash": "f4a842b222d6de4a324c7d1e031f2b6fd5275f9e052a396cee4c990711879a0a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Discussion: Why Shouldn't We Use yfinance for Backtesting and Researching?\n\nDescription: \n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 111, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "60aeffa9-5f14-448a-afa0-3351bd6e48b8", "embedding": null, "metadata": {"issue_id": 33, "title": "Discussion: why langgraph.graph", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "12b91952-6d97-45d1-858a-a6e3d7f65f6a", "node_type": "4", "metadata": {"issue_id": 33, "title": "Discussion: why langgraph.graph", "state": "closed", "labels": [], "type": "issue"}, "hash": "8dd8a30a0dcaeb5a01a382971af580cfc6f6d06eb13b85a0151ac8e03836904c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Discussion: why langgraph.graph\n\nDescription: Hey, I am about what are your motivations about using langgraph.graph. Thanks for sharing your repository.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 174, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "87ce6720-f2c5-46e8-bedf-486ff282cbe3", "embedding": null, "metadata": {"issue_id": 32, "title": "JUST HOLD, NO BUY", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "989af5f0-e751-4805-b943-1d23c1c4558c", "node_type": "4", "metadata": {"issue_id": 32, "title": "JUST HOLD, NO BUY", "state": "closed", "labels": [], "type": "issue"}, "hash": "47b7c83ed22a482d4c507a2ce515fb3df6525a521b6b5e55acfd2bcb39f51926", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: JUST HOLD, NO BUY\n\nDescription: I have the following issue, and i would like to know if i am doing someting wrong, or this is how its supposed to happen. When I run either backtest or just the main, i only get hold as an answer for everything. I tried multiple companie, it seems that my bot is doing nothing else than holding.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 349, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "328449a8-96e1-46b9-8570-b10c7ddae27e", "embedding": null, "metadata": {"issue_id": 31, "title": "Ai hedge-fund", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "df3b42e7-40e8-477b-acf5-85db06256d12", "node_type": "4", "metadata": {"issue_id": 31, "title": "Ai hedge-fund", "state": "closed", "labels": [], "type": "issue"}, "hash": "636d70aa1ec4ee72bb095bc4453aebca743b3d850300e071d14cb9a3c19374c7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Ai hedge-fund\n\nDescription: \n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 50, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "fab53ecc-03d0-4b2f-8fea-478937290bae", "embedding": null, "metadata": {"issue_id": 29, "title": "please make a tutorial video", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "afcb8535-20f0-4333-b301-db436818d371", "node_type": "4", "metadata": {"issue_id": 29, "title": "please make a tutorial video", "state": "closed", "labels": [], "type": "issue"}, "hash": "93d18fcf4899eee50a393534381d8fd3cfbee9db932dde4eeda43e4109ef9361", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: please make a tutorial video\n\nDescription: Can you please make a tutorial video of how this AI is intended to be used. Are there any requirements for running it on cloud infrastructure. Thank you in advance\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 228, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "fe4b4a6e-9665-44fe-a9ac-f9144334d665", "embedding": null, "metadata": {"issue_id": 26, "title": "cache data", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b1af4042-f988-4e0f-81f8-d0e6bf448d5b", "node_type": "4", "metadata": {"issue_id": 26, "title": "cache data", "state": "closed", "labels": [], "type": "issue"}, "hash": "a1a4d8d9093a2b096d4f430af110cb1754a8109011894b3fe5a270e5a4ecc180", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: cache data\n\nDescription: would be cool to cache financialdataset data\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 91, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "754715dc-2580-452c-9790-3f7007a870f8", "embedding": null, "metadata": {"issue_id": 24, "title": "Suggestion: Add yfinance as Alternative Data Source ", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d8e05be6-80bb-49f5-a6b1-207bc31ee64d", "node_type": "4", "metadata": {"issue_id": 24, "title": "Suggestion: Add yfinance as Alternative Data Source ", "state": "closed", "labels": [], "type": "issue"}, "hash": "105eb504a84933d8ca83e43751d79ecf70d930f3fca90851c8c3a6e7abd928ee", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Suggestion: Add yfinance as Alternative Data Source \n\nDescription: Hi and thanks for creating this educational project. context While exploring this project, I encounter API limits with the financial Dataset API (which is understandable for the free tier). Thus, this let me to thinking of ways to experiment and learn. Suggestion I'd like to propose adding yfinance as an optional/alternative data source, for Local testing and education. I believe it would lower barriers to new contributors, enable developers to test changes locally without API limits, and also help users learn the system before upgrading to Financial Dataset API. Implementation Approach The integration could be done in a way that: 1. Keeps Financial Datasets API as the default/recommended source 2. Clearly documents the limitations of yfinance compared to Financial Datasets API 3. Uses a simple configuration flag to switch between sources Would love to hear your thoughts on this suggestion.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 992, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "673a9f61-c575-4d21-aa70-45ba28152080", "embedding": null, "metadata": {"issue_id": 22, "title": "Financial Data.ai", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4ed4b41-c8e0-4f01-9016-d8afc65f963d", "node_type": "4", "metadata": {"issue_id": 22, "title": "Financial Data.ai", "state": "closed", "labels": [], "type": "issue"}, "hash": "5b488110114447502033592702f0b3316bcdf2bbadae4d53eaade2b9a6d6f8cc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Financial Data.ai\n\nDescription: Is there another option besides the $100 per month subscription to the FinancialData.ai API?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 146, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ffa6d344-a4c7-4a09-b518-7fb9c1671530", "embedding": null, "metadata": {"issue_id": 21, "title": "how to download idm crack 6.42 build 26 latest version 2025?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3adf0308-9231-4e1a-891c-49fdb8324d16", "node_type": "4", "metadata": {"issue_id": 21, "title": "how to download idm crack 6.42 build 26 latest version 2025?", "state": "closed", "labels": [], "type": "issue"}, "hash": "1ea5cc609fa835cc8519cf8be28d9cc05e03b5ba1fe9cba496d4cc0452912c73", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: how to download idm crack 6.42 build 26 latest version 2025?\n\nDescription: Idm crack is one of the best downloader manager. Its increase your download speed up to 10 times. Download now here . . . . . . . . . . . . . . . .. . . . . . ..\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 258, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "af204ce2-0229-46be-aed9-6160ce8eeccf", "embedding": null, "metadata": {"issue_id": 20, "title": "[quuestion] is TAVILY_API_KEY required?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "92ecf132-0f7d-4840-90d9-c4661b0ee9cb", "node_type": "4", "metadata": {"issue_id": 20, "title": "[quuestion] is TAVILY_API_KEY required?", "state": "closed", "labels": [], "type": "issue"}, "hash": "de9673fd365aa5a0dc470f1f5a0e8d02b5fe9c14a68c4c28de779bc77f97d7cc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: [quuestion] is TAVILY_API_KEY required?\n\nDescription: \n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 76, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "869047bc-f071-4f8f-b8b7-46c897882068", "embedding": null, "metadata": {"issue_id": 17, "title": "Request - financialdatasets.ai request type and frequency", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dae6cdde-4cf1-4b07-8dcc-353bfc178ece", "node_type": "4", "metadata": {"issue_id": 17, "title": "Request - financialdatasets.ai request type and frequency", "state": "closed", "labels": [], "type": "issue"}, "hash": "21ff79d9bd20cd41dcd128711e41941b875c08d569d4f52ce0da3b793f814832", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Request - financialdatasets.ai request type and frequency\n\nDescription: Hi, Can you please update the readme file with financialdatasets.ai request type needed for proper operation and also the number of times the request is run after running the script? Prices $0.01 / request Options $0.02 / request Financial metrics $0.02 / request Insider trades $0.02 / request Institutional ownership $0.02 / request SEC filings $0.02 / request Segmented revenue $0.02 / request Income statements $0.04 / request Balance sheets $0.04 / request Cash flow statements $0.04 / request All financial statements $0.10 / request Search $0.01 per 10 filters Thanks.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 669, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d88c7fcd-0466-4513-9324-335a13d9d959", "embedding": null, "metadata": {"issue_id": 15, "title": "Do not support crypto trading right?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a3df2765-b6f6-4be8-bfc6-ade3cbdce064", "node_type": "4", "metadata": {"issue_id": 15, "title": "Do not support crypto trading right?", "state": "closed", "labels": [], "type": "issue"}, "hash": "5edbdb269e5cc8af11a58f4822d1b3bb5fb3d3f40a85e73c2729c2acc32f89e5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Do not support crypto trading right?\n\nDescription: only stock market.... do not consider crypto market in the future?\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 139, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "dab40b6c-3492-4dc8-9b64-7d3f71f32988", "embedding": null, "metadata": {"issue_id": 13, "title": "[Feature] Allow using any OpenAI-compatible mode", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f3b9d08a-a5a6-401b-b1f9-f652bc97cd2f", "node_type": "4", "metadata": {"issue_id": 13, "title": "[Feature] Allow using any OpenAI-compatible mode", "state": "closed", "labels": [], "type": "issue"}, "hash": "c79e8d5cf7052241b1671ffbda42c04143a3d9c6fbc0991b81b929f413ca4d27", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: [Feature] Allow using any OpenAI-compatible mode\n\nDescription: Currently, the model=\"gpt-4o\" is hardcoded in the code. We should allow using any OpenAI-compatible model. This will allow users to use other providers (e.g., OpenRouter) and even local models.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 278, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "05ee934a-1cef-4dae-a2df-c2bcd2b7070d", "embedding": null, "metadata": {"issue_id": 9, "title": "A docker image for this project?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "11dae09d-7ae9-4d05-b5d7-5a2e65a68a38", "node_type": "4", "metadata": {"issue_id": 9, "title": "A docker image for this project?", "state": "closed", "labels": [], "type": "issue"}, "hash": "2871ebdaca5492f733f75936f623e87e9be9a5d47d8a7435052512d1fa0c2c42", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: A docker image for this project?\n\nDescription: Hi, do you by any chance have a docker image for this project? I previously was traumatised by the experience of installing packages onto my local machine which messed up other dependencies.\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 259, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6f766003-9d21-4847-bc50-34d5cbb844e7", "embedding": null, "metadata": {"issue_id": 7, "title": "Financial datasets api?", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "99e7f855-72ed-430b-90de-5cde308ae72a", "node_type": "4", "metadata": {"issue_id": 7, "title": "Financial datasets api?", "state": "closed", "labels": [], "type": "issue"}, "hash": "02fe760cbc68cb2e4e9f7b0659d3090aa151ca35e9239defc3366b54120ec2ea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Financial datasets api?\n\nDescription: Which service or api key is this from? FINANCIAL_DATASETS_API_KEY\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 125, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "517a8b66-ebb9-46f3-b4a6-66fb520ba9b7", "embedding": null, "metadata": {"issue_id": 6, "title": "Small typo in Readme.md", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c8396b9f-6bda-439b-8bed-51a9dd2eb62f", "node_type": "4", "metadata": {"issue_id": 6, "title": "Small typo in Readme.md", "state": "closed", "labels": [], "type": "issue"}, "hash": "ba6d6e643f569bd5f55595b851b41ff9da6f6e84a7c99ccdf80769e8f3b8fa74", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Small typo in Readme.md\n\nDescription: In setup: Clone the repository: git clone https://github.com/your-repo/ai-hedge-fund.git Change to https://github.com/virattt/ai-hedge-fund.git`\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 204, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "67293622-7d6c-4e02-9ed7-e5aa4d860bec", "embedding": null, "metadata": {"issue_id": 3, "title": "Compatibility with Openai compatible api", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4a437737-d749-4aea-8079-d8910c38db13", "node_type": "4", "metadata": {"issue_id": 3, "title": "Compatibility with Openai compatible api", "state": "closed", "labels": [], "type": "issue"}, "hash": "5418aa56a8ea1bd753623072bb45a5d4549a8892671fd458f34db5bc5351136e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Compatibility with Openai compatible api\n\nDescription: Hi! I am just wondering if the set up supports openai compatible api? If so, what adjustment do I need to make? Thanks!\n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 196, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f1f56dc2-bbdc-4b69-af14-1ddddbd8cb29", "embedding": null, "metadata": {"issue_id": 1, "title": "No requirements.txt", "state": "closed", "labels": [], "type": "issue"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4b250527-e4b2-4505-89ec-63cd670f6183", "node_type": "4", "metadata": {"issue_id": 1, "title": "No requirements.txt", "state": "closed", "labels": [], "type": "issue"}, "hash": "32207831fccc050f1d3a023b2b62b5885bb811736620a3ce49c2c87f29de5a06", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: No requirements.txt\n\nDescription: \n\nState: closed", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 56, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4d788707-3337-469c-8e16-b28f0f335de3", "embedding": null, "metadata": {"issue_id": 280, "pr_number": 282, "type": "patch", "files": ["src/agents/sentiment.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ee43a3d2-bd59-4fba-9c59-6b3c7118c3a4", "node_type": "4", "metadata": {"issue_id": 280, "pr_number": 282, "type": "patch", "files": ["src/agents/sentiment.py"]}, "hash": "6759ebd6bdc33e885094c503b9ab08eaf80931ec45b2bc12b7db941edeb07887", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #280 (PR #282):\nPatch summary for PR (max 8000 chars):\nFiles changed: sentiment.py\n--- Changes ---\n\n--- src/agents/sentiment.py ---\n@@ -70,7 +70,7 @@ def sentiment_agent(state: AgentState):\n         total_weighted_signals = len(insider_signals) * insider_weight + len(news_signals) * news_weight\n         confidence = 0  # Default confidence when there are no signals\n         if total_weighted_signals > 0:\n-            confidence = round(max(bullish_signals, bearish_signals) / total_weighted_signals, 2) * 100\n+            confidence = round((max(bullish_signals, bearish_signals) / total_weighted_signals) * 100, 2)\n         reasoning = f\"Weighted Bullish signals: {bullish_signals:.1f}, Weighted Bearish signals: {bearish_signals:.1f}\"\n         sentiment_analysis[ticker] = {", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 796, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "90ff59f5-0910-4dc6-922f-99bf207f0e32", "embedding": null, "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "560ac8a1-9b87-4c86-b608-f804920c51c6", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "hash": "e39d395787800f663ae1f5976db21a995306d375b320dd281fe06379cb66c0a8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "136b0486-c382-4fe6-83e7-a49716f53c4f", "node_type": "1", "metadata": {}, "hash": "31887f6f8ee8371e9df3737de858ff232e783386c3cf01c8e2c4ea03060adf3c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #329):\nPatch summary for PR (max 8000 chars):\nFiles changed: agents.ts, README.md, rakesh_jhunjhunwala.py\n--- Changes ---\n\n--- README.md ---\n@@ -12,14 +12,15 @@ This system employs several agents working together:\n 6. Michael Burry Agent - The Big Short contrarian who hunts for deep value\n 7. Peter Lynch Agent - Practical investor who seeks \"ten-baggers\" in everyday businesses\n 8. Phil Fisher Agent - Meticulous growth investor who uses deep \"scuttlebutt\" research \n-9. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential\n-10. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price\n-11. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals\n-12. Sentiment Agent - Analyzes market sentiment and generates trading signals\n-13. Fundamentals Agent - Analyzes fundamental data and generates trading signals\n-14. Technicals Agent - Analyzes technical indicators and generates trading signals\n-15. Risk Manager - Calculates risk metrics and sets position limits\n-16. Portfolio Manager - Makes final trading decisions and generates orders\n+9. Rakesh Jhunjhunwala Agent - The Big Bull of India, rides on conviction, patience, and long-term India growth stories.\n+10. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential\n+11. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price\n+12. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals\n+13. Sentiment Agent - Analyzes market sentiment and generates trading signals\n+14. Fundamentals Agent - Analyzes fundamental data and generates trading signals\n+15. Technicals Agent - Analyzes technical indicators and generates trading signals\n+16. Risk Manager - Calculates risk metrics and sets position limits\n+17. Portfolio Manager - Makes final trading decisions and generates orders\n <img width=\"1042\" alt=\"Screenshot 2025-03-22 at 6 19 07 PM\" src=\"https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4\" />\n\n--- README.md ---\n@@ -236,22 +237,23 @@ run.bat --ticker AAPL,MSFT,NVDA --ollama backtest\n ```\n ai-hedge-fund/\n \u251c\u2500\u2500 src/\n-\u2502   \u251c\u2500\u2500 agents/                   # Agent definitions and workflow\n-\u2502   \u2502   \u251c\u2500\u2500 bill_ackman.py        # Bill Ackman agent\n-\u2502   \u2502   \u251c\u2500\u2500 fundamentals.py       # Fundamental analysis agent\n-\u2502   \u2502   \u251c\u2500\u2500 portfolio_manager.py  # Portfolio management agent\n-\u2502   \u2502   \u251c\u2500\u2500 risk_manager.py       # Risk management agent\n-\u2502   \u2502   \u251c\u2500\u2500 sentiment.py          # Sentiment analysis agent\n-\u2502   \u2502   \u251c\u2500\u2500 technicals.py         # Technical analysis agent\n-\u2502   \u2502   \u251c\u2500\u2500 valuation.py          # Valuation analysis agent\n-\u2502   \u2502   \u251c\u2500\u2500 ...                   # Other agents\n-\u2502   \u2502   \u251c\u2500\u2500 warren_buffett.py     # Warren Buffett agent\n-\u2502   \u2502   \u251c\u2500\u2500 aswath_damodaran.py   # Aswath Damodaran agent\n-\u2502   \u2502   \u251c\u2500\u2500 ...                   # Other agents\n-\u2502   \u2502   \u251c\u2500\u2500 ...                   # Other agents\n-\u2502   \u251c\u2500\u2500 tools/                    # Agent tools\n-\u2502   \u2502   \u251c\u2500\u2500 api.py                # API tools\n-\u2502   \u251c\u2500\u2500 backtester.py             # Backtesting tools\n+\u2502   \u251c\u2500\u2500 agents/                     # Agent definitions and workflow\n+\u2502   \u2502   \u251c\u2500\u2500 bill_ackman.py          # Bill Ackman agent\n+\u2502   \u2502   \u251c\u2500\u2500 fundamentals.py         # Fundamental analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 portfolio_manager.py    # Portfolio management agent\n+\u2502   \u2502   \u251c\u2500\u2500 risk_manager.py         # Risk management agent\n+\u2502   \u2502   \u251c\u2500\u2500 sentiment.py            # Sentiment analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 technicals.py           # Technical analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 valuation.py            # Valuation analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 ...                     # Other agents\n+\u2502   \u2502   \u251c\u2500\u2500 warren_buffett.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3765, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "136b0486-c382-4fe6-83e7-a49716f53c4f", "embedding": null, "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "560ac8a1-9b87-4c86-b608-f804920c51c6", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "hash": "e39d395787800f663ae1f5976db21a995306d375b320dd281fe06379cb66c0a8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "90ff59f5-0910-4dc6-922f-99bf207f0e32", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "hash": "311c635bb339b0e62abde3d247c0666d736b75e857e6d90596faf65c28180953", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "03d2c831-c82a-48b3-b398-a2de92308822", "node_type": "1", "metadata": {}, "hash": "46cb65bcb10a6a955eecb8a88f5a91a1c4779a0417baacbf91b45edd6c37c224", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "..                   # Other agents\n-\u2502   \u251c\u2500\u2500 tools/                    # Agent tools\n-\u2502   \u2502   \u251c\u2500\u2500 api.py                # API tools\n-\u2502   \u251c\u2500\u2500 backtester.py             # Backtesting tools\n+\u2502   \u251c\u2500\u2500 agents/                     # Agent definitions and workflow\n+\u2502   \u2502   \u251c\u2500\u2500 bill_ackman.py          # Bill Ackman agent\n+\u2502   \u2502   \u251c\u2500\u2500 fundamentals.py         # Fundamental analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 portfolio_manager.py    # Portfolio management agent\n+\u2502   \u2502   \u251c\u2500\u2500 risk_manager.py         # Risk management agent\n+\u2502   \u2502   \u251c\u2500\u2500 sentiment.py            # Sentiment analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 technicals.py           # Technical analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 valuation.py            # Valuation analysis agent\n+\u2502   \u2502   \u251c\u2500\u2500 ...                     # Other agents\n+\u2502   \u2502   \u251c\u2500\u2500 warren_buffett.py       # Warren Buffett agent\n+\u2502   \u2502   \u251c\u2500\u2500 aswath_damodaran.py     # Aswath Damodaran agent\n+\u2502   \u2502   \u251c\u2500\u2500 rakesh_jhunjhunwala.py  # Rakesh_Jhunjhunwala agent\n+\u2502   \u2502   \u251c\u2500\u2500 ...                     # Other agents\n+\u2502   \u2502   \u251c\u2500\u2500 ...                     # Other agents\n+\u2502   \u251c\u2500\u2500 tools/                      # Agent tools\n+\u2502   \u2502   \u251c\u2500\u2500 api.py                  # API tools\n+\u2502   \u251c\u2500\u2500 backtester.py               # Backtesting tools\n \u2502   \u251c\u2500\u2500 main.py # Main entry point\n \u251c\u2500\u2500 pyproject.toml\n \u251c\u2500\u2500 ...\n\n--- app/frontend/src/data/agents.ts ---\n@@ -54,42 +54,49 @@ export const agents: AgentItem[] = [\n     \"description\": \"The Scuttlebutt Investor\",\n     \"order\": 7\n   },\n+  {\n+    \"key\": \"rakesh_jhunjhunwala\",\n+    \"display_name\": \"Rakesh Jhunjhunwala\",\n+    \"description\": \"The Big Bull Of India\",\n+    \"order\": 8\n+  },\n   {\n     \"key\": \"stanley_druckenmiller\",\n     \"display_name\": \"Stanley Druckenmiller\",\n     \"description\": \"The Macro Investor\",\n-    \"order\": 8\n+    \"order\": 9\n   },\n   {\n     \"key\": \"warren_buffett\",\n     \"display_name\": \"Warren Buffett\",\n     \"description\": \"The Oracle of Omaha\",\n-    \"order\": 9\n+    \"order\": 10\n   },\n   {\n     \"key\": \"technical_analyst\",\n     \"display_name\": \"Technical Analyst\",\n     \"description\": \"Chart Pattern Specialist\",\n-    \"order\": 10\n+    \"order\": 11\n   },\n   {\n     \"key\": \"fundamentals_analyst\",\n     \"display_name\": \"Fundamentals Analyst\",\n     \"description\": \"Financial Statement Specialist\",\n-    \"order\": 11\n+    \"order\": 12\n   },\n   {\n     \"key\": \"sentiment_analyst\",\n     \"display_name\": \"Sentiment Analyst\",\n     \"description\": \"Market Sentiment Specialist\",\n-    \"order\": 12\n+    \"order\": 13\n   },\n   {\n     \"key\": \"valuation_analyst\",\n     \"display_name\": \"Valuation Analyst\",\n     \"description\": \"Company Valuation Specialist\",\n-    \"order\": 13\n-  }\n+    \"order\": 14\n+  },\n+  \n ];\n // Get agent by key\n\n--- app/frontend/src/data/agents.ts ---\n@@ -98,4 +105,4 @@ export function getAgentByKey(key: string): AgentItem | undefined {\n }\n // Get default agent to use\n-export const defaultAgent = agents.find(agent => agent.key === \"warren_buffett\") || null; \n+export const defaultAgent = agents.find(agent => agent.key === \"warren_buffett\") || null; \n--- /dev/null\n\n--- src/agents/rakesh_jhunjhunwala.py ---\n@@ -0,0 +1,689 @@\n+from src.graph.state import AgentState, show_agent_reasoning\n+from langchain_core.prompts import ChatPromptTemplate\n+from langchain_core.", "mimetype": "text/plain", "start_char_idx": 2986, "end_char_idx": 6175, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "03d2c831-c82a-48b3-b398-a2de92308822", "embedding": null, "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "560ac8a1-9b87-4c86-b608-f804920c51c6", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "hash": "e39d395787800f663ae1f5976db21a995306d375b320dd281fe06379cb66c0a8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "136b0486-c382-4fe6-83e7-a49716f53c4f", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 329, "type": "patch", "files": ["README.md", "app/frontend/src/data/agents.ts", "src/agents/rakesh_jhunjhunwala.py", "src/utils/analysts.py"]}, "hash": "0923caf9232820d316b821d8f12b555a9a7fdca49bc5a9a0b06281015415f7b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "-    \"order\": 13\n-  }\n+    \"order\": 14\n+  },\n+  \n ];\n // Get agent by key\n\n--- app/frontend/src/data/agents.ts ---\n@@ -98,4 +105,4 @@ export function getAgentByKey(key: string): AgentItem | undefined {\n }\n // Get default agent to use\n-export const defaultAgent = agents.find(agent => agent.key === \"warren_buffett\") || null; \n+export const defaultAgent = agents.find(agent => agent.key === \"warren_buffett\") || null; \n--- /dev/null\n\n--- src/agents/rakesh_jhunjhunwala.py ---\n@@ -0,0 +1,689 @@\n+from src.graph.state import AgentState, show_agent_reasoning\n+from langchain_core.prompts import ChatPromptTemplate\n+from langchain_core.messages import HumanMessage\n+from pydantic import BaseModel\n+import json\n+from typing_extensions import Literal\n+from src.tools.api import get_financial_metrics, get_market_cap, search_line_items\n+from src.utils.llm import call_llm\n+from src.utils.progress import progress\n+\n+class RakeshJhunjhunwalaSignal(BaseModel):\n+    signal: Literal[\"bullish\", \"bearish\", \"neutral\"]\n+    confidence: float\n+    reasoning: str\n+\n+def rakesh_jhunjhunwala_agent(state: AgentState):\n+    \"\"\"Analyzes stocks using Rakesh Jhunjhunwala's principles and LLM reasoning.\"\"\"\n+    data = state[\"data\"]\n+    end_date = data[\"end_date\"]\n+    tickers = data[\"tickers\"]\n+\n+    # Collect all analysis for LLM reasoning\n+    analysis_data = {}\n+    jhunjhunwala_analysis = {}\n+\n+    for ticker in tickers:\n+\n+        # Core Data\n+        progress.update_status(\"rakesh_jhunjhunwala_agent\", ticker, \"Fetching financial metrics\")\n+        metrics = get_financial_metrics(ticker, end_date, period=\"ttm\", limit=5)\n+\n+        progress.update_status(\"rakesh_jhunjhunwala_agent\", ticker, \"Fetching financial line items\")\n+        line_items = search_line_items(\n+            ticker,\n+            [\n+                \"net_income\",\n+                \"earnings_per_share\",\n+                \"ebit\",\n+                \"operating_income\",\n+                \"revenue\",\n+                \"operating_margin\",\n+                \"total_assets\",\n+                \"total_liabilities\",\n+                \"current_assets\",\n+                \"current_liabilities\",\n+                \"free_cash_flow\",\n+                \"dividends_and_other_cash_distributions\",\n+                \"issuance_or_purchase_of_equity_shares\"\n+            ],\n+            end_date,\n+        )\n+\n+        progress.update_status(\"rakesh_jhunjhunwala_agent\", ticker, \"Getting market cap\")\n+        market_cap... [diff truncated for embedding] ...", "mimetype": "text/plain", "start_char_idx": 5544, "end_char_idx": 8033, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "773a0ae0-ffe0-4a86-81c2-1810cc04a1f4", "embedding": null, "metadata": {"issue_id": null, "pr_number": 311, "type": "patch", "files": ["Dockerfile"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a122d3b0-9ea7-476a-9496-981efb064c4a", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 311, "type": "patch", "files": ["Dockerfile"]}, "hash": "fe0e1c8bdf190b35a760807a34a2f55a6bd3313235977e316f7cc9f027a1e466", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #311):\nPatch summary for PR (max 8000 chars):\nFiles changed: Dockerfile\n--- Changes ---\n\n--- Dockerfile ---\n@@ -2,6 +2,9 @@ FROM python:3.11-slim\n WORKDIR /app\n+# Set PYTHONPATH to include the app directory\n+ENV PYTHONPATH=/app\n+\n # Install Poetry\n RUN pip install poetry==1.7.1\n\n--- Dockerfile ---\n@@ -16,4 +19,4 @@ RUN poetry config virtualenvs.create false \\\n COPY . /app/\n # Default command (will be overridden by Docker Compose)\n-CMD [\"python\", \"src/main.py\"] \n+CMD [\"python\", \"src/main.py\"]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 522, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c91d95cb-42be-43ce-9fb2-1c01a4570e8a", "embedding": null, "metadata": {"issue_id": null, "pr_number": 301, "type": "patch", "files": ["src/backtester.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "35e770ec-f271-4311-bc15-abb0548aea67", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 301, "type": "patch", "files": ["src/backtester.py"]}, "hash": "0dbd7e311f98dd08297eadfa57a08b4a13f38ae1e4da3a640446ee1acdd96c81", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #301):\nPatch summary for PR (max 8000 chars):\nFiles changed: backtester.py\n--- Changes ---\n\n--- src/backtester.py ---\n@@ -640,6 +640,17 @@ def analyze_performance(self):\n         default=0.0,\n         help=\"Margin ratio for short positions, e.g. 0.5 for 50% (default: 0.0)\",\n     )\n+    parser.add_argument(\n+        \"--analysts\",\n+        type=str,\n+        required=False,\n+        help=\"Comma-separated list of analysts to use (e.g., michael_burry,other_analyst)\",\n+    )\n+    parser.add_argument(\n+        \"--analysts-all\",\n+        action=\"store_true\",\n+        help=\"Use all available analysts (overrides --analysts)\",\n+    )\n     parser.add_argument(\"--ollama\", action=\"store_true\", help=\"Use Ollama for local LLM inference\")\n     args = parser.parse_args()\n\n--- src/backtester.py ---\n@@ -647,29 +658,34 @@ def analyze_performance(self):\n     # Parse tickers from comma-separated string\n     tickers = [ticker.strip() for ticker in args.tickers.split(\",\")] if args.tickers else []\n-    # Choose analysts\n+    # Parse analysts from command-line flags\n     selected_analysts = None\n-    choices = questionary.checkbox(\n-        \"Use the Space bar to select/unselect analysts.\",\n-        choices=[questionary.Choice(display, value=value) for display, value in ANALYST_ORDER],\n-        instruction=\"\\n\\nPress 'a' to toggle all.\\n\\nPress Enter when done to run the hedge fund.\",\n-        validate=lambda x: len(x) > 0 or \"You must select at least one analyst.\",\n-        style=questionary.Style(\n-            [\n-                (\"checkbox-selected\", \"fg:green\"),\n-                (\"selected\", \"fg:green noinherit\"),\n-                (\"highlighted\", \"noinherit\"),\n-                (\"pointer\", \"noinherit\"),\n-            ]\n-        ),\n-    ).ask()\n-\n-    if not choices:\n-        print(\"\\n\\nInterrupt received. Exiting...\")\n-        sys.exit(0)\n+    if args.analysts_all:\n+        selected_analysts = [a[1] for a in ANALYST_ORDER]\n+    elif args.analysts:\n+        selected_analysts = [a.strip() for a in args.analysts.split(\",\") if a.strip()]\n     else:\n-        selected_analysts = choices\n-        print(f\"\\nSelected analysts: \" f\"{', '.join(Fore.GREEN + choice.title().replace('_', ' ') + Style.RESET_ALL for choice in choices)}\")\n+        # Choose analysts interactively\n+        choices = questionary.checkbox(\n+            \"Use the Space bar to select/unselect analysts.\",\n+            choices=[questionary.Choice(display, value=value) for display, value in ANALYST_ORDER],\n+            instruction=\"\\n\\nPress 'a' to toggle all.\\n\\nPress Enter when done to run the hedge fund.\",\n+            validate=lambda x: len(x) > 0 or \"You must select at least one analyst.\",\n+            style=questionary.Style(\n+                [\n+                    (\"checkbox-selected\", \"fg:green\"),\n+                    (\"selected\", \"fg:green noinherit\"),\n+                    (\"highlighted\", \"noinherit\"),\n+                    (\"pointer\", \"noinherit\"),\n+                ]\n+            ),\n+        ).ask()\n+        if not choices:\n+            print(\"\\n\\nInterrupt received. Exiting...\")\n+            sys.exit(0)\n+        else:\n+            selected_analysts = choices\n+            print(f\"\\nSelected analysts: \" f\"{', '.join(Fore.GREEN + choice.title().replace('_', ' ') + Style.RESET_ALL for choice in choices)}\")\n     # Select LLM model based on whether Ollama is being used\n     model_name = \"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3411, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "23599bd3-7890-426d-a81a-16eacc01dd22", "embedding": null, "metadata": {"issue_id": null, "pr_number": 275, "type": "patch", "files": ["src/llm/models.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "af4d56ff-10d6-4780-87ff-af03570dabf2", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 275, "type": "patch", "files": ["src/llm/models.py"]}, "hash": "c0f931375243a1fa986092e6f480bca9a6772e72c02cf9bd10adfc665e67a113", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #275):\nPatch summary for PR (max 8000 chars):\nFiles changed: models.py\n--- Changes ---\n\n--- src/llm/models.py ---\n@@ -111,11 +111,12 @@ def get_model(model_name: str, model_provider: ModelProvider) -> ChatOpenAI | Ch\n     elif model_provider == ModelProvider.OPENAI:\n         # Get and validate API key\n         api_key = os.getenv(\"OPENAI_API_KEY\")\n+        base_url = os.getenv(\"OPENAI_API_BASE\")\n         if not api_key:\n             # Print error to console\n             print(f\"API Key Error: Please make sure OPENAI_API_KEY is set in your .env file.\")\n             raise ValueError(\"OpenAI API key not found.  Please make sure OPENAI_API_KEY is set in your .env file.\")\n-        return ChatOpenAI(model=model_name, api_key=api_key)\n+        return ChatOpenAI(model=model_name, api_key=api_key, base_url=base_url)\n     elif model_provider == ModelProvider.ANTHROPIC:\n         api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n         if not api_key:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 972, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "fd736ebe-39fb-4f5d-9fef-91c06b2bd15b", "embedding": null, "metadata": {"issue_id": null, "pr_number": 293, "type": "patch", "files": [".env.example", "app/frontend/src/data/models.ts", "src/llm/api_models.json"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0e184c78-44be-4871-9315-11757df406d1", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 293, "type": "patch", "files": [".env.example", "app/frontend/src/data/models.ts", "src/llm/api_models.json"]}, "hash": "ada59f4ebdd96f07c55617f730c4ae990a88d971db86154d694795bc34bc6131", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #293):\nPatch summary for PR (max 8000 chars):\nFiles changed: .env.example, models.ts, api_models.json\n--- Changes ---\n\n--- .env.example ---\n@@ -1,6 +1,7 @@\n # For running LLMs hosted by anthropic (claude-3-5-sonnet, claude-3-opus, claude-3-5-haiku)\n # Get your Anthropic API key from https://anthropic.com/\n ANTHROPIC_API_KEY=your-anthropic-api-key\n+\n # For running LLMs hosted by deepseek (deepseek-chat, deepseek-reasoner, etc.)\n # Get your DeepSeek API key from https://deepseek.com/\n DEEPSEEK_API_KEY=your-deepseek-api-key\n\n--- .env.example ---\n@@ -9,12 +10,14 @@ DEEPSEEK_API_KEY=your-deepseek-api-key\n # Get your Groq API key from https://groq.com/\n GROQ_API_KEY=your-groq-api-key\n-# For running LLMs hosted by gemini (gemini-2.0-flash, gemini-2.0-pro)\n-# Get your Google API key from https://console.cloud.google.com/\n+# For running LLMs hosted by gemini (gemini-2.5-flash, gemini-2.5-pro)\n+# Get your Google API key from https://ai.dev/\n GOOGLE_API_KEY=your-google-api-key\n+\n # For getting financial data to power the hedge fund\n # Get your Financial Datasets API key from https://financialdatasets.ai/\n FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key\n+\n # For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)\n # Get your OpenAI API key from https://platform.openai.com/\n-OPENAI_API_KEY=your-openai-api-key\n+OPENAI_API_KEY=your-openai-api-key\n\n--- app/frontend/src/data/models.ts ---\n@@ -26,8 +26,8 @@ export const apiModels: ModelItem[] = [\n     \"provider\": \"DeepSeek\"\n   },\n   {\n-    \"display_name\": \"gemini-2.0-flash\",\n-    \"model_name\": \"gemini-2.0-flash\",\n+    \"display_name\": \"gemini-2.5-flash\",\n+    \"model_name\": \"gemini-2.5-flash-preview-05-20\",\n     \"provider\": \"Gemini\"\n   },\n   {\n\n--- src/llm/api_models.json ---\n@@ -35,8 +35,8 @@\n     \"provider\": \"DeepSeek\"\n   },\n   {\n-    \"display_name\": \"[gemini] gemini-2.0-flash\",\n-    \"model_name\": \"gemini-2.0-flash\",\n+    \"display_name\": \"[gemini] gemini-2.5-flash\",\n+    \"model_name\": \"gemini-2.5-flash-preview-05-20\",\n     \"provider\": \"Gemini\"\n   },\n   {\n\n--- src/llm/api_models.json ---\n@@ -89,4 +89,4 @@\n     \"model_name\": \"-\",\n     \"provider\": \"OpenAI\"\n   }\n-] \n+]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2177, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d07edeb1-8b65-4ccf-a83c-cf1c25079a6c", "embedding": null, "metadata": {"issue_id": null, "pr_number": 281, "type": "patch", "files": ["app/frontend/src/nodes/components/text-output-dialog.tsx"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a8a458f2-3915-4853-a772-af72f86b55d3", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 281, "type": "patch", "files": ["app/frontend/src/nodes/components/text-output-dialog.tsx"]}, "hash": "764a7922a77334f187ef789f996ef8e699678ff3afcdde6091ae33428fc0a820", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #281):\nPatch summary for PR (max 8000 chars):\nFiles changed: text-output-dialog.tsx\n--- Changes ---\n\n--- app/frontend/src/nodes/components/text-output-dialog.tsx ---\n@@ -69,14 +69,13 @@ export function TextOutputDialog({\n   const getConfidenceBadge = (confidence: number) => {\n     let variant = 'outline';\n-    \n     if (confidence >= 50) variant = 'success';\n     else if (confidence >= 0) variant = 'warning';\n     else variant = 'outline';\n-    \n+    const rounded = Number(confidence.toFixed(1));\n     return (\n       <Badge variant={variant as any}>\n-        {confidence}%\n+        {rounded}%\n       </Badge>\n     );\n   };\n\n--- app/frontend/src/nodes/components/text-output-dialog.tsx ---\n@@ -202,4 +201,4 @@ export function TextOutputDialog({\n       </DialogContent>\n     </Dialog>\n   );\n-} \n+}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 827, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "47a41f2f-a77c-472b-b540-59c3a8ec6398", "embedding": null, "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab9612ea-56c2-42dd-a8d5-f78cb097ac22", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "hash": "4d3450858cd978fa0be085450490d3fc33998f6d20b9f048854da607ecce1a8d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7dde1f5c-589e-4a2c-9b84-5bfaf234f593", "node_type": "1", "metadata": {}, "hash": "58f71fa196f785975fda1487ac5e301c322d82a6d3e8561bbffeecbdaf17922e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #274):\nPatch summary for PR (max 8000 chars):\nFiles changed: ollama_models.json, backtester.py, main.py, models.py, api_models.json\n--- Changes ---\n\n--- src/backtester.py ---\n@@ -672,14 +672,14 @@ def analyze_performance(self):\n         print(f\"\\nSelected analysts: \" f\"{', '.join(Fore.GREEN + choice.title().replace('_', ' ') + Style.RESET_ALL for choice in choices)}\")\n     # Select LLM model based on whether Ollama is being used\n-    model_choice = None\n+    model_name = \"\"\n     model_provider = None\n     if args.ollama:\n         print(f\"{Fore.CYAN}Using Ollama for local LLM inference.{Style.RESET_ALL}\")\n         # Select from Ollama-specific models\n-        model_choice = questionary.select(\n+        model_name = questionary.select(\n             \"Select your Ollama model:\",\n             choices=[questionary.Choice(display, value=value) for display, value, _ in OLLAMA_LLM_ORDER],\n             style=questionary.Style(\n\n--- src/backtester.py ---\n@@ -692,22 +692,28 @@ def analyze_performance(self):\n             ),\n         ).ask()\n-        if not model_choice:\n+        if not model_name:\n             print(\"\\n\\nInterrupt received. Exiting...\")\n             sys.exit(0)\n+        if model_name == \"-\":\n+            model_name = questionary.text(\"Enter the custom model name:\").ask()\n+            if not model_name:\n+                print(\"\\n\\nInterrupt received. Exiting...\")\n+                sys.exit(0)\n+\n         # Ensure Ollama is installed, running, and the model is available\n-        if not ensure_ollama_and_model(model_choice):\n+        if not ensure_ollama_and_model(model_name):\n             print(f\"{Fore.RED}Cannot proceed without Ollama and the selected model.{Style.RESET_ALL}\")\n             sys.exit(1)\n         model_provider = ModelProvider.OLLAMA.value\n-        print(f\"\\nSelected {Fore.CYAN}Ollama{Style.RESET_ALL} model: {Fore.GREEN + Style.BRIGHT}{model_choice}{Style.RESET_ALL}\\n\")\n+        print(f\"\\nSelected {Fore.CYAN}Ollama{Style.RESET_ALL} model: {Fore.GREEN + Style.BRIGHT}{model_name}{Style.RESET_ALL}\\n\")\n     else:\n         # Use the standard cloud-based LLM selection\n         model_choice = questionary.select(\n             \"Select your LLM model:\",\n-            choices=[questionary.Choice(display, value=value) for display, value, _ in LLM_ORDER],\n+            choices=[questionary.Choice(display, value=(name, provider)) for display, name, provider in LLM_ORDER],\n             style=questionary.Style(\n                 [\n                     (\"selected\", \"fg:green bold\"),\n\n--- src/backtester.py ---\n@@ -721,14 +727,21 @@ def analyze_performance(self):\n         if not model_choice:\n             print(\"\\n\\nInterrupt received. Exiting...\")\n             sys.exit(0)\n+        \n+        model_name, model_provider = model_choice\n+\n+        model_info = get_model_info(model_name, model_provider)\n+        if model_info:\n+            if model_info.is_custom():\n+                model_name = questionary.text(\"Enter the custom model name:\").ask()\n+                if not model_name:\n+                    print(\"\\n\\nInterrupt received. Exiting...\")\n+                    sys.exit(0)\n+\n+            print(f\"\\nSelected {Fore.CYAN}{model_provider}{Style.RESET_ALL} model: {Fore.GREEN + Style.BRIGHT}{model_name}{Style.RESET_ALL}\\n\")\n         else:\n-            model_info = get_model_info(model_choice)\n-            if model_info:\n-                model_provider = model_info.provider.value\n-                print(f\"\\nSelected {Fore.CYAN}{model_provider}{Style.RESET_ALL} model: {Fore.GREEN + Style.BRIGHT}{model_choice}{Style.RESET_ALL}\\n\")\n-            else:\n-                model_provider = \"Unknown\"\n-                print(f\"\\nSelected model: {Fore.GREEN + Style.BRIGHT}{model_choice}{Style.RESET_ALL}\\n\")\n+            model_provider = \"Unknown\"\n+            print(f\"\\nSelected model: {Fore.GREEN + Style.BRIGHT}{model_name}{Style.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3902, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "7dde1f5c-589e-4a2c-9b84-5bfaf234f593", "embedding": null, "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab9612ea-56c2-42dd-a8d5-f78cb097ac22", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "hash": "4d3450858cd978fa0be085450490d3fc33998f6d20b9f048854da607ecce1a8d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "47a41f2f-a77c-472b-b540-59c3a8ec6398", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "hash": "7547bd798f56732ed159027556f8f5e2a0e361bb84c972b4ac295ef5f7a8bf8f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4c711d6c-d031-498f-bf9f-c561204ff158", "node_type": "1", "metadata": {}, "hash": "a387afae71efecd6b591bb3528ffbfe691e9d58009aa1336554b7e7b276fc072", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "exit(0)\n+\n+            print(f\"\\nSelected {Fore.CYAN}{model_provider}{Style.RESET_ALL} model: {Fore.GREEN + Style.BRIGHT}{model_name}{Style.RESET_ALL}\\n\")\n         else:\n-            model_info = get_model_info(model_choice)\n-            if model_info:\n-                model_provider = model_info.provider.value\n-                print(f\"\\nSelected {Fore.CYAN}{model_provider}{Style.RESET_ALL} model: {Fore.GREEN + Style.BRIGHT}{model_choice}{Style.RESET_ALL}\\n\")\n-            else:\n-                model_provider = \"Unknown\"\n-                print(f\"\\nSelected model: {Fore.GREEN + Style.BRIGHT}{model_choice}{Style.RESET_ALL}\\n\")\n+            model_provider = \"Unknown\"\n+            print(f\"\\nSelected model: {Fore.GREEN + Style.BRIGHT}{model_name}{Style.RESET_ALL}\\n\")\n     # Create and run the backtester\n     backtester = Backtester(\n\n--- src/backtester.py ---\n@@ -737,7 +750,7 @@ def analyze_performance(self):\n         start_date=args.start_date,\n         end_date=args.end_date,\n         initial_capital=args.initial_capital,\n-        model_name=model_choice,\n+        model_name=model_name,\n         model_provider=model_provider,\n         selected_analysts=selected_analysts,\n         initial_margin_requirement=args.margin_requirement,\n\n--- src/llm/api_models.json ---\n@@ -14,6 +14,11 @@\n     \"model_name\": \"claude-3-7-sonnet-latest\",\n     \"provider\": \"Anthropic\"\n   },\n+  {\n+    \"display_name\": \"[anthropic] custom\",\n+    \"model_name\": \"-\",\n+    \"provider\": \"Anthropic\"\n+  },\n   {\n     \"display_name\": \"[deepseek] deepseek-r1\",\n     \"model_name\": \"deepseek-reasoner\",\n\n--- src/llm/api_models.json ---\n@@ -24,6 +29,11 @@\n     \"model_name\": \"deepseek-chat\",\n     \"provider\": \"DeepSeek\"\n   },\n+  {\n+    \"display_name\": \"[deepseek] custom\",\n+    \"model_name\": \"-\",\n+    \"provider\": \"DeepSeek\"\n+  },\n   {\n     \"display_name\": \"[gemini] gemini-2.0-flash\",\n     \"model_name\": \"gemini-2.0-flash\",\n\n--- src/llm/api_models.json ---\n@@ -34,6 +44,11 @@\n     \"model_name\": \"gemini-2.5-pro-exp-03-25\",\n     \"provider\": \"Gemini\"\n   },\n+  {\n+    \"display_name\": \"[gemini] custom\",\n+    \"model_name\": \"-\",\n+    \"provider\": \"Gemini\"\n+  },\n   {\n     \"display_name\": \"[groq] llama-4-scout-17b\",\n     \"model_name\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n\n--- src/llm/api_models.json ---\n@@ -44,6 +59,11 @@\n     \"model_name\": \"meta-llama/llama-4-maverick-17b-128e-instruct\",\n     \"provider\": \"Groq\"\n   },\n+  {\n+    \"display_name\": \"[groq] custom\",\n+    \"model_name\": \"-\",\n+    \"provider\": \"Groq\"\n+  },\n   {\n     \"display_name\": \"[openai] gpt-4.5\",\n     \"model_name\": \"gpt-4.5-preview\",\n\n--- src/llm/api_models.json ---\n@@ -63,5 +83,10 @@\n     \"display_name\": \"[openai] o4-mini\",\n     \"model_name\": \"o4-mini\",\n     \"provider\": \"OpenAI\"\n+  },\n+  {\n+    \"display_name\": \"[openai] custom\",\n+    \"model_name\": \"-\",\n+    \"provider\": \"OpenAI\"\n   }\n ] \n\n--- src/llm/models.py ---\n@@ -34,6 +34,10 @@ def to_choice_tuple(self) -> Tuple[str, str, str]:\n         \"\"\"Convert to format needed for questionary choices\"\"\"\n         return (self.display_name, self.", "mimetype": "text/plain", "start_char_idx": 3144, "end_char_idx": 6188, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4c711d6c-d031-498f-bf9f-c561204ff158", "embedding": null, "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab9612ea-56c2-42dd-a8d5-f78cb097ac22", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "hash": "4d3450858cd978fa0be085450490d3fc33998f6d20b9f048854da607ecce1a8d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7dde1f5c-589e-4a2c-9b84-5bfaf234f593", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 274, "type": "patch", "files": ["src/backtester.py", "src/llm/api_models.json", "src/llm/models.py", "src/llm/ollama_models.json", "src/main.py", "src/utils/llm.py"]}, "hash": "42d087625c61f38deba609108ad8c159c9ef6b2e446d0c98c9c9be68349e41a1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "+    \"provider\": \"Groq\"\n+  },\n   {\n     \"display_name\": \"[openai] gpt-4.5\",\n     \"model_name\": \"gpt-4.5-preview\",\n\n--- src/llm/api_models.json ---\n@@ -63,5 +83,10 @@\n     \"display_name\": \"[openai] o4-mini\",\n     \"model_name\": \"o4-mini\",\n     \"provider\": \"OpenAI\"\n+  },\n+  {\n+    \"display_name\": \"[openai] custom\",\n+    \"model_name\": \"-\",\n+    \"provider\": \"OpenAI\"\n   }\n ] \n\n--- src/llm/models.py ---\n@@ -34,6 +34,10 @@ def to_choice_tuple(self) -> Tuple[str, str, str]:\n         \"\"\"Convert to format needed for questionary choices\"\"\"\n         return (self.display_name, self.model_name, self.provider.value)\n+    def is_custom(self) -> bool:\n+        \"\"\"Check if the model is a Gemini model\"\"\"\n+        return self.model_name == \"-\"\n+\n     def has_json_mode(self) -> bool:\n         \"\"\"Check if the model supports JSON mode\"\"\"\n         if self.is_deepseek() or self.is_gemini():\n\n--- src/llm/models.py ---\n@@ -94,10 +98,10 @@ def load_models_from_json(json_path: str) -> List[LLMModel]:\n OLLAMA_LLM_ORDER = [model.to_choice_tuple() for model in OLLAMA_MODELS]\n-def get_model_info(model_name: str) -> LLMModel | None:\n+def get_model_info(model_name: str, model_provider: str) -> LLMModel | None:\n     \"\"\"Get model information by model_name\"\"\"\n     all_models = AVAILABLE_MODELS + OLLAMA_MODELS\n-    return next((model for model in all_models if model.model_name == model_name), None)\n+    return next((model for model in all_models if model.model_name == model_name and model.provider == model_provider), None)\n def get_model(model_name: str, model_provider: ModelProvider) -> ChatOpenAI | ChatGroq | ChatOllama | None:\n\n--- src/llm/ollama_models.json ---\n@@ -38,5 +38,10 @@\n     \"display_name\": \"[meta] llama-3.3 (70B)\",\n     \"model_name\": \"llama3.3:70b-instruct-q4_0\",\n     \"provider\": \"Ollama\"\n+  },\n+  {\n+    \"display_name\": \"custom\",\n+    \"model_name\": \"-\",\n+    \"provider\": \"Ollama\"\n   }\n ] \n\n--- src/main.py ---\n@@ -177,14 +177,14 @@ def create_workflow(selected_analysts=None):\n         print(f\"\\nSelected analysts: {', '.join(Fore.GREEN + choice.title().replace('_', ' ') + Style.RESET_ALL for choice in choices)}\\n\")\n     # Select LLM model based on whether Ollama is being used\n-    model_choice = None\n-    model_provider = None\n+    model_name = \"\"\n+    model_provider = \"\"\n     if args.ollama:\n         print(f\"{Fore.CYAN}Using Ollama for local LLM inference.{Style.RESE... [diff truncated for embedding] ...", "mimetype": "text/plain", "start_char_idx": 5613, "end_char_idx": 8033, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "55535d46-4021-4265-97f2-8698ce9739c2", "embedding": null, "metadata": {"issue_id": null, "pr_number": 273, "type": "patch", "files": ["docker-compose.yml"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2dba470b-827b-4168-bb56-fd51c05a7741", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 273, "type": "patch", "files": ["docker-compose.yml"]}, "hash": "869201d013adcf18ceb22e9b1b39442eb4d00d75115e54b974cffe012b24b675", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #273):\nPatch summary for PR (max 8000 chars):\nFiles changed: docker-compose.yml\n--- Changes ---\n\n--- docker-compose.yml ---\n@@ -24,6 +24,7 @@ services:\n     environment:\n       - PYTHONUNBUFFERED=1\n       - OLLAMA_BASE_URL=http://ollama:11434\n+      - PYTHONPATH=/app\n     tty: true\n     stdin_open: true\n\n--- docker-compose.yml ---\n@@ -38,6 +39,7 @@ services:\n     environment:\n       - PYTHONUNBUFFERED=1\n       - OLLAMA_BASE_URL=http://ollama:11434\n+      - PYTHONPATH=/app\n     tty: true\n     stdin_open: true\n\n--- docker-compose.yml ---\n@@ -52,6 +54,7 @@ services:\n     environment:\n       - PYTHONUNBUFFERED=1\n       - OLLAMA_BASE_URL=http://ollama:11434\n+      - PYTHONPATH=/app\n     tty: true\n     stdin_open: true\n\n--- docker-compose.yml ---\n@@ -66,6 +69,7 @@ services:\n     environment:\n       - PYTHONUNBUFFERED=1\n       - OLLAMA_BASE_URL=http://ollama:11434\n+      - PYTHONPATH=/app\n     tty: true\n     stdin_open: true\n\n--- docker-compose.yml ---\n@@ -80,6 +84,7 @@ services:\n     environment:\n       - PYTHONUNBUFFERED=1\n       - OLLAMA_BASE_URL=http://ollama:11434\n+      - PYTHONPATH=/app\n     tty: true\n     stdin_open: true", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1166, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "923091a5-9887-4a76-a3e7-ddae0fa4ff20", "embedding": null, "metadata": {"issue_id": null, "pr_number": 238, "type": "patch", "files": ["src/utils/ollama.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "da2b72ab-af6c-4889-8dea-0df1c83865d4", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 238, "type": "patch", "files": ["src/utils/ollama.py"]}, "hash": "ae217016d54b04526fb9782f177014cbc7c4918a18133b2c848bb4a604657fc8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #238):\nPatch summary for PR (max 8000 chars):\nFiles changed: ollama.py\n--- Changes ---\n\n--- src/utils/ollama.py ---\n@@ -197,8 +197,16 @@ def download_model(model_name: str) -> bool:\n     try:\n         # Use the Ollama CLI to download the model\n-        process = subprocess.Popen([\"ollama\", \"pull\", model_name], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True)  # Redirect stderr to stdout to capture all output  # Line buffered\n-\n+        process = subprocess.Popen(\n+            [\"ollama\", \"pull\", model_name],\n+            stdout=subprocess.PIPE, \n+            stderr=subprocess.STDOUT,  # Redirect stderr to stdout to capture all output\n+            text=True,\n+            bufsize=1,  # Line buffered\n+            encoding='utf-8',  # Explicitly use UTF-8 encoding\n+            errors='replace'   # Replace any characters that cannot be decoded\n+        )\n+        \n         # Show some progress to the user\n         print(f\"{Fore.CYAN}Download progress:{Style.RESET_ALL}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1052, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d4393b5c-8ca4-4cca-8e40-e80ca00f117c", "embedding": null, "metadata": {"issue_id": null, "pr_number": 249, "type": "patch", "files": ["src/llm/models.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b08ae928-767c-423c-b87c-e2040e37676a", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 249, "type": "patch", "files": ["src/llm/models.py"]}, "hash": "0ac5d3d36011d9fb0f9371164ffd3e0904eeb7f09dbdd022cc730c0c4ec87eec", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #249):\nPatch summary for PR (max 8000 chars):\nFiles changed: models.py\n--- Changes ---\n\n--- src/llm/models.py ---\n@@ -111,13 +111,13 @@ def is_ollama(self) -> bool:\n         provider=ModelProvider.OPENAI\n     ),\n     LLMModel(\n-        display_name=\"[openai] o1\",\n-        model_name=\"o1\",\n+        display_name=\"[openai] o3\",\n+        model_name=\"o3\",\n         provider=ModelProvider.OPENAI\n     ),\n     LLMModel(\n-        display_name=\"[openai] o3-mini\",\n-        model_name=\"o3-mini\",\n+        display_name=\"[openai] o4-mini\",\n+        model_name=\"o4-mini\",\n         provider=ModelProvider.OPENAI\n     ),\n ]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 636, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "80472f26-b5df-4ac1-8cde-22100111d7b9", "embedding": null, "metadata": {"issue_id": null, "pr_number": 230, "type": "patch", "files": ["src/utils/ollama.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b1692439-cb2b-4413-a831-7e0e538b6fd4", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 230, "type": "patch", "files": ["src/utils/ollama.py"]}, "hash": "efa6d08d77ae4f6f7225a70068bf5074156d8b5a389272526030d714a7950dd4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #230):\nPatch summary for PR (max 8000 chars):\nFiles changed: ollama.py\n--- Changes ---\n\n--- src/utils/ollama.py ---\n@@ -13,12 +13,12 @@\n OLLAMA_API_MODELS_ENDPOINT = f\"{OLLAMA_SERVER_URL}/api/tags\"\n OLLAMA_DOWNLOAD_URL = {\n     \"darwin\": \"https://ollama.com/download/darwin\",     # macOS\n-    \"win32\": \"https://ollama.com/download/windows\",     # Windows\n+    \"windows\": \"https://ollama.com/download/windows\",     # Windows\n     \"linux\": \"https://ollama.com/download/linux\"        # Linux\n }\n INSTALLATION_INSTRUCTIONS = {\n     \"darwin\": \"curl -fsSL https://ollama.com/install.sh | sh\",\n-    \"win32\": \"# Download from https://ollama.com/download/windows and run the installer\",\n+    \"windows\": \"# Download from https://ollama.com/download/windows and run the installer\",\n     \"linux\": \"curl -fsSL https://ollama.com/install.sh | sh\"\n }\n\n--- src/utils/ollama.py ---\n@@ -36,7 +36,7 @@ def is_ollama_installed() -> bool:\n             return result.returncode == 0\n         except Exception:\n             return False\n-    elif system == \"win32\":  # Windows\n+    elif system == \"windows\":  # Windows\n         try:\n             result = subprocess.run([\"where\", \"ollama\"], \n                                    stdout=subprocess.PIPE, \n\n--- src/utils/ollama.py ---\n@@ -184,15 +184,15 @@ def install_ollama() -> bool:\n         except Exception as e:\n             print(f\"{Fore.RED}Error during Ollama installation: {e}{Style.RESET_ALL}\")\n             return False\n-    elif system == \"win32\":  # Windows\n+    elif system == \"windows\":  # Windows\n         print(f\"{Fore.YELLOW}Automatic installation on Windows is not supported.{Style.RESET_ALL}\")\n-        print(f\"Please download and install Ollama from: {OLLAMA_DOWNLOAD_URL['win32']}\")\n+        print(f\"Please download and install Ollama from: {OLLAMA_DOWNLOAD_URL['windows']}\")\n         # Ask if they want to open the download page\n         if questionary.confirm(\"Do you want to open the Ollama download page in your browser?\").ask():\n             try:\n                 import webbrowser\n-                webbrowser.open(OLLAMA_DOWNLOAD_URL['win32'])\n+                webbrowser.open(OLLAMA_DOWNLOAD_URL['windows'])\n                 print(f\"{Fore.YELLOW}After installation, please restart this application.{Style.RESET_ALL}\")\n                 # Ask if they want to try continuing after installation", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2371, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9cabcec4-2740-4c9a-aee4-220d95d87006", "embedding": null, "metadata": {"issue_id": null, "pr_number": 129, "type": "patch", "files": ["src/tools/api.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bce1b90c-693e-4600-9869-c277973fda29", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 129, "type": "patch", "files": ["src/tools/api.py"]}, "hash": "1e9847f1075de197cdc85a9d754e40e3757fcfc5eb8198eb9ed711cc3a055f49", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #129):\nPatch summary for PR (max 8000 chars):\nFiles changed: api.py\n--- Changes ---\n\n--- src/tools/api.py ---\n@@ -37,7 +37,7 @@ def get_prices(ticker: str, start_date: str, end_date: str) -> list[Price]:\n     url = f\"https://api.financialdatasets.ai/prices/?ticker={ticker}&interval=day&interval_multiplier=1&start_date={start_date}&end_date={end_date}\"\n     response = requests.get(url, headers=headers)\n     if response.status_code != 200:\n-        raise Exception(f\"Error fetching data: {response.status_code} - {response.text}\")\n+        raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\")\n     # Parse response with Pydantic model\n     price_response = PriceResponse(**response.json())\n\n--- src/tools/api.py ---\n@@ -74,7 +74,7 @@ def get_financial_metrics(\n     url = f\"https://api.financialdatasets.ai/financial-metrics/?ticker={ticker}&report_period_lte={end_date}&limit={limit}&period={period}\"\n     response = requests.get(url, headers=headers)\n     if response.status_code != 200:\n-        raise Exception(f\"Error fetching data: {response.status_code} - {response.text}\")\n+        raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\")\n     # Parse response with Pydantic model\n     metrics_response = FinancialMetricsResponse(**response.json())\n\n--- src/tools/api.py ---\n@@ -113,7 +113,7 @@ def search_line_items(\n     }\n     response = requests.post(url, headers=headers, json=body)\n     if response.status_code != 200:\n-        raise Exception(f\"Error fetching data: {response.status_code} - {response.text}\")\n+        raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\")\n     data = response.json()\n     response_model = LineItemResponse(**data)\n     search_results = response_model.search_results\n\n--- src/tools/api.py ---\n@@ -157,7 +157,7 @@ def get_insider_trades(\n         response = requests.get(url, headers=headers)\n         if response.status_code != 200:\n-            raise Exception(f\"Error fetching data: {response.status_code} - {response.text}\")\n+            raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\")\n         data = response.json()\n         response_model = InsiderTradeResponse(**data)\n\n--- src/tools/api.py ---\n@@ -220,7 +220,7 @@ def get_company_news(\n         response = requests.get(url, headers=headers)\n         if response.status_code != 200:\n-            raise Exception(f\"Error fetching data: {response.status_code} - {response.text}\")\n+            raise Exception(f\"Error fetching data: {ticker} - {response.status_code} - {response.text}\")\n         data = response.json()\n         response_model = CompanyNewsResponse(**data)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2761, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "323dfb8b-463a-4ade-936f-16923bd589ae", "embedding": null, "metadata": {"issue_id": null, "pr_number": 191, "type": "patch", "files": ["src/agents/fundamentals.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ffb67ffe-819a-43ad-9c38-f9e87dd809fc", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 191, "type": "patch", "files": ["src/agents/fundamentals.py"]}, "hash": "9219d406af0c7e60caaac462f753bda315407d323c9f519fd729b51f6cb2ea9d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #191):\nPatch summary for PR (max 8000 chars):\nFiles changed: fundamentals.py\n--- Changes ---\n\n--- src/agents/fundamentals.py ---\n@@ -110,7 +110,7 @@ def fundamentals_agent(state: AgentState):\n         ]\n         price_ratio_score = sum(metric is not None and metric > threshold for metric, threshold in thresholds)\n-        signals.append(\"bullish\" if price_ratio_score >= 2 else \"bearish\" if price_ratio_score == 0 else \"neutral\")\n+        signals.append(\"bearish\" if price_ratio_score >= 2 else \"bullish\" if price_ratio_score == 0 else \"neutral\")\n         reasoning[\"price_ratios_signal\"] = {\n             \"signal\": signals[3],\n             \"details\": (f\"P/E: {pe_ratio:.2f}\" if pe_ratio else \"P/E: N/A\") + \", \" + (f\"P/B: {pb_ratio:.2f}\" if pb_ratio else \"P/B: N/A\") + \", \" + (f\"P/S: {ps_ratio:.2f}\" if ps_ratio else \"P/S: N/A\"),", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 857, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c2ca7d95-23cf-4990-aeb3-6edae7c052ae", "embedding": null, "metadata": {"issue_id": null, "pr_number": 184, "type": "patch", "files": [".gitignore"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bbb4b53e-3fca-4d30-bc93-54fb8084b6ea", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 184, "type": "patch", "files": [".gitignore"]}, "hash": "81bf5a103fdb4115018d681849fb5c014ba8c16706e28286b61d0d212472ab90", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #184):\nPatch summary for PR (max 8000 chars):\nFiles changed: .gitignore\n--- Changes ---\n\n--- .gitignore ---\n@@ -33,6 +33,9 @@ ENV/\n .vscode/\n *.swp\n *.swo\n+.cursorrules\n+.cursorignore\n+.cursorindexingignore\n # OS\n .DS_Store", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 249, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "26d6bd07-459d-4d25-83ee-6e437c872177", "embedding": null, "metadata": {"issue_id": null, "pr_number": 159, "type": "patch", "files": [".env.example"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a74086e7-cbf6-407b-8c2a-7dfe21325b97", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 159, "type": "patch", "files": [".env.example"]}, "hash": "6d526b18e8b6b91305f6d6d865c5f4f312a990f3492904628c883364a48eb6c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #159):\nPatch summary for PR (max 8000 chars):\nFiles changed: .env.example\n--- Changes ---\n\n--- .env.example ---\n@@ -9,7 +9,7 @@ DEEPSEEK_API_KEY=your-deepseek-api-key\n # Get your Groq API key from https://groq.com/\n GROQ_API_KEY=your-groq-api-key\n-# For getting news data to power the hedge fund\n+# For running LLMs hosted by gemini (gemini-2.0-flash, gemini-2.0-pro)\n # Get your Google API key from https://console.cloud.google.com/\n GOOGLE_API_KEY=your-google-api-key\n # For getting financial data to power the hedge fund", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 549, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "eb7b370b-59bf-4ea0-9698-deb71f237b2b", "embedding": null, "metadata": {"issue_id": null, "pr_number": 142, "type": "patch", "files": ["src/main.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5e89189f-1aeb-46b3-b749-5e838e3464f6", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 142, "type": "patch", "files": ["src/main.py"]}, "hash": "8bd13da10e8d7a08345487499437bd29dce6e61fc0bbf87069ba55404a43602a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #142):\nPatch summary for PR (max 8000 chars):\nFiles changed: main.py\n--- Changes ---\n\n--- src/main.py ---\n@@ -25,6 +25,7 @@\n from dateutil.relativedelta import relativedelta\n from tabulate import tabulate\n from utils.visualize import save_graph_as_png\n+import json\n # Load environment variables from .env file\n load_dotenv()\n\n--- src/main.py ---\n@@ -33,13 +34,19 @@\n def parse_hedge_fund_response(response):\n-    import json\n-\n+    \"\"\"Parses a JSON string and returns a dictionary.\"\"\"\n     try:\n         return json.loads(response)\n-    except:\n-        print(f\"Error parsing response: {response}\")\n+    except json.JSONDecodeError as e:\n+        print(f\"JSON decoding error: {e}\\nResponse: {repr(response)}\")\n+        return None\n+    except TypeError as e:\n+        print(f\"Invalid response type (expected string, got {type(response).__name__}): {e}\")\n         return None\n+    except Exception as e:\n+        print(f\"Unexpected error while parsing response: {e}\\nResponse: {repr(response)}\")\n+        return None\n+\n ##### Run the Hedge Fund #####", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1075, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b22b3e01-b2f7-4ab1-af4f-1496f01a1c1a", "embedding": null, "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "82c548a4-674d-4173-a89e-611bae011200", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "hash": "0685107db83b6dc3a6d6c20fbbd80b77ccdc14c3e5606dafd4941c38ab746284", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d1be6998-d08b-4727-8ec6-d78d44d89315", "node_type": "1", "metadata": {}, "hash": "170a7d01396c9aac1312b273f6ea430a491ba3537eaf20d23b7789efbad2aae9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #126):\nPatch summary for PR (max 8000 chars):\nFiles changed: cathie_wood.py\n--- Changes ---\n\n--- src/agents/cathie_wood.py ---\n@@ -143,19 +143,19 @@ def analyze_disruptive_potential(metrics: list, financial_line_items: list) -> d\n         }\n     # 1. Revenue Growth Analysis - Check for accelerating growth\n-    revenues = [item.revenue for item in financial_line_items if item.revenue is not None]\n+    revenues = [item.revenue for item in financial_line_items if item.revenue]\n     if len(revenues) >= 3:  # Need at least 3 periods to check acceleration\n         growth_rates = []\n         for i in range(len(revenues)-1):\n             if revenues[i] and revenues[i+1]:\n-                growth_rate = (revenues[i+1] - revenues[i]) / abs(revenues[i])\n+                growth_rate = (revenues[i+1] - revenues[i]) / abs(revenues[i]) if revenues[i] != 0 else 0\n                 growth_rates.append(growth_rate)\n-        \n+\n         # Check if growth is accelerating\n         if len(growth_rates) >= 2 and growth_rates[-1] > growth_rates[0]:\n             score += 2\n             details.append(f\"Revenue growth is accelerating: {(growth_rates[-1]*100):.1f}% vs {(growth_rates[0]*100):.1f}%\")\n-        \n+\n         # Check absolute growth rate\n         latest_growth = growth_rates[-1] if growth_rates else 0\n         if latest_growth > 1.0:\n\n--- src/agents/cathie_wood.py ---\n@@ -180,7 +180,7 @@ def analyze_disruptive_potential(metrics: list, financial_line_items: list) -> d\n         elif margin_trend > 0:\n             score += 1\n             details.append(f\"Slightly improving gross margins: +{(margin_trend*100):.1f}%\")\n-        \n+\n         # Check absolute margin level\n         if gross_margins[-1] > 0.50:  # High margin business\n             score += 2\n\n--- src/agents/cathie_wood.py ---\n@@ -189,13 +189,17 @@ def analyze_disruptive_potential(metrics: list, financial_line_items: list) -> d\n         details.append(\"Insufficient gross margin data\")\n     # 3. Operating Leverage Analysis\n-    revenues = [item.revenue for item in financial_line_items if item.revenue is not None]\n-    operating_expenses = [item.operating_expense for item in financial_line_items if hasattr(item, 'operating_expense') and item.operating_expense is not None]\n-    \n+    revenues = [item.revenue for item in financial_line_items if item.revenue]\n+    operating_expenses = [\n+        item.operating_expense\n+        for item in financial_line_items\n+        if hasattr(item, \"operating_expense\") and item.operating_expense\n+    ]\n+\n     if len(revenues) >= 2 and len(operating_expenses) >= 2:\n         rev_growth = (revenues[-1] - revenues[0]) / abs(revenues[0])\n         opex_growth = (operating_expenses[-1] - operating_expenses[0]) / abs(operating_expenses[0])\n-        \n+\n         if rev_growth > opex_growth:\n             score += 2\n             details.append(\"Positive operating leverage: Revenue growing faster than expenses\")\n\n--- src/agents/cathie_wood.py ---\n@@ -250,19 +254,23 @@ def analyze_innovation_growth(metrics: list, financial_line_items: list) -> dict\n         }\n     # 1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3104, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d1be6998-d08b-4727-8ec6-d78d44d89315", "embedding": null, "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "82c548a4-674d-4173-a89e-611bae011200", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "hash": "0685107db83b6dc3a6d6c20fbbd80b77ccdc14c3e5606dafd4941c38ab746284", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b22b3e01-b2f7-4ab1-af4f-1496f01a1c1a", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "hash": "3e80b6dec096f62381cad0dce9ed2afa6cf2a1ea959d3a5495e8f1ba235acc90", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f96f2de3-85ce-4425-bac5-3b1c98eb6f27", "node_type": "1", "metadata": {}, "hash": "6b13c05f7f4447fd02083fd9b07ff1a7b0aae1caa17ea454ec0ee8a2232f09aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "R&D Investment Trends\n-    rd_expenses = [item.research_and_development for item in financial_line_items if hasattr(item, 'research_and_development') and item.research_and_development is not None]\n-    revenues = [item.revenue for item in financial_line_items if item.revenue is not None]\n-    \n+    rd_expenses = [\n+        item.research_and_development\n+        for item in financial_line_items\n+        if hasattr(item, \"research_and_development\") and item.research_and_development\n+    ]\n+    revenues = [item.revenue for item in financial_line_items if item.revenue]\n+\n     if rd_expenses and revenues and len(rd_expenses) >= 2:\n         # Check R&D growth rate\n-        rd_growth = (rd_expenses[-1] - rd_expenses[0]) / abs(rd_expenses[0])\n+        rd_growth = (rd_expenses[-1] - rd_expenses[0]) / abs(rd_expenses[0]) if rd_expenses[0] != 0 else 0\n         if rd_growth > 0.5:  # 50% growth in R&D\n             score += 3\n             details.append(f\"Strong R&D investment growth: +{(rd_growth*100):.1f}%\")\n         elif rd_growth > 0.2:\n             score += 2\n             details.append(f\"Moderate R&D investment growth: +{(rd_growth*100):.1f}%\")\n-        \n+\n         # Check R&D intensity trend\n         rd_intensity_start = rd_expenses[0] / revenues[0]\n         rd_intensity_end = rd_expenses[-1] / revenues[-1]\n\n--- src/agents/cathie_wood.py ---\n@@ -273,12 +281,12 @@ def analyze_innovation_growth(metrics: list, financial_line_items: list) -> dict\n         details.append(\"Insufficient R&D data for trend analysis\")\n     # 2. Free Cash Flow Analysis\n-    fcf_vals = [item.free_cash_flow for item in financial_line_items if item.free_cash_flow is not None]\n+    fcf_vals = [item.free_cash_flow for item in financial_line_items if item.free_cash_flow]\n     if fcf_vals and len(fcf_vals) >= 2:\n         # Check FCF growth and consistency\n-        fcf_growth = (fcf_vals[-1] - fcf_vals[0]) / abs(fcf_vals[0]) if fcf_vals[0] != 0 else 0\n+        fcf_growth = (fcf_vals[-1] - fcf_vals[0]) / abs(fcf_vals[0])\n         positive_fcf_count = sum(1 for f in fcf_vals if f > 0)\n-        \n+\n         if fcf_growth > 0.3 and positive_fcf_count == len(fcf_vals):\n             score += 3\n             details.append(\"Strong and consistent FCF growth, excellent innovation funding capacity\")\n\n--- src/agents/cathie_wood.py ---\n@@ -292,11 +300,11 @@ def analyze_innovation_growth(metrics: list, financial_line_items: list) -> dict\n         details.append(\"Insufficient FCF data for analysis\")\n     # 3. Operating Efficiency Analysis\n-    op_margin_vals = [item.operating_margin for item in financial_line_items if item.operating_margin is not None]\n+    op_margin_vals = [item.operating_margin for item in financial_line_items if item.operating_margin]\n     if op_margin_vals and len(op_margin_vals) >= 2:\n         # Check margin improvement\n         margin_trend = op_margin_vals[-1] - op_margin_vals[0]\n-        \n+\n         if op_margin_vals[-1] > 0.15 and margin_trend > 0:\n             score += 3\n             details.append(f\"Strong and improving operating margin: {(op_margin_vals[-1]*100):.1f}%\")\n\n--- src/agents/cathie_wood.py ---\n@@ -310,11 +318,11 @@ def analyze_innovation_growth(metrics: list, financial_line_items: list) -> dict\n         details.append(\"Insufficient operating margin data\")\n     # 4.", "mimetype": "text/plain", "start_char_idx": 3105, "end_char_idx": 6413, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f96f2de3-85ce-4425-bac5-3b1c98eb6f27", "embedding": null, "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "82c548a4-674d-4173-a89e-611bae011200", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "hash": "0685107db83b6dc3a6d6c20fbbd80b77ccdc14c3e5606dafd4941c38ab746284", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1be6998-d08b-4727-8ec6-d78d44d89315", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 126, "type": "patch", "files": ["src/agents/cathie_wood.py"]}, "hash": "6190e9b649d28043e0dfedce366d1465084bf0e042cd7372815e7eee3e209c4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Capital Allocation Analysis\n-    capex = [item.capital_expenditure for item in financial_line_items if hasattr(item, 'capital_expenditure') and item.capital_expenditure is not None]\n+    capex = [item.capital_expenditure for item in financial_line_items if hasattr(item, 'capital_expenditure') and item.capital_expenditure]\n     if capex and revenues and len(capex) >= 2:\n         capex_intensity = abs(capex[-1]) / revenues[-1]\n         capex_growth = (abs(capex[-1]) - abs(capex[0])) / abs(capex[0]) if capex[0] != 0 else 0\n-        \n+\n         if capex_intensity > 0.10 and capex_growth > 0.2:\n             score += 2\n             details.append(\"Strong investment in growth infrastructure\")\n\n--- src/agents/cathie_wood.py ---\n@@ -325,7 +333,7 @@ def analyze_innovation_growth(metrics: list, financial_line_items: list) -> dict\n         details.append(\"Insufficient CAPEX data\")\n     # 5. Growth Reinvestment Analysis\n-    dividends = [item.dividends_and_other_cash_distributions for item in financial_line_items if hasattr(item, 'dividends_and_other_cash_distributions') and item.dividends_and_other_cash_distributions is not None]\n+    dividends = [item.dividends_and_other_cash_distributions for item in financial_line_items if hasattr(item, 'dividends_and_other_cash_distributions') and item.dividends_and_other_cash_distributions]\n     if dividends and fcf_vals:\n         # Check if company prioritizes reinvestment over dividends\n         latest_payout_ratio = dividends[-1] / fcf_vals[-1] if fcf_vals[-1] != 0 else 1", "mimetype": "text/plain", "start_char_idx": 6414, "end_char_idx": 7940, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "eb6a7fff-7ed5-4f03-978f-045da3182436", "embedding": null, "metadata": {"issue_id": null, "pr_number": 58, "type": "patch", "files": [".gitignore", "src/main.py", "src/utils/visualize.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "30111ce0-c69a-44bc-91c4-9432952a2c02", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 58, "type": "patch", "files": [".gitignore", "src/main.py", "src/utils/visualize.py"]}, "hash": "7ec4771a6a8ff4f6a61468e334befdaddc05a833c370c5477d71c77227142063", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #58):\nPatch summary for PR (max 8000 chars):\nFiles changed: main.py, visualize.py, .gitignore\n--- Changes ---\n\n--- .gitignore ---\n@@ -36,4 +36,7 @@ ENV/\n # OS\n .DS_Store\n-Thumbs.db \n+Thumbs.db\n+\n+# graph\n+*.png\n\n--- src/main.py ---\n@@ -21,6 +21,7 @@\n from datetime import datetime\n from dateutil.relativedelta import relativedelta\n from tabulate import tabulate\n+from utils.visualize import save_graph_as_png\n # Load environment variables from .env file\n load_dotenv()\n\n--- src/main.py ---\n@@ -152,6 +153,9 @@ def create_workflow(selected_analysts=None):\n     )\n     parser.add_argument(\"--end-date\", type=str, help=\"End date (YYYY-MM-DD). Defaults to today\")\n     parser.add_argument(\"--show-reasoning\", action=\"store_true\", help=\"Show reasoning from each agent\")\n+    parser.add_argument(\n+        \"--show-agent-graph\", action=\"store_true\", help=\"Show the agent graph\"\n+    )\n     args = parser.parse_args()\n\n--- src/main.py ---\n@@ -212,6 +216,14 @@ def create_workflow(selected_analysts=None):\n     workflow = create_workflow(selected_analysts)\n     app = workflow.compile()\n+    if args.show_agent_graph:\n+        file_path = \"\"\n+        if selected_analysts is not None:\n+            for selected_analyst in selected_analysts:\n+                file_path += selected_analyst + \"_\"\n+            file_path += \"graph.png\"\n+        save_graph_as_png(app, file_path)\n+\n     # Validate dates if provided\n     if args.start_date:\n         try:\n--- /dev/null\n\n--- src/utils/visualize.py ---\n@@ -0,0 +1,9 @@\n+from langgraph.graph.state import CompiledGraph\n+from langchain_core.runnables.graph import MermaidDrawMethod\n+\n+\n+def save_graph_as_png(app: CompiledGraph, output_file_path) -> None:\n+    png_image = app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)\n+    file_path = output_file_path if len(output_file_path) > 0 else \"graph.png\"\n+    with open(file_path, \"wb\") as f:\n+        f.write(png_image)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1944, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "20a08099-e2e7-47d4-9816-d39b033387a1", "embedding": null, "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9e389c97-f3a2-4186-a3db-46df735b51d8", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "hash": "2ee7b43b7992f4945d04c22afe6d75558d49607cee906d00993013587288f549", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca21b07c-41b5-4190-9a03-fce1eae1e37d", "node_type": "1", "metadata": {}, "hash": "5b8e45ecbf8e8cd558f34488bccd687eb02c9583ec11e55c3e0f9f2f8277687e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #103):\nPatch summary for PR (max 8000 chars):\nFiles changed: cathie_wood.py\n--- Changes ---\n--- /dev/null\n\n--- src/agents/cathie_wood.py ---\n@@ -0,0 +1,329 @@\n+from langchain_openai import ChatOpenAI\n+from graph.state import AgentState, show_agent_reasoning\n+from tools.api import get_financial_metrics, get_market_cap, search_line_items\n+from langchain_core.prompts import ChatPromptTemplate\n+from langchain_core.messages import HumanMessage\n+from pydantic import BaseModel\n+import json\n+from typing_extensions import Literal\n+from utils.progress import progress\n+from utils.llm import call_llm\n+\n+class CathieWoodSignal(BaseModel):\n+    signal: Literal[\"bullish\", \"bearish\", \"neutral\"]\n+    confidence: float\n+    reasoning: str\n+\n+\n+def cathie_wood_agent(state: AgentState):\n+    \"\"\"\n+    Analyzes stocks using Cathie Wood's investing principles and LLM reasoning.\n+    1. Prioritizes companies with breakthrough technologies or business models\n+    2. Focuses on industries with rapid adoption curves and massive TAM (Total Addressable Market).\n+    3. Invests mostly in AI, robotics, genomic sequencing, fintech, and blockchain.\n+    4. Willing to endure short-term volatility for long-term gains.\n+    \"\"\"\n+    data = state[\"data\"]\n+    end_date = data[\"end_date\"]\n+    tickers = data[\"tickers\"]\n+\n+    analysis_data = {}\n+    cw_analysis = {}\n+\n+    for ticker in tickers:\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Fetching financial metrics\")\n+        # You can adjust these parameters (period=\"annual\"/\"ttm\", limit=5/10, etc.)\n+        metrics = get_financial_metrics(ticker, end_date, period=\"annual\", limit=5)\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Gathering financial line items\")\n+        # Request multiple periods of data (annual or TTM) for a more robust view.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1847, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ca21b07c-41b5-4190-9a03-fce1eae1e37d", "embedding": null, "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9e389c97-f3a2-4186-a3db-46df735b51d8", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "hash": "2ee7b43b7992f4945d04c22afe6d75558d49607cee906d00993013587288f549", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20a08099-e2e7-47d4-9816-d39b033387a1", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "hash": "0b6be1c88a543338a33fba401c0cddf6d66e507a4ab8e8029e4744f859f99a29", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "709eb263-8808-45af-b0df-3b290b9ad135", "node_type": "1", "metadata": {}, "hash": "cd2f45bd10210a3ee047b922b638d28aef1df4622fe02e21e56fc3854fcbee98", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Invests mostly in AI, robotics, genomic sequencing, fintech, and blockchain.\n+    4. Willing to endure short-term volatility for long-term gains.\n+    \"\"\"\n+    data = state[\"data\"]\n+    end_date = data[\"end_date\"]\n+    tickers = data[\"tickers\"]\n+\n+    analysis_data = {}\n+    cw_analysis = {}\n+\n+    for ticker in tickers:\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Fetching financial metrics\")\n+        # You can adjust these parameters (period=\"annual\"/\"ttm\", limit=5/10, etc.)\n+        metrics = get_financial_metrics(ticker, end_date, period=\"annual\", limit=5)\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Gathering financial line items\")\n+        # Request multiple periods of data (annual or TTM) for a more robust view.\n+        financial_line_items = search_line_items(\n+            ticker,\n+            [\n+                \"revenue\",\n+                \"operating_margin\",\n+                \"debt_to_equity\",\n+                \"free_cash_flow\",\n+                \"total_assets\",\n+                \"total_liabilities\",\n+                \"dividends_and_other_cash_distributions\",\n+                \"outstanding_shares\"\n+            ],\n+            end_date,\n+            period=\"annual\",\n+            limit=5\n+        )\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Getting market cap\")\n+        market_cap = get_market_cap(ticker, end_date)\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Analyzing disruptive potential\")\n+        disruptive_analysis = analyze_disruptive_potential(metrics, financial_line_items)\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Analyzing innovation-driven growth\")\n+        innovation_analysis = analyze_innovation_growth(metrics, financial_line_items)\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Calculating valuation & high-growth scenario\")\n+        valuation_analysis = analyze_cathie_wood_valuation(financial_line_items, market_cap)\n+\n+        # Combine partial scores or signals\n+        total_score = disruptive_analysis[\"score\"] + innovation_analysis[\"score\"] + valuation_analysis[\"score\"]\n+        max_possible_score = 15  # Adjust weighting as desired\n+\n+        if total_score >= 0.7 * max_possible_score:\n+            signal = \"bullish\"\n+        elif total_score <= 0.3 * max_possible_score:\n+            signal = \"bearish\"\n+        else:\n+            signal = \"neutral\"\n+\n+        analysis_data[ticker] = {\n+            \"signal\": signal,\n+            \"score\": total_score,\n+            \"max_score\": max_possible_score,\n+            \"disruptive_analysis\": disruptive_analysis,\n+            \"innovation_analysis\": innovation_analysis,\n+            \"valuation_analysis\": valuation_analysis\n+        }\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Generating Cathie Wood style analysis\")\n+        cw_output = generate_cathie_wood_output(\n+            ticker=ticker,\n+            analysis_data=analysis_data,\n+            model_name=state[\"metadata\"][\"model_name\"],\n+            model_provider=state[\"metadata\"][\"model_provider\"],\n+        )\n+\n+        cw_analysis[ticker] = {\n+            \"signal\": cw_output.signal,\n+            \"confidence\": cw_output.confidence,\n+            \"reasoning\": cw_output.reasoning\n+        }\n+\n+        progress.update_status(\"cathie_wood_agent\", ticker, \"Done\")\n+\n+    message = HumanMessage(\n+        content=json.dumps(cw_analysis),\n+        name=\"cathie_wood_agent\"\n+    )\n+\n+    if state[\"metadata\"].get(\"show_reasoning\"):\n+        show_agent_reasoning(cw_analysis, \"Cathie Wood Agent\")\n+\n+    state[\"data\"][\"analyst_signals\"][\"cathie_wood_agent\"] = cw_analysis\n+\n+    return {\n+        \"messages\": [message],\n+        \"data\": state[\"data\"]\n+    }\n+\n+\n+def analyze_disruptive_potential(metrics: list, financial_line_items: list) -> dict:\n+    \"\"\"\n+    Analyze whether the company has disruptive products, technology, or business model.\n+    This can involve revenue growth acceleration, R&D intensity, and market share expansion.", "mimetype": "text/plain", "start_char_idx": 1083, "end_char_idx": 5115, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "709eb263-8808-45af-b0df-3b290b9ad135", "embedding": null, "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9e389c97-f3a2-4186-a3db-46df735b51d8", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "hash": "2ee7b43b7992f4945d04c22afe6d75558d49607cee906d00993013587288f549", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca21b07c-41b5-4190-9a03-fce1eae1e37d", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 103, "type": "patch", "files": ["src/agents/cathie_wood.py", "src/utils/analysts.py"]}, "hash": "a8b50a33ae067daf4c619557373d96824d9bc364550be7dac5f31f0432616e46", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "+    This can involve revenue growth acceleration, R&D intensity, and market share expansion.\n+    \"\"\"\n+    score = 0\n+    details = []\n+\n+    if not metrics or not financial_line_items:\n+        return {\n+            \"score\": 0,\n+            \"details\": \"Insufficient data to analyze disruptive potential\"\n+        }\n+\n+    # Example: check multi-year revenue growth as a proxy for disruptive adoption\n+    revenues = [item.revenue for item in financial_line_items if item.revenue is not None]\n+    if len(revenues) >= 2:\n+        initial, final = revenues[0], revenues[-1]\n+        if initial and final and final > initial:\n+            growth_rate = (final - initial) / abs(initial)\n+            if growth_rate > 1.0:\n+                score += 3\n+                details.append(f\"Revenue more than doubled over the period (growth: {(growth_rate*100):.1f}%).\")\n+            elif growth_rate > 0.5:\n+                score += 2\n+                details.append(f\"Revenue grew significantly over the period (growth: {(growth_rate*100):.1f}%).\")\n+            else:\n+                score += 1\n+                details.append(f\"Revenue growth is positive (growth: {(growth_rate*100):.1f}%).\")\n+        else:\n+            details.append(\"Revenue did not grow significantly or data insufficient.\")\n+    else:\n+        details.append(\"Not enough revenue data for multi-period trend.\")\n+\n+    return {\n+        \"score\": score,\n+        \"details\": \"; \".join(details)\n+    }\n+\n+\n+def analyze_innovation_growth(metrics: list, financial_line_items: list) -> dict:\n+    \"\"\"\n+    Evaluate the company's commitment to R&D, future-facing technologies, and\n+    potential for exponential growth.\n+    \"\"\"\n+    score = 0\n+    details = []\n+\n+    if not metrics or not financial_line_items:\n+        return {\n+            \"score\": 0,\n+            \"details\": \"Insufficient data to analyze innovation-driven growth\"\n+        }\n+\n+    # We might check operating margin, free cash flow used for R&D, etc.\n+    # For demonstration, let's treat consistent positive FCF as an indicator of capacity to invest.\n+\n+    fcf_vals = [item.free_cash_flow for item in financial_line_items if item.free_cash_flow is not None]\n+    if fcf_vals:\n+        positive_fcf_count = sum(1 for f in fcf_vals if f > 0)\n+        if positive_fcf_count >= (len(fcf_vals) // 2 + 1):\n+            score += 2\n+            details.append(\"Company has consistent free cash flow for reinvestment in innovation.\")\n+        else:\n+            details.append(\"Free cash flow not consistently positive, limited reinvestment capacity.\")\n+    else:\n+        details.append(\"No free cash flow data available.\")\n+\n+    # Potentially also look for a metric or ratio indicating R&D expenditure.\n+    # This is purely illustrative.\n+    # We'll just assume if there's an operating margin > 0, there's some buffer for R&D.\n+\n+    op_margin_vals = [item.operating_margin for item in financial_line_items if item.operating_margin is not None]\n... [diff truncated for embedding] ...", "mimetype": "text/plain", "start_char_idx": 5022, "end_char_idx": 8033, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "56a54289-a8cc-44b5-a780-ce7effe8e1af", "embedding": null, "metadata": {"issue_id": null, "pr_number": 85, "type": "patch", "files": ["src/backtester.py", "src/main.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "474f1689-82bd-4f98-8288-0edfaad8b538", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 85, "type": "patch", "files": ["src/backtester.py", "src/main.py"]}, "hash": "5440f8dd6dbbaa7fd02a4ec55cc3cc7e4857c608aed5436190f4d7fdb0b27180", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #85):\nPatch summary for PR (max 8000 chars):\nFiles changed: main.py, backtester.py\n--- Changes ---\n\n--- src/backtester.py ---\n@@ -1,3 +1,5 @@\n+import sys\n+\n from datetime import datetime, timedelta\n from dateutil.relativedelta import relativedelta\n import questionary\n\n--- src/backtester.py ---\n@@ -370,8 +372,8 @@ def analyze_performance(self):\n     ).ask()\n     if not choices:\n-        print(\"You must select at least one analyst. Using all analysts by default.\")\n-        selected_analysts = None\n+        print(\"\\n\\nInterrupt received. Exiting...\")\n+        sys.exit(0)\n     else:\n         selected_analysts = choices\n         print(f\"\\nSelected analysts: {', '.join(Fore.GREEN + choice.title().replace('_', ' ') + Style.RESET_ALL for choice in choices)}\")\n\n--- src/backtester.py ---\n@@ -390,9 +392,8 @@ def analyze_performance(self):\n     ).ask()\n     if not model_choice:\n-        print(\"Using default model: gpt-4o\")\n-        model_choice = \"gpt-4o\"\n-        model_provider = \"OpenAI\"\n+        print(\"\\n\\nInterrupt received. Exiting...\")\n+        sys.exit(0)\n     else:\n         # Get model info using the helper function\n         model_info = get_model_info(model_choice)\n\n--- src/main.py ---\n@@ -1,3 +1,5 @@\n+import sys\n+\n from dotenv import load_dotenv\n from langchain_core.messages import HumanMessage\n from langgraph.graph import END, StateGraph\n\n--- src/main.py ---\n@@ -180,8 +182,8 @@ def create_workflow(selected_analysts=None):\n     ).ask()\n     if not choices:\n-        print(\"You must select at least one analyst. Using all analysts by default.\")\n-        selected_analysts = None\n+        print(\"\\n\\nInterrupt received. Exiting...\")\n+        sys.exit(0)\n     else:\n         selected_analysts = choices\n         print(f\"\\nSelected analysts: {', '.join(Fore.GREEN + choice.title().replace('_', ' ') + Style.RESET_ALL for choice in choices)}\\n\")\n\n--- src/main.py ---\n@@ -199,9 +201,8 @@ def create_workflow(selected_analysts=None):\n     ).ask()\n     if not model_choice:\n-        print(\"Using default model: gpt-4o\")\n-        model_choice = \"gpt-4o\"\n-        model_provider = \"OpenAI\"\n+        print(\"\\n\\nInterrupt received. Exiting...\")\n+        sys.exit(0)\n     else:\n         # Get model info using the helper function\n         model_info = get_model_info(model_choice)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2315, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ac9ff53e-ef73-4529-ab6f-5e74545ddd95", "embedding": null, "metadata": {"issue_id": null, "pr_number": 84, "type": "patch", "files": [".env.example", "README.md", "src/llm/models.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "81ad8607-6dd3-4496-9b0d-4b0942cd75be", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 84, "type": "patch", "files": [".env.example", "README.md", "src/llm/models.py"]}, "hash": "1d58fdbdc122f9cece4c6cc01c587eb3da0e6fa2f55a82cefccfa078c90a778c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #84):\nPatch summary for PR (max 8000 chars):\nFiles changed: .env.example, README.md, models.py\n--- Changes ---\n\n--- .env.example ---\n@@ -6,6 +6,10 @@ OPENAI_API_KEY=your-openai-api-key\n # Get your Groq API key from https://groq.com/\n GROQ_API_KEY=your-groq-api-key\n+# For running LLMs hosted by anthropic (claude-3-5-sonnet, claude-3-opus, claude-3-5-haiku)\n+# Get your Anthropic API key from https://anthropic.com/\n+ANTHROPIC_API_KEY=your-anthropic-api-key\n+\n # For getting financial data to power the hedge fund\n # Get your Financial Datasets API key from https://financialdatasets.ai/\n FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key\n\n--- README.md ---\n@@ -79,7 +79,7 @@ GROQ_API_KEY=your-groq-api-key\n FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key\n ```\n-**Important**: You must set `OPENAI_API_KEY` or `GROQ_API_KEY` for the hedge fund to work.  If you want to use LLMs from both providers, you will need to set both API keys.\n+**Important**: You must set `OPENAI_API_KEY`, `GROQ_API_KEY`, or `ANTHROPIC_API_KEY` for the hedge fund to work.  If you want to use LLMs from all providers, you will need to set all API keys.\n Financial data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key.\n\n--- src/llm/models.py ---\n@@ -1,4 +1,5 @@\n import os\n+from langchain_anthropic import ChatAnthropic\n from langchain_groq import ChatGroq\n from langchain_openai import ChatOpenAI\n from enum import Enum\n\n--- src/llm/models.py ---\n@@ -10,6 +11,7 @@ class ModelProvider(str, Enum):\n     \"\"\"Enum for supported LLM providers\"\"\"\n     OPENAI = \"OpenAI\"\n     GROQ = \"Groq\"\n+    ANTHROPIC = \"Anthropic\"\n class LLMModel(BaseModel):\n\n--- src/llm/models.py ---\n@@ -54,6 +56,21 @@ def is_deepseek(self) -> bool:\n         model_name=\"llama-3.3-70b-versatile\",\n         provider=ModelProvider.GROQ\n     ),\n+    LLMModel(\n+        display_name=\"claude-3.5-sonnet [anthropic]\",\n+        model_name=\"claude-3-5-sonnet-latest\",\n+        provider=ModelProvider.ANTHROPIC\n+    ),\n+    LLMModel(\n+        display_name=\"claude-3.5-haiku [anthropic]\",\n+        model_name=\"claude-3-5-haiku-latest\",\n+        provider=ModelProvider.ANTHROPIC\n+    ),\n+    LLMModel(\n+        display_name=\"claude-3-opus [anthropic]\",\n+        model_name=\"claude-3-opus-latest\",\n+        provider=ModelProvider.ANTHROPIC\n+    ),\n ]\n # Create LLM_ORDER in the format expected by the UI\n\n--- src/llm/models.py ---\n@@ -79,5 +96,9 @@ def get_model(model_name: str, model_provider: ModelProvider) -> ChatOpenAI | Ch\n             print(f\"API Key Error: Please make sure OPENAI_API_KEY is set in your .env file.\")\n             return None\n         return ChatOpenAI(model=model_name, api_key=api_key)\n-\n-\n+    elif model_provider == ModelProvider.ANTHROPIC:\n+        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n+        if not api_key:\n+            print(f\"API Key Error: Please make sure ANTHROPIC_API_KEY is set in your .env file.\")\n+            return None\n+        return ChatAnthropic(model=model_name, api_key=api_key)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3040, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "185255ca-863b-4ee9-8f16-6f723e8d2518", "embedding": null, "metadata": {"issue_id": null, "pr_number": 66, "type": "patch", "files": ["src/main.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9eb7fa0a-cd7f-4812-9235-e71cee233b3d", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 66, "type": "patch", "files": ["src/main.py"]}, "hash": "b348c2b5adedc776fef70ebc7f971bd739a5b2f6b632fd16bd8f12f9097f9c88", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #66):\nPatch summary for PR (max 8000 chars):\nFiles changed: main.py\n--- Changes ---\n\n--- src/main.py ---\n@@ -131,6 +131,12 @@ def create_workflow(selected_analysts=None):\n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser(description=\"Run the hedge fund trading system\")\n+    parser.add_argument(\n+        \"--initial-cash\",\n+        type=float,\n+        default=100000.0,\n+        help=\"Initial cash position. Defaults to 100000.0)\"\n+    )\n     parser.add_argument(\"--tickers\", type=str, required=True, help=\"Comma-separated list of stock ticker symbols\")\n     parser.add_argument(\n         \"--start-date\",\n\n--- src/main.py ---\n@@ -194,10 +200,10 @@ def create_workflow(selected_analysts=None):\n     else:\n         start_date = args.start_date\n-    # Initialize portfolio with multiple tickers\n+    # Initialize portfolio with cash amount and stock positions\n     portfolio = {\n-        \"cash\": 100000.0,  # $100,000 initial cash\n-        \"positions\": {ticker: 0 for ticker in tickers},  # No initial stock positions\n+        \"cash\": args.initial_cash,  # Initial cash amount\n+        \"positions\": {ticker: 0 for ticker in tickers}  # Initial stock positions\n     }\n     # Run the hedge fund", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1232, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "e2c0dd56-eb3b-4876-81fe-32cc2f5755aa", "embedding": null, "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "28f464d6-2f05-47bb-8b34-154a422577ac", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "hash": "79ff7b7bc526973689c605bb28bc5455b0e5ced6ec636916f692992185233cff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2565a924-1840-4d57-97cc-25ebf1ea3735", "node_type": "1", "metadata": {}, "hash": "f34b7599db7561f8bfbc9394bebaf946f95ba230d54046b8969b59a32da3451d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #60):\nPatch summary for PR (max 8000 chars):\nFiles changed: main.py, display.py, analysts.py, backtester.py\n--- Changes ---\n\n--- src/backtester.py ---\n@@ -7,6 +7,7 @@\n from tabulate import tabulate\n from colorama import Fore, Back, Style, init\n+from utils.analysts import ANALYST_ORDER\n from main import run_hedge_fund\n from tools.api import get_price_data\n from utils.display import print_backtest_results, format_backtest_row\n\n--- src/backtester.py ---\n@@ -64,7 +65,7 @@ def execute_trade(self, action, quantity, current_price):\n     def run_backtest(self):\n         dates = pd.date_range(self.start_date, self.end_date, freq=\"B\")\n         table_rows = []\n-        \n+\n         print(\"\\nStarting backtest...\")\n         for current_date in dates:\n\n--- src/backtester.py ---\n@@ -98,7 +99,7 @@ def run_backtest(self):\n             bullish_count = len([s for s in analyst_signals.values() if s.get(\"signal\", \"\").lower() == \"bullish\"])\n             bearish_count = len([s for s in analyst_signals.values() if s.get(\"signal\", \"\").lower() == \"bearish\"])\n             neutral_count = len([s for s in analyst_signals.values() if s.get(\"signal\", \"\").lower() == \"neutral\"])\n-            \n+\n             print(f\"Signal counts - Bullish: {bullish_count}, Bearish: {bearish_count}, Neutral: {neutral_count}\")\n             # Format and add row\n\n--- src/backtester.py ---\n@@ -192,21 +193,18 @@ def analyze_performance(self):\n     choices = questionary.checkbox(\n         \"Use the Space bar to select/unselect analysts.\",\n         choices=[\n-            questionary.Choice(\"Technical Analyst\", value=\"technical_analyst\"),\n-            questionary.Choice(\"Fundamentals Analyst\", value=\"fundamentals_analyst\"),\n-            questionary.Choice(\"Sentiment Analyst\", value=\"sentiment_analyst\"),\n-            questionary.Choice(\"Valuation Analyst\", value=\"valuation_analyst\"),\n+            questionary.Choice(display, value=value) for display, value in ANALYST_ORDER\n         ],\n         instruction=\"\\n\\nPress 'a' to toggle all.\\n\\nPress Enter when done to run the hedge fund.\",\n         validate=lambda x: len(x) > 0 or \"You must select at least one analyst.\",\n         style=questionary.Style([\n-            ('checkbox-selected', 'fg:green'),       \n+            ('checkbox-selected', 'fg:green'),\n             ('selected', 'fg:green noinherit'),\n-            ('highlighted', 'noinherit'),  \n-            ('pointer', 'noinherit'),             \n+            ('highlighted', 'noinherit'),\n+            ('pointer', 'noinherit'),\n         ])\n     ).ask()\n-    \n+\n     if not choices:\n         print(\"You must select at least one analyst. Using all analysts by default.\")\n         selected_analysts = None\n\n--- src/main.py ---\n@@ -12,6 +12,7 @@\n from graph.state import AgentState\n from agents.valuation import valuation_agent\n from utils.display import print_trading_output\n+from utils.analysts import ANALYST_ORDER\n import argparse\n from datetime import datetime\n\n--- src/main.py ---\n@@ -81,11 +82,11 @@ def create_workflow(selected_analysts=None):\n     \"\"\"Create the workflow with selected analysts.\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3107, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "2565a924-1840-4d57-97cc-25ebf1ea3735", "embedding": null, "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "28f464d6-2f05-47bb-8b34-154a422577ac", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "hash": "79ff7b7bc526973689c605bb28bc5455b0e5ced6ec636916f692992185233cff", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e2c0dd56-eb3b-4876-81fe-32cc2f5755aa", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "hash": "a14cbec044a820ced9a540b7c4b5015eb60fe6c17c99af8a23a34a313da5a16f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "15a139ec-798f-4262-aa56-ceeef415fcb4", "node_type": "1", "metadata": {}, "hash": "158417d2b3d8a16bfecf02d16b76e5ba0a3ed262771d2e5062baaba63c6e1893", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Using all analysts by default.\")\n         selected_analysts = None\n\n--- src/main.py ---\n@@ -12,6 +12,7 @@\n from graph.state import AgentState\n from agents.valuation import valuation_agent\n from utils.display import print_trading_output\n+from utils.analysts import ANALYST_ORDER\n import argparse\n from datetime import datetime\n\n--- src/main.py ---\n@@ -81,11 +82,11 @@ def create_workflow(selected_analysts=None):\n     \"\"\"Create the workflow with selected analysts.\"\"\"\n     workflow = StateGraph(AgentState)\n     workflow.add_node(\"start_node\", start)\n-    \n+\n     # Default to all analysts if none selected\n     if selected_analysts is None:\n         selected_analysts = [\"technical_analyst\", \"fundamentals_analyst\", \"sentiment_analyst\", \"valuation_analyst\"]\n-    \n+\n     # Dictionary of all available analysts\n     analyst_nodes = {\n         \"technical_analyst\": (\"technical_analyst_agent\", technical_analyst_agent),\n\n--- src/main.py ---\n@@ -93,25 +94,25 @@ def create_workflow(selected_analysts=None):\n         \"sentiment_analyst\": (\"sentiment_agent\", sentiment_agent),\n         \"valuation_analyst\": (\"valuation_agent\", valuation_agent),\n     }\n-    \n+\n     # Add selected analyst nodes\n     for analyst_key in selected_analysts:\n         node_name, node_func = analyst_nodes[analyst_key]\n         workflow.add_node(node_name, node_func)\n         workflow.add_edge(\"start_node\", node_name)\n-    \n+\n     # Always add risk and portfolio management\n     workflow.add_node(\"risk_management_agent\", risk_management_agent)\n     workflow.add_node(\"portfolio_management_agent\", portfolio_management_agent)\n-    \n+\n     # Connect selected analysts to risk management\n     for analyst_key in selected_analysts:\n         node_name = analyst_nodes[analyst_key][0]\n         workflow.add_edge(node_name, \"risk_management_agent\")\n-    \n+\n     workflow.add_edge(\"risk_management_agent\", \"portfolio_management_agent\")\n     workflow.add_edge(\"portfolio_management_agent\", END)\n-    \n+\n     workflow.set_entry_point(\"start_node\")\n     return workflow\n\n--- src/main.py ---\n@@ -140,21 +141,18 @@ def create_workflow(selected_analysts=None):\n     choices = questionary.checkbox(\n         \"Select your AI analysts.\",\n         choices=[\n-            questionary.Choice(\"Technical Analyst\", value=\"technical_analyst\"),\n-            questionary.Choice(\"Fundamentals Analyst\", value=\"fundamentals_analyst\"),\n-            questionary.Choice(\"Sentiment Analyst\", value=\"sentiment_analyst\"),\n-            questionary.Choice(\"Valuation Analyst\", value=\"valuation_analyst\"),\n+            questionary.Choice(display, value=value) for display, value in ANALYST_ORDER\n         ],\n         instruction=\"\\n\\nInstructions: \\n1. Press Space to select/unselect analysts.\\n2. Press 'a' to select/unselect all.\\n3. Press Enter when done to run the hedge fund.\\n\",\n         validate=lambda x: len(x) > 0 or \"You must select at least one analyst.\",\n         style=questionary.Style([\n-            ('checkbox-selected', 'fg:green'),       \n+            ('checkbox-selected', 'fg:green'),\n             ('selected', 'fg:green noinherit'),\n-            ('highlighted', 'noinherit'),  \n-            ('pointer', 'noinherit'),             \n+            ('highlighted', 'noinherit'),\n+            ('pointer', 'noinherit'),\n         ])\n     ).ask()\n-    \n+\n     if not choices:\n         print(\"You must select at least one analyst. Using all analysts by default.\")\n         selected_analysts = None\n--- /dev/null\n\n--- src/utils/analysts.py ---\n@@ -0,0 +1,9 @@\n+\"\"\"Constants and utilities related to analysts configuration.\"\"\"\n+\n+# Define analyst order - single source of truth\n+ANALYST_ORDER = [\n+    (\"Technical Analyst\", \"technical_analyst\"),\n+    (\"Fundamentals Analyst\", \"fundamentals_analyst\"),\n+    (\"Sentiment Analyst\", \"sentiment_analyst\"),\n+    (\"Valuation Analyst\", \"valuation_analyst\"),\n+]\n\n--- src/utils/display.py ---\n@@ -1,7 +1,15 @@\n from colorama import Fore, Style\n from tabulate import tabulate\n from typing import List, Dict\n+from .analysts import ANALYST_ORDER\n+def sort_analyst_signals(signals):\n+    \"\"\"Sort analyst signals in a consistent order.\"\"\"", "mimetype": "text/plain", "start_char_idx": 2641, "end_char_idx": 6760, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "15a139ec-798f-4262-aa56-ceeef415fcb4", "embedding": null, "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "28f464d6-2f05-47bb-8b34-154a422577ac", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "hash": "79ff7b7bc526973689c605bb28bc5455b0e5ced6ec636916f692992185233cff", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2565a924-1840-4d57-97cc-25ebf1ea3735", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 60, "type": "patch", "files": ["src/backtester.py", "src/main.py", "src/utils/analysts.py", "src/utils/display.py"]}, "hash": "ada330eaf999a7b26af88b1c60f1a4f462bd7b8e123acf970ec607dea4069b9b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Using all analysts by default.\")\n         selected_analysts = None\n--- /dev/null\n\n--- src/utils/analysts.py ---\n@@ -0,0 +1,9 @@\n+\"\"\"Constants and utilities related to analysts configuration.\"\"\"\n+\n+# Define analyst order - single source of truth\n+ANALYST_ORDER = [\n+    (\"Technical Analyst\", \"technical_analyst\"),\n+    (\"Fundamentals Analyst\", \"fundamentals_analyst\"),\n+    (\"Sentiment Analyst\", \"sentiment_analyst\"),\n+    (\"Valuation Analyst\", \"valuation_analyst\"),\n+]\n\n--- src/utils/display.py ---\n@@ -1,7 +1,15 @@\n from colorama import Fore, Style\n from tabulate import tabulate\n from typing import List, Dict\n+from .analysts import ANALYST_ORDER\n+def sort_analyst_signals(signals):\n+    \"\"\"Sort analyst signals in a consistent order.\"\"\"\n+    # Create order mapping from ANALYST_ORDER\n+    analyst_order = {display: idx for idx, (display, _) in enumerate(ANALYST_ORDER)}\n+    analyst_order['Risk Management'] = len(ANALYST_ORDER)  # Add Risk Management at the end\n+\n+    return sorted(signals, key=lambda x: analyst_order.get(x[0], 999))\n def print_trading_output(result: dict) -> None:\n     \"\"\"\n\n--- src/utils/display.py ---\n@@ -15,7 +23,7 @@ def print_trading_output(result: dict) -> None:\n         print(f\"{Fore.RED}No trading decision available{Style.RESET_ALL}\")\n         return\n-    # Print Analyst Signals Table\n+    # Prepare analyst signals table\n     table_data = []\n     for agent, signal in result.get(\"analyst_signals\", {}).items():\n         agent_name = agent.replace(\"_agent\", \"\").replace(\"_\", \" \").title()\n\n--- src/utils/display.py ---\n@@ -35,6 +43,9 @@ def print_trading_output(result: dict) -> None:\n             ]\n         )\n+    # Sort the signals according to the predefined order\n+    table_data = sort_analyst_signals(table_data)\n+\n     print(f\"\\n{Fore.WHITE}{Style.BRIGHT}ANALYST SIGNALS:{Style.RESET_ALL}\")\n     print(\n         tabulate(", "mimetype": "text/plain", "start_char_idx": 6021, "end_char_idx": 7885, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b52a1dc6-d3a3-49e1-a4e0-e776d9501524", "embedding": null, "metadata": {"issue_id": null, "pr_number": 55, "type": "patch", "files": ["src/main.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8dba43b2-86e4-40b9-8d9c-4485f085c741", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 55, "type": "patch", "files": ["src/main.py"]}, "hash": "402b914c2bd574901a4bef02fa1c0dab7093ece009d4e288e15a1dd6eb130177", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #55):\nPatch summary for PR (max 8000 chars):\nFiles changed: main.py\n--- Changes ---\n\n--- src/main.py ---\n@@ -1,3 +1,4 @@\n+from dotenv import load_dotenv\n from langchain_core.messages import HumanMessage\n from langgraph.graph import END, StateGraph\n from colorama import Fore, Back, Style, init\n\n--- src/main.py ---\n@@ -17,8 +18,10 @@\n from dateutil.relativedelta import relativedelta\n from tabulate import tabulate\n-init(autoreset=True)\n+# Load environment variables from .env file\n+load_dotenv()\n+init(autoreset=True)\n def parse_hedge_fund_response(response):\n     import json\n\n--- src/main.py ---\n@@ -200,4 +203,4 @@ def create_workflow(selected_analysts=None):\n         show_reasoning=args.show_reasoning,\n         selected_analysts=selected_analysts,\n     )\n-    print_trading_output(result)\n+    print_trading_output(result)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 855, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4b71f0a1-9a8b-4c4b-b8e2-37c265b5e454", "embedding": null, "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3d128ffc-bfbe-4d9d-8829-9a5fa2a3ddf9", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "hash": "71248a5b8a94e4a92a6b0a966152940983fd029ac6c9a7ffe781c83ff95139cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6f4c0fa1-0f79-4bcf-9bed-c301fa1dddbe", "node_type": "1", "metadata": {}, "hash": "6b8f11e918f331d31bf9d24f63470cb37bb68085e9fa9d9a8ba8e2e553101c7b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #39):\nPatch summary for PR (max 8000 chars):\nFiles changed: valuation.py, fundamentals.py\n--- Changes ---\n\n--- src/agents/fundamentals.py ---\n@@ -16,67 +16,107 @@ def fundamentals_agent(state: AgentState):\n     reasoning = {}\n     # 1. Profitability Analysis\n-    profitability_score = 0\n-    if metrics[\"return_on_equity\"] > 0.15:  # Strong ROE above 15%\n-        profitability_score += 1\n-    if metrics[\"net_margin\"] > 0.20:  # Healthy profit margins\n-        profitability_score += 1\n-    if metrics[\"operating_margin\"] > 0.15:  # Strong operating efficiency\n-        profitability_score += 1\n+    return_on_equity = metrics.get(\"return_on_equity\")\n+    net_margin = metrics.get(\"net_margin\")\n+    operating_margin = metrics.get(\"operating_margin\")\n+\n+    thresholds = [\n+        (return_on_equity, 0.15),  # Strong ROE above 15%\n+        (net_margin, 0.20),  # Healthy profit margins\n+        (operating_margin, 0.15)  # Strong operating efficiency\n+    ]\n+    profitability_score = sum(\n+        metric is not None and metric > threshold\n+        for metric, threshold in thresholds\n+    )\n     signals.append('bullish' if profitability_score >= 2 else 'bearish' if profitability_score == 0 else 'neutral')\n     reasoning[\"profitability_signal\"] = {\n         \"signal\": signals[0],\n-        \"details\": f\"ROE: {metrics['return_on_equity']:.2%}, Net Margin: {metrics['net_margin']:.2%}, Op Margin: {metrics['operating_margin']:.2%}\"\n+        \"details\": (\n+            f\"ROE: {metrics['return_on_equity']:.2%}\" if metrics[\"return_on_equity\"] else \"ROE: N/A\"\n+        ) + \", \" + (\n+            f\"Net Margin: {metrics['net_margin']:.2%}\" if metrics[\"net_margin\"] else \"Net Margin: N/A\"\n+        ) + \", \" + (\n+            f\"Op Margin: {metrics['operating_margin']:.2%}\" if metrics[\"operating_margin\"] else \"Op Margin: N/A\"\n+        )\n     }\n     # 2. Growth Analysis\n-    growth_score = 0\n-    if metrics[\"revenue_growth\"] > 0.10:  # 10% revenue growth\n-        growth_score += 1\n-    if metrics[\"earnings_growth\"] > 0.10:  # 10% earnings growth\n-        growth_score += 1\n-    if metrics[\"book_value_growth\"] > 0.10:  # 10% book value growth\n-        growth_score += 1\n+    revenue_growth = metrics.get(\"revenue_growth\")\n+    earnings_growth = metrics.get(\"earnings_growth\")\n+    book_value_growth = metrics.get(\"book_value_growth\")\n+\n+    thresholds = [\n+        (revenue_growth, 0.10),  # 10% revenue growth\n+        (earnings_growth, 0.10),  # 10% earnings growth\n+        (book_value_growth, 0.10)  # 10% book value growth\n+    ]\n+    growth_score = sum(\n+        metric is not None and metric > threshold\n+        for metric, threshold in thresholds\n+    )\n     signals.append('bullish' if growth_score >= 2 else 'bearish' if growth_score == 0 else 'neutral')\n     reasoning[\"growth_signal\"] = {\n         \"signal\": signals[1],\n-        \"details\": f\"Revenue Growth: {metrics['revenue_growth']:.2%}, Earnings Growth: {metrics['earnings_growth']:.2%}\"\n+        \"details\": (\n+            f\"Revenue Growth: {metrics['revenue_growth']:.2%}\" if metrics[\"revenue_growth\"] else \"Revenue Growth: N/A\"\n+        ) + \", \" + (\n+            f\"Earnings Growth: {metrics['earnings_growth']:.2%}\" if metrics[\"earnings_growth\"] else \"Earnings Growth: N/A\"\n+        )\n     }\n     # 3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3295, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6f4c0fa1-0f79-4bcf-9bed-c301fa1dddbe", "embedding": null, "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3d128ffc-bfbe-4d9d-8829-9a5fa2a3ddf9", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "hash": "71248a5b8a94e4a92a6b0a966152940983fd029ac6c9a7ffe781c83ff95139cb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b71f0a1-9a8b-4c4b-b8e2-37c265b5e454", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "hash": "4bbad4b1590a621addff6992ef42ca3719ae8ddafe111e00852cec02351d6bb6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9ce73b49-860b-46d0-a82f-d120dcb87f10", "node_type": "1", "metadata": {}, "hash": "d729bb3051f8cf484dd9c767a5d1c4bdb20c040b11c1e2568bf9aa27db5c1146", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Financial Health\n+    current_ratio = metrics.get(\"current_ratio\")\n+    debt_to_equity = metrics.get(\"debt_to_equity\")\n+    free_cash_flow_per_share = metrics.get(\"free_cash_flow_per_share\")\n+    earnings_per_share = metrics.get(\"earnings_per_share\")\n+\n     health_score = 0\n-    if metrics[\"current_ratio\"] > 1.5:  # Strong liquidity\n+    if current_ratio and current_ratio > 1.5:  # Strong liquidity\n         health_score += 1\n-    if metrics[\"debt_to_equity\"] < 0.5:  # Conservative debt levels\n+    if debt_to_equity and debt_to_equity < 0.5:  # Conservative debt levels\n         health_score += 1\n-    if metrics[\"free_cash_flow_per_share\"] > metrics[\"earnings_per_share\"] * 0.8:  # Strong FCF conversion\n+    if (free_cash_flow_per_share and earnings_per_share and\n+            free_cash_flow_per_share > earnings_per_share * 0.8):  # Strong FCF conversion\n         health_score += 1\n     signals.append('bullish' if health_score >= 2 else 'bearish' if health_score == 0 else 'neutral')\n     reasoning[\"financial_health_signal\"] = {\n         \"signal\": signals[2],\n-        \"details\": f\"Current Ratio: {metrics['current_ratio']:.2f}, D/E: {metrics['debt_to_equity']:.2f}\"\n+        \"details\": (\n+            f\"Current Ratio: {metrics['current_ratio']:.2f}\" if metrics[\"current_ratio\"] else \"Current Ratio: N/A\"\n+        ) + \", \" + (\n+            f\"D/E: {metrics['debt_to_equity']:.2f}\" if metrics[\"debt_to_equity\"] else \"D/E: N/A\"\n+        )\n     }\n     # 4.", "mimetype": "text/plain", "start_char_idx": 3296, "end_char_idx": 4758, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9ce73b49-860b-46d0-a82f-d120dcb87f10", "embedding": null, "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3d128ffc-bfbe-4d9d-8829-9a5fa2a3ddf9", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "hash": "71248a5b8a94e4a92a6b0a966152940983fd029ac6c9a7ffe781c83ff95139cb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6f4c0fa1-0f79-4bcf-9bed-c301fa1dddbe", "node_type": "1", "metadata": {"issue_id": null, "pr_number": 39, "type": "patch", "files": ["src/agents/fundamentals.py", "src/agents/valuation.py"]}, "hash": "714ee10498ce67610da143adab6b6724c92ac5533443bd85f8c41111400b8b9c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Price to X ratios\n-    pe_ratio = metrics[\"price_to_earnings_ratio\"]\n-    pb_ratio = metrics[\"price_to_book_ratio\"]\n-    ps_ratio = metrics[\"price_to_sales_ratio\"]\n-    \n-    price_ratio_score = 0\n-    if pe_ratio < 25:  # Reasonable P/E ratio\n-        price_ratio_score += 1\n-    if pb_ratio < 3:  # Reasonable P/B ratio\n-        price_ratio_score += 1\n-    if ps_ratio < 5:  # Reasonable P/S ratio\n-        price_ratio_score += 1\n+    pe_ratio = metrics.get(\"price_to_earnings_ratio\")\n+    pb_ratio = metrics.get(\"price_to_book_ratio\")\n+    ps_ratio = metrics.get(\"price_to_sales_ratio\")\n+\n+    thresholds = [\n+        (pe_ratio, 25),  # Reasonable P/E ratio\n+        (pb_ratio, 3),  # Reasonable P/B ratio\n+        (ps_ratio, 5)  # Reasonable P/S ratio\n+    ]\n+    price_ratio_score = sum(\n+        metric is not None and metric > threshold\n+        for metric, threshold in thresholds\n+    )\n     signals.append('bullish' if price_ratio_score >= 2 else 'bearish' if price_ratio_score == 0 else 'neutral')\n     reasoning[\"price_ratios_signal\"] = {\n         \"signal\": signals[3],\n-        \"details\": f\"P/E: {pe_ratio:.2f}, P/B: {pb_ratio:.2f}, P/S: {ps_ratio:.2f}\"\n+        \"details\": (\n+            f\"P/E: {pe_ratio:.2f}\" if pe_ratio else \"P/E: N/A\"\n+        ) + \", \" + (\n+            f\"P/B: {pb_ratio:.2f}\" if pb_ratio else \"P/B: N/A\"\n+        ) + \", \" + (\n+            f\"P/S: {ps_ratio:.2f}\" if ps_ratio else \"P/S: N/A\"\n+        )\n     }\n     # Determine overall signal\n\n--- src/agents/fundamentals.py ---\n@@ -113,4 +153,4 @@ def fundamentals_agent(state: AgentState):\n     return {\n         \"messages\": [message],\n         \"data\": data,\n-    }\n+    }\n\n--- src/agents/valuation.py ---\n@@ -14,7 +14,7 @@ def valuation_agent(state: AgentState):\n     reasoning = {}\n     # Calculate working capital change\n-    working_capital_change = current_financial_line_item.get('working_capital', 0) - previous_financial_line_item.get('working_capital', 0)\n+    working_capital_change = (current_financial_line_item.get('working_capital') or 0) - (previous_financial_line_item.get('working_capital') or 0)\n     # Owner Earnings Valuation (Buffett Method)\n     owner_earnings_value = calculate_owner_earnings_value(", "mimetype": "text/plain", "start_char_idx": 4759, "end_char_idx": 6965, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9fb25c42-3ed2-4136-9651-38dbb7890f8f", "embedding": null, "metadata": {"issue_id": null, "pr_number": 35, "type": "patch", "files": ["src/backtester.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "546d09a3-968f-481a-8248-b8be1f2f5628", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 35, "type": "patch", "files": ["src/backtester.py"]}, "hash": "cc79562c9030f1130391d3977c59e07ee0474eb3ad579987b13068294ab7f5c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #35):\nPatch summary for PR (max 8000 chars):\nFiles changed: backtester.py\n--- Changes ---\n\n--- src/backtester.py ---\n@@ -133,9 +133,9 @@ def analyze_performance(self):\n     # Set up argument parser\n     parser = argparse.ArgumentParser(description='Run backtesting simulation')\n     parser.add_argument('--ticker', type=str, help='Stock ticker symbol (e.g., AAPL)')\n-    parser.add_argument('--end_date', type=str, default=datetime.now().strftime('%Y-%m-%d'), help='End date in YYYY-MM-DD format')\n-    parser.add_argument('--start_date', type=str, default=(datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d'), help='Start date in YYYY-MM-DD format')\n-    parser.add_argument('--initial_capital', type=float, default=100000, help='Initial capital amount (default: 100000)')\n+    parser.add_argument('--end-date', type=str, default=datetime.now().strftime('%Y-%m-%d'), help='End date in YYYY-MM-DD format')\n+    parser.add_argument('--start-date', type=str, default=(datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d'), help='Start date in YYYY-MM-DD format')\n+    parser.add_argument('--initial-capital', type=float, default=100000, help='Initial capital amount (default: 100000)')\n     args = parser.parse_args()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1251, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c3f29fee-c4b1-4662-969e-70f598d91179", "embedding": null, "metadata": {"issue_id": null, "pr_number": 27, "type": "patch", "files": ["src/agents/sentiment.py"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ea5699cd-ea67-4993-a4f9-50f5865e3a50", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 27, "type": "patch", "files": ["src/agents/sentiment.py"]}, "hash": "019e909d920a40ce5f6b7212f5ad0cba8f74a91988c943dac8f593e04a45a2a7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #27):\nPatch summary for PR (max 8000 chars):\nFiles changed: sentiment.py\n--- Changes ---\n\n--- src/agents/sentiment.py ---\n@@ -3,6 +3,10 @@\n from agents.state import AgentState, show_agent_reasoning\n+import pandas as pd\n+\n+import numpy as np\n+\n import json\n ##### Sentiment Agent #####\n\n--- src/agents/sentiment.py ---\n@@ -13,15 +17,13 @@ def sentiment_agent(state: AgentState):\n     show_reasoning = state[\"metadata\"][\"show_reasoning\"]\n     # Loop through the insider trades, if transaction_shares is negative, then it is a sell, which is bearish, if positive, then it is a buy, which is bullish\n-    signals = []\n-    for trade in insider_trades:\n-        transaction_shares = trade[\"transaction_shares\"]\n-        if not transaction_shares:\n-            continue\n-        if transaction_shares < 0:\n-            signals.append(\"bearish\")\n-        else:\n-            signals.append(\"bullish\")\n+\n+    # dropping na values \n+    transaction_shares = pd.Series([t['transaction_shares'] for t in insider_trades]).dropna()\n+    \n+    # vectorized form of the previous loop for more efficiency while dealing with large data.\n+    bearish_condition = transaction_shares < 0\n+    signals = np.where(bearish_condition, \"bearish\", \"bullish\").tolist()\n     # Determine overall signal\n     bullish_signals = signals.count(\"bullish\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1346, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "70692bbc-2cb1-4bcf-a281-096f695202a4", "embedding": null, "metadata": {"issue_id": null, "pr_number": 19, "type": "patch", "files": ["LICENSE"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eaa2f1d6-db06-40c1-9dc4-0577e8497713", "node_type": "4", "metadata": {"issue_id": null, "pr_number": 19, "type": "patch", "files": ["LICENSE"]}, "hash": "6d014c091bbced8256778e4cb906399c51a957b2600035c5605569c13bd7e349", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Patch for Issue #None (PR #19):\nPatch summary for PR (max 8000 chars):\nFiles changed: LICENSE\n--- Changes ---\n--- /dev/null\n\n--- LICENSE ---\n@@ -0,0 +1,21 @@\n+MIT License\n+\n+Copyright (c) 2024 Virat Singh\n+\n+Permission is hereby granted, free of charge, to any person obtaining a copy\n+of this software and associated documentation files (the \"Software\"), to deal\n+in the Software without restriction, including without limitation the rights\n+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n+copies of the Software, and to permit persons to whom the Software is\n+furnished to do so, subject to the following conditions:\n+\n+The above copyright notice and this permission notice shall be included in all\n+copies or substantial portions of the Software.\n+\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n+SOFTWARE.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1246, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}]